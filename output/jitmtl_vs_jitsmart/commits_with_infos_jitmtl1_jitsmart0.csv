commit_id,label,msg,code
eec10fcf0c795bdfacef4c9933585f65f953fd58,1.0,Writing central directory in chunks instead of one by one Increased size of copybuf,"{'added_code': {'writeCentralDirectoryInChunks ( ) ;', 'count + + ;', '}', '. ARCHIVE TOO BIG MESSAGE ) ;', 'while ( iterator . hasNext ( ) ) {', '| | ze . getCompressedSize ( ) > = ZIP64 MAGIC', 'int count = 0 ;', 'writeCounted ( centralFileHeader ) ;', '| | ze . getSize ( ) > = ZIP64 MAGIC', 'int NUM PER WRITE = 1000 ;', '} ;', 'byteArrayOutputStream . reset ( ) ;', 'return createCentralFileHeader ( ze , getName ( ze ) , lfhOffset , needsZip64Extra ) ;', 'import java . io . ByteArrayOutputStream ;', 'ze = iterator . next ( ) ;', 'if ( count > NUM PER WRITE ) {', 'ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream ( 70 * NUM PER WRITE ) ;', 'final byte [ ] copyBuffer = new byte [ 32768 ] ;', 'ZipArchiveEntry ze ;', 'System . arraycopy ( ZERO , 0 , buf , CFH DISK NUMBER OFFSET , SHORT ) ;', 'private byte [ ] createCentralFileHeader ( ZipArchiveEntry ze ) throws IOException {', 'Iterator < ZipArchiveEntry > iterator = entries . iterator ( ) ;', 'byteArrayOutputStream . write ( createCentralFileHeader ( ze ) ) ;', 'import java . util . Iterator ;', 'byte [ ] centralFileHeader = createCentralFileHeader ( ze ) ;', 'count = 0 ;', 'writeCounted ( byteArrayOutputStream . toByteArray ( ) ) ;', '| | lfhOffset > = ZIP64 MAGIC ;', 'private void writeCentralDirectoryInChunks ( ) throws IOException {'}, 'removed_code': {'for ( ZipArchiveEntry ze : entries ) {', 'writeCentralFileHeader ( ze ) ;', 'writeCounted ( centralFileHeader ) ;', '| | lfhOffset > = ZIP64 MAGIC ;', 'byte [ ] centralFileHeader = createCentralFileHeader ( ze , getName ( ze ) , lfhOffset , needsZip64Extra ) ;', '. ARCHIVE TOO BIG MESSAGE ) ;', '}', 'System . arraycopy ( ZERO , 0 , buf , CFH DISK NUMBER OFFSET , SHORT ) ;', 'final byte [ ] copyBuffer = new byte [ 16384 ] ;', '| | ze . getSize ( ) > = ZIP64 MAGIC', '| | ze . getCompressedSize ( ) > = ZIP64 MAGIC'}}"
4b8647bf6ce2b478e6bc90d0158ce81939a14378,1.0,[ MATH - 898 ] Add implementation of fuzzy k - means clusterer .,"{'added_code': {'membershipMatrix [ i ] = MathArrays . normalizeArray ( membershipMatrix [ i ] , 1 . 0 ) ;', 'clusters . get ( newCluster ) . addPoint ( point ) ;', 'return maxIterations ;', 'membershipMatrix [ i ] [ j ] = 1 . 0 / sum ;', 'this . maxIterations = maxIterations ;', 'final int maxIterations , final DistanceMeasure measure )', 'import org . apache . commons . math3 . util . FastMath ;', 'if ( size = = 0 ) {', 'private List < CentroidCluster < T > > clusters ;', 'clusters = newClusters ;', 'public RealMatrix getMembershipMatrix ( ) {', 'private double [ ] [ ] membershipMatrix ;', 'final double epsilon , final RandomGenerator random )', 'import org . apache . commons . math3 . random . RandomGenerator ;', 'public double getFuzzyness ( ) {', 'return 0 ;', 'points = Collections . unmodifiableList ( new ArrayList < T > ( dataPoints ) ) ;', 'final Clusterable center = cluster . getCenter ( ) ;', 'public int getMaxIterations ( ) {', 'public List < T > getDataPoints ( ) {', 'membershipMatrix = new double [ size ] [ k ] ;', 'sum + = u ;', 'sum + = FastMath . pow ( distA / distB , 2 . 0 / ( fuzzyness - 1 . 0 ) ) ;', 'throws MathIllegalArgumentException {', 'clusters . add ( new CentroidCluster < T > ( new DoublePoint ( new double [ pointDimension ] ) ) ) ;', 'for ( int i = 0 ; i < points . size ( ) ; i + + ) {', 'double v = FastMath . abs ( membershipMatrix [ i ] [ j ] - matrix [ i ] [ j ] ) ;', 'updateMembershipMatrix ( ) ;', 'if ( points = = null | | clusters = = null ) {', 'newCluster = j ;', 'i + + ;', 'if ( fuzzyness < = 1 . 0d ) {', 'import org . apache . commons . math3 . ml . distance . DistanceMeasure ;', 'int newCluster = - 1 ;', 'import org . apache . commons . math3 . util . MathUtils ;', 'membershipMatrix [ i ] [ j ] = random . nextDouble ( ) ;', 'double dist = distance ( point , cluster . getCenter ( ) ) ;', 'final double [ ] pointArr = point . getPoint ( ) ;', 'import org . apache . commons . math3 . exception . NumberIsTooSmallException ;', 'this . k = k ;', 'public RandomGenerator getRandomGenerator ( ) {', 'this . clusters = null ;', 'initializeMembershipMatrix ( ) ;', 'private final int k ;', 'final double [ ] [ ] oldMatrix = new double [ size ] [ k ] ;', 'return maxMembership ;', 'this . fuzzyness = fuzzyness ;', 'for ( final CentroidCluster < T > cluster : clusters ) {', '} while ( difference > epsilon & & + + iteration < max ) ;', 'private void updateClusterCenters ( ) {', 'double [ ] arr = new double [ center . getPoint ( ) . length ] ;', 'import java . util . ArrayList ;', 'private List < T > points ;', 'final double u = FastMath . pow ( membershipMatrix [ i ] [ j ] , fuzzyness ) ;', 'MathUtils . checkNotNull ( dataPoints ) ;', 'double objFunction = 0 . 0 ;', 'throw new NumberIsTooSmallException ( fuzzyness , 1 . 0 , false ) ;', 'return fuzzyness ;', 'return points ;', 'private final double epsilon ;', 'double maxMembership = 0 . 0 ;', 'for ( final T point : points ) {', 'private final double fuzzyness ;', 'double difference = 0 . 0 ;', 'return objFunction ;', 'import org . apache . commons . math3 . util . MathArrays ;', 'this . epsilon = epsilon ;', 'clusters = new ArrayList < CentroidCluster < T > > ( ) ;', 'import java . util . Collections ;', 'import java . util . List ;', 'double sum = 0 . 0 ;', 'public FuzzyKMeansClusterer ( final int k , final double fuzzyness ,', 'int iteration = 0 ;', 'private double calculateMaxMembershipChange ( final double [ ] [ ] matrix ) {', 'return clusters ;', 'for ( int i = 0 ; i < k ; i + + ) {', 'private static final double DEFAULT EPSILON = 1e - 3 ;', 'for ( int idx = 0 ; idx < arr . length ; idx + + ) {', 'final int pointDimension = points . get ( 0 ) . getPoint ( ) . length ;', 'private void initializeMembershipMatrix ( ) {', 'arr [ idx ] + = u * pointArr [ idx ] ;', 'private final RandomGenerator random ;', 'this . membershipMatrix = null ;', 'throws NumberIsTooSmallException {', 'maxMembership = membershipMatrix [ i ] [ j ] ;', 'final double distA = FastMath . abs ( distance ( point , clusters . get ( j ) . getCenter ( ) ) ) ;', 'import org . apache . commons . math3 . exception . MathIllegalArgumentException ;', 'import java . util . Collection ;', 'public List < CentroidCluster < T > > cluster ( final Collection < T > dataPoints )', 'clusters . clear ( ) ;', 'import org . apache . commons . math3 . ml . distance . EuclideanDistance ;', 'j + + ;', 'final List < CentroidCluster < T > > newClusters = new ArrayList < CentroidCluster < T > > ( k ) ;', 'throw new NumberIsTooSmallException ( size , k , false ) ;', 'for ( int j = 0 ; j < k ; j + + ) {', 'this ( k , fuzzyness , - 1 , new EuclideanDistance ( ) ) ;', 'import org . apache . commons . math3 . random . JDKRandomGenerator ;', 'updateClusterCenters ( ) ;', 'difference = calculateMaxMembershipChange ( oldMatrix ) ;', 'int j = 0 ;', 'newClusters . add ( new CentroidCluster < T > ( new DoublePoint ( arr ) ) ) ;', 'import org . apache . commons . math3 . linear . MatrixUtils ;', 'do {', 'public double getObjectiveFunctionValue ( ) {', 'private void updateMembershipMatrix ( ) {', 'if ( size < k ) {', 'import org . apache . commons . math3 . linear . RealMatrix ;', 'private final int maxIterations ;', 'for ( int j = 0 ; j < clusters . size ( ) ; j + + ) {', 'final int maxIterations , final DistanceMeasure measure ,', 'final int size = dataPoints . size ( ) ;', '}', 'this . points = null ;', 'System . arraycopy ( membershipMatrix [ i ] , 0 , matrix [ i ] , 0 , clusters . size ( ) ) ;', 'return k ;', 'public class FuzzyKMeansClusterer < T extends Clusterable > extends Clusterer < T > {', 'public FuzzyKMeansClusterer ( final int k , final double fuzzyness ) throws NumberIsTooSmallException {', 'final int max = ( maxIterations < 0 ) ? Integer . MAX VALUE : maxIterations ;', 'if ( membershipMatrix [ i ] [ j ] > maxMembership ) {', 'return MatrixUtils . createRealMatrix ( membershipMatrix ) ;', 'MathArrays . scaleInPlace ( 1 . 0 / sum , arr ) ;', 'super ( measure ) ;', 'maxMembership = FastMath . max ( v , maxMembership ) ;', 'final double distB = FastMath . abs ( distance ( point , c . getCenter ( ) ) ) ;', 'this ( k , fuzzyness , maxIterations , measure , DEFAULT EPSILON , new JDKRandomGenerator ( ) ) ;', 'int i = 0 ;', 'objFunction + = ( dist * dist ) * FastMath . pow ( membershipMatrix [ i ] [ j ] , fuzzyness ) ;', 'package org . apache . commons . math3 . ml . clustering ;', 'final T point = points . get ( i ) ;', 'private void saveMembershipMatrix ( final double [ ] [ ] matrix ) {', 'this . random = random ;', 'return random ;', 'for ( final CentroidCluster < T > c : clusters ) {', 'saveMembershipMatrix ( oldMatrix ) ;', 'public int getK ( ) {', 'public List < CentroidCluster < T > > getClusters ( ) {'}, 'removed_code': set()}"
7117039b146155d81857ec29cc48b64324e5f19c,1.0,COMPRESS - 373 support for writing legacy lzma streams,"{'added_code': {'import java . io . OutputStream ;', 'public void close ( ) throws IOException {', 'import org . tukaani . xz . LZMAOutputStream ;', 'out . finish ( ) ;', 'public class LZMACompressorOutputStream extends CompressorOutputStream {', 'out . flush ( ) ;', '}', 'public void finish ( ) throws IOException {', 'package org . apache . commons . compress . compressors . lzma ;', 'import org . tukaani . xz . LZMA2Options ;', 'import java . io . IOException ;', 'import org . apache . commons . compress . compressors . CompressorOutputStream ;', 'private final LZMAOutputStream out ;', 'public LZMACompressorOutputStream ( final OutputStream outputStream )', 'public void flush ( ) throws IOException {', 'public void write ( final byte [ ] buf , final int off , final int len ) throws IOException {', '@ Override', 'public void write ( final int b ) throws IOException {', 'out . close ( ) ;', 'out . write ( b ) ;', 'out . write ( buf , off , len ) ;', 'throws IOException {', 'out = new LZMAOutputStream ( outputStream , new LZMA2Options ( ) , - 1 ) ;'}, 'removed_code': set()}"
bd2d4a000c4d5b4377e9a28bb225d3f61d45de31,1.0,[ VFS - 544 ] Allow virtual file system to be closed . Renamed map to typeMap . Javadoc fixes .,"{'added_code': {'typeMap . addMimeType ( mimeType , scheme ) ;', 'private VirtualFileProvider vfsProvider ;', 'filesCache = null ;', '}', 'closeComponent ( vfsProvider ) ;', 'private final FileTypeMap typeMap = new FileTypeMap ( ) ;', 'components . clear ( ) ;', 'vfsProvider = new VirtualFileProvider ( ) ;', 'typeMap . addExtension ( extension , scheme ) ;', 'tempFileStore = null ;', 'return typeMap . getScheme ( file ) ! = null ;', 'closeComponent ( filesCache ) ;', 'log . warn ( ""DefaultFilesystemManager . close : not all components are closed : "" + components . toString ( ) ) ;', 'defaultProvider = null ;', 'operationProviders . clear ( ) ;', 'if ( !components . isEmpty ( ) )', 'else if ( filesystem instanceof VirtualFileSystem )', 'vfsProvider . closeFileSystem ( filesystem ) ;', 'closeComponent ( defaultProvider ) ;', 'final String scheme = typeMap . getScheme ( file ) ;', 'fileReplicator = null ;', 'vfsProvider = null ;', 'if ( filesCache = = null )', 'typeMap . clear ( ) ;', '{', 'filesCache = new SoftRefFilesCache ( ) ;'}, 'removed_code': {'filesCache = null ;', '}', 'components . clear ( ) ;', 'return map . getScheme ( file ) ! = null ;', 'private final FileTypeMap map = new FileTypeMap ( ) ;', 'private final VirtualFileProvider vfsProvider = new VirtualFileProvider ( ) ;', 'tempFileStore = null ;', 'map . clear ( ) ;', 'closeComponent ( filesCache ) ;', 'map . addExtension ( extension , scheme ) ;', 'defaultProvider = null ;', 'operationProviders . clear ( ) ;', 'map . addMimeType ( mimeType , scheme ) ;', 'closeComponent ( defaultProvider ) ;', 'final String scheme = map . getScheme ( file ) ;', 'fileReplicator = null ;', 'if ( filesCache = = null )', '{', 'filesCache = new SoftRefFilesCache ( ) ;'}}"
4f72517b0e7881107a0db3046f0247ea2218039d,1.0,Replace direct use of external fields with getter / setter,"{'added_code': {'if ( i1 . getOpcode ( ) = = i2 . getOpcode ( ) ) {', 'return ( ( BranchInstruction ) i1 ) . getTarget ( ) = = ( ( BranchInstruction ) i2 ) . getTarget ( ) ;'}, 'removed_code': {'return ( ( BranchInstruction ) i1 ) . target = = ( ( BranchInstruction ) i2 ) . target ;', 'if ( i1 . opcode = = i2 . opcode ) {'}}"
66b24cabe95485abbe4398ff468a57e5ea0e3cf8,1.0,JCS - 169 ensure access expiry policy is respected binding it on jcs features instead of faking it with createtime,"{'added_code': {'import java . util . Set ;', 'else if ( v ! = null )', 'oldElt ! = null ? oldElt . getElementAttributes ( ) : delegate . getElementAttributes ( ) . clone ( ) ) ;', 'import org . apache . commons . jcs . engine . behavior . ICacheElement ;', 'else', 'import java . util . concurrent . ConcurrentMap ;', 'import java . util . concurrent . Executors ;', 'attrs . setLastAccessTimeNow ( ) ;', 'import java . util . concurrent . ExecutorService ;', 'final IElementAttributes clone = delegate . getElementAttributes ( ) . clone ( ) ;', '}', 'remove ( key ) ;', 'attrs . setTimeFactorForMilliseconds ( 1 ) ;', 'import java . util . Arrays ;', 'import org . apache . commons . jcs . engine . behavior . IElementAttributes ;', 'if ( oldValue . equals ( v ) )', 'import org . apache . commons . jcs . jcache . jmx . JCSCacheStatisticsMXBean ;', 'if ( ElementAttributes . class . isInstance ( copy ) ) {', 'import org . apache . commons . jcs . engine . ElementAttributes ;', 'import org . apache . commons . jcs . engine . CacheElement ;', 'import static org . apache . commons . jcs . jcache . serialization . Serializations . copy ;', 'private ICacheElement < K , V > updateElement ( final K key , final V v , final Duration duration , final IElementAttributes attrs )', 'final ICacheElement < K , V > element = updateElement ( key , v , duration , clone ) ;', 'attrs . setIsEternal ( eternal ) ;', 'import java . io . IOException ;', 'import static org . apache . commons . jcs . jcache . Asserts . assertNotNull ;', 'import java . util . concurrent . ConcurrentHashMap ;', 'if ( duration = = expiryPolicy . getExpiryForAccess ( ) )', 'ElementAttributes . class . cast ( clone ) . setCreateTime ( ) ;', 'import java . io . Closeable ;', 'import java . util . Map ;', 'import java . util . HashMap ;', 'element . setElementAttributes ( attrs ) ;', 'import java . util . Properties ;', 'expiryPolicy . getExpiryForAccess ( ) ;', 'element . getElementAttributes ( ) . setIdleTime ( duration . getTimeUnit ( ) . toMillis ( duration . getDurationAmount ( ) ) ) ;', 'delegate . update ( updateElement ( key , elt . getVal ( ) , expiryForAccess , elt . getElementAttributes ( ) ) ) ;', 'import org . apache . commons . jcs . engine . behavior . IElementSerializer ;', 'import org . apache . commons . jcs . utils . serialization . StandardSerializer ;', 'jcsKey , value , created ? null : duration ,', 'import org . apache . commons . jcs . jcache . jmx . JCSCacheMXBean ;', 'import org . apache . commons . jcs . engine . control . CompositeCache ;', 'import org . apache . commons . jcs . jcache . jmx . JMXs ;', 'import org . apache . commons . jcs . jcache . proxy . ExceptionWrapperHandler ;', 'element . getElementAttributes ( ) . setMaxLife ( duration . getTimeUnit ( ) . toMillis ( duration . getDurationAmount ( ) ) ) ;', '{', 'return true ;', 'import java . util . Iterator ;', 'if ( ElementAttributes . class . isInstance ( clone ) )', 'import org . apache . commons . jcs . jcache . thread . DaemonThreadFactory ;', 'ElementAttributes . class . cast ( copy ) . setCreateTime ( ) ;', 'final ICacheElement < K , V > element = updateElement (', 'import java . util . HashSet ;'}, 'removed_code': {'catch ( final IOException e )', 'import java . util . Set ;', 'import org . apache . commons . jcs . engine . behavior . ICacheElement ;', 'element . setElementAttributes ( copy ) ;', 'import java . util . concurrent . ConcurrentMap ;', 'import java . util . concurrent . Executors ;', 'import java . util . concurrent . ExecutorService ;', '}', 'remove ( key ) ;', 'delegate . update ( updateElement ( key , elt . getVal ( ) , expiryForAccess ) ) ;', 'if ( expiryForAccess ! = null )', 'import java . util . Arrays ;', 'import org . apache . commons . jcs . engine . behavior . IElementAttributes ;', 'final boolean found = v ! = null ;', 'import org . apache . commons . jcs . jcache . jmx . JCSCacheStatisticsMXBean ;', 'final ICacheElement < K , V > element = updateElement ( key , v , duration ) ;', 'import org . apache . commons . jcs . engine . ElementAttributes ;', 'import org . apache . commons . jcs . engine . CacheElement ;', 'import static org . apache . commons . jcs . jcache . serialization . Serializations . copy ;', 'copy . setIsEternal ( eternal ) ;', 'final ICacheElement < K , V > element = updateElement ( jcsKey , value , created ? null : duration ) ;', 'import java . io . IOException ;', 'import static org . apache . commons . jcs . jcache . Asserts . assertNotNull ;', 'import java . util . concurrent . ConcurrentHashMap ;', 'copy . setIdleTime ( duration . getTimeUnit ( ) . toMillis ( duration . getDurationAmount ( ) ) ) ;', 'if ( v . equals ( oldValue ) )', 'import java . io . Closeable ;', 'if ( found )', 'delegate . update ( updateElement ( key , v , expiryForAccess ) ) ;', 'try', 'import java . util . Map ;', 'import java . util . HashMap ;', 'import java . util . Properties ;', 'import org . apache . commons . jcs . engine . behavior . IElementSerializer ;', 'import org . apache . commons . jcs . utils . serialization . StandardSerializer ;', 'private ICacheElement < K , V > updateElement ( final K key , final V v , final Duration duration )', 'throw new CacheException ( e ) ;', 'import org . apache . commons . jcs . jcache . jmx . JCSCacheMXBean ;', 'import org . apache . commons . jcs . engine . control . CompositeCache ;', 'import org . apache . commons . jcs . jcache . jmx . JMXs ;', 'import org . apache . commons . jcs . jcache . proxy . ExceptionWrapperHandler ;', 'final Duration expiryForAccess = expiryPolicy . getExpiryForAccess ( ) ;', 'final IElementAttributes copy = delegate . getElementAttributes ( ) . clone ( ) ;', 'element . getElementAttributes ( ) . setMaxLife ( duration . getTimeUnit ( ) . toMillis ( duration . getDurationAmount ( ) ) ) ;', '{', 'return true ;', 'import java . util . Iterator ;', 'copy . setTimeFactorForMilliseconds ( 1 ) ;', 'import org . apache . commons . jcs . jcache . thread . DaemonThreadFactory ;', 'import java . util . HashSet ;'}}"
dff4cea14174548f52d6fcc66c9bfd7a339b7336,1.0,IVY - 1421 : SSH agent support for SSH and SFTP transports,"{'added_code': {'import com . jcraft . jsch . agentproxy . AgentProxyException ;', 'private boolean attemptAgentUse ( JSch jsch ) {', '} catch ( AgentProxyException e ) {', 'if ( allowedAgentUse ) {', 'import com . jcraft . jsch . agentproxy . Connector ;', 'jsch . setIdentityRepository ( new RemoteIdentityRepository ( con ) ) ;', 'attemptAgentUse ( jsch ) ;', 'throws IOException {', 'File pemFile , String pemPassword , File passFile , boolean allowedAgentUse )', 'try {', 'return true ;', '}', 'return false ;', 'Connector con = ConnectorFactory . getDefault ( ) . createConnector ( ) ;', 'import com . jcraft . jsch . agentproxy . ConnectorFactory ;', 'import com . jcraft . jsch . agentproxy . RemoteIdentityRepository ;', 'Message . verbose ( "" : : SSH : : Failure connecting to agent : : "" + e . toString ( ) ) ;'}, 'removed_code': {'File pemFile , String pemPassword , File passFile ) throws IOException {'}}"
350f01c78374b4df99c1a84cc32122eeeb48b036,1.0,[ COMPRESS - 368 ] Allow compressor extensions through a standard JRE ServiceLoader . Revisit new interface to add decompress until EOF .,"{'added_code': {'return compressorStreamProvider . createCompressorInputStream ( name , in , actualDecompressConcatenated ) ;', 'static void putAll ( final Set < String > names , final CompressorStreamProvider provider ,', 'return createCompressorInputStream ( name , in , decompressConcatenated ) ;', 'for ( final CompressorStreamProvider provider : findCompressorStreamProviders ( ) ) {', 'final TreeMap < String , CompressorStreamProvider > map = new TreeMap < > ( ) ;', 'final TreeMap < String , CompressorStreamProvider > map ) {', 'public CompressorInputStream createCompressorInputStream ( final String name , final InputStream in ,', 'for ( final String name : names ) {', '}', 'return new XZCompressorInputStream ( in , actualDecompressConcatenated ) ;', 'final boolean actualDecompressConcatenated ) throws CompressorException {', '@ Override', 'return new GzipCompressorInputStream ( in , actualDecompressConcatenated ) ;', 'return new BZip2CompressorInputStream ( in , actualDecompressConcatenated ) ;'}, 'removed_code': {'return new XZCompressorInputStream ( in , decompressConcatenated ) ;', 'TreeMap < String , CompressorStreamProvider > map ) {', 'static void putAll ( Set < String > names , CompressorStreamProvider provider ,', 'for ( String name : names ) {', 'return new GzipCompressorInputStream ( in , decompressConcatenated ) ;', 'return compressorStreamProvider . createCompressorInputStream ( name , in ) ;', 'return new BZip2CompressorInputStream ( in , decompressConcatenated ) ;', 'for ( CompressorStreamProvider provider : findCompressorStreamProviders ( ) ) {', 'TreeMap < String , CompressorStreamProvider > map = new TreeMap < > ( ) ;', '@ Override'}}"
f1fc61922c3d8b4aefa26f6f51f0fafd94baf28a,1.0,ignoring CacheValue for key parameters,"{'added_code': {'final CacheInvocationParameter [ ] parametersAsArray = new CacheInvocationParameter [ indexes = = null ? args . length : indexes . length ] ;', 'final Class < ? > [ ] parameterTypes = getMethod ( ) . getParameterTypes ( ) ;', 'else', 'final Object [ ] args = delegate . getParameters ( ) ;', 'final Annotation [ ] annotations , final int i ) {', '}', 'return new CacheInvocationParameterImpl ( type , arg , new HashSet < Annotation > ( asList ( annotations ) ) , i ) ;', 'final Annotation [ ] [ ] parameterAnnotations = getMethod ( ) . getParameterAnnotations ( ) ;', 'if ( indexes = = null )', 'for ( int idx = 0 ; idx < indexes . length ; idx + + )', 'protected CacheInvocationParameter [ ] doGetAllParameters ( final Integer [ ] indexes )', 'return parametersAsArray ;', 'parameters = doGetAllParameters ( null ) ;', 'for ( int i = 0 ; i < args . length ; i + + )', 'import java . lang . annotation . Annotation ;', 'private CacheInvocationParameterImpl newCacheInvocationParameterImpl ( final Class < ? > type , final Object arg ,', 'parametersAsArray [ i ] = newCacheInvocationParameterImpl ( parameterTypes [ i ] , args [ i ] , parameterAnnotations [ i ] , i ) ;', '{', 'final int i = indexes [ idx ] ;', 'import java . util . HashSet ;'}, 'removed_code': {'import java . lang . annotation . Annotation ;', 'parameters = new CacheInvocationParameter [ args . length ] ;', 'final Class < ? > [ ] parameterTypes = getMethod ( ) . getParameterTypes ( ) ;', 'final Annotation [ ] [ ] parameterAnnotations = getMethod ( ) . getParameterAnnotations ( ) ;', 'final Object [ ] args = delegate . getParameters ( ) ;', '{', '}', 'parameters [ i ] = new CacheInvocationParameterImpl ( parameterTypes [ i ] , args [ i ] , new HashSet < Annotation > ( asList ( parameterAnnotations [ i ] ) ) , i ) ;', 'for ( int i = 0 ; i < args . length ; i + + )', 'import java . util . HashSet ;'}}"
2282c22c5b252859b459cc2474350fbaf2a588e9,1.0,"PARQUET - 389 : Support predicate push down on missing columns . Predicate push - down will complain when predicates reference columns that aren't in a file's schema . This makes it difficult to implement predicate push - down in engines where schemas evolve because each task needs to process the predicates and prune references to columns not in that task's file . This PR implements predicate evaluation for missing columns , where the values are all null . This allows engines to pass predicates as they are written . A future commit should rewrite the predicates to avoid the extra work currently done in record - level filtering , but that isn't included here because it is an optimization . Author : Ryan Blue < blue @ apache . org > Closes #354 from rdblue / PARQUET - 389 - predicate - push - down - on - missing - columns and squashes the following commits : b4d809a [ Ryan Blue ] PARQUET - 389 : Support record - level filtering with missing columns . 91b841c [ Ryan Blue ] PARQUET - 389 : Add missing column support to StatisticsFilter . 275f950 [ Ryan Blue ] PARQUET - 389 : Add missing column support to DictionaryFilter .","{'added_code': {'if ( value ! = null ) {', 'if ( meta = = null ) {', '}', 'if ( hasNulls ( meta ) ) {', 'private static final boolean BLOCK CANNOT MATCH = true ;', 'ColumnChunkMetaData meta = getColumnChunk ( filterColumn . getColumnPath ( ) ) ;', 'T value = gtEq . getValue ( ) ;', 'if ( value = = null ) {', 'Statistics < T > stats = meta . getStatistics ( ) ;', 'return BLOCK MIGHT MATCH ;', 'return isAllNulls ( meta ) ;', 'T value = gt . getValue ( ) ;', 'T value = ltEq . getValue ( ) ;', 'T value = lt . getValue ( ) ;', 'return !hasNulls ( meta ) ;', 'return BLOCK CANNOT MATCH ;', 'if ( isAllNulls ( meta ) ) {', 'private static final boolean BLOCK MIGHT MATCH = false ;', 'return columns . get ( columnPath ) ;', '@ SuppressWarnings ( ""unchecked"" )'}, 'removed_code': {'ColumnChunkMetaData columnChunk = getColumnChunk ( filterColumn . getColumnPath ( ) ) ;', 'return c ;', 'if ( isAllNulls ( columnChunk ) ) {', 'return !hasNulls ( columnChunk ) ;', 'ColumnChunkMetaData c = columns . get ( columnPath ) ;', 'T value = lt . getValue ( ) ;', 'return true ;', 'return isAllNulls ( columnChunk ) ;', 'return false ;', 'if ( hasNulls ( columnChunk ) ) {', 'Statistics < T > stats = columnChunk . getStatistics ( ) ;', 'T value = gt . getValue ( ) ;', 'T value = gtEq . getValue ( ) ;', 'checkArgument ( c ! = null , ""Column "" + columnPath . toDotString ( ) + "" not found in schema!"" ) ;', 'T value = ltEq . getValue ( ) ;'}}"
21fb80f02c177a99cccd69899703424eab803c34,1.0,PropertiesConfigurationLayout no longer reacts on RELOAD events . Because PropertiesConfiguration no longer extends AbstractFileConfiguration such events will never be fired .,"{'added_code': {'if ( !event . isBeforeUpdate ( ) )'}, 'removed_code': {'if ( event . isBeforeUpdate ( ) )', 'else', 'clear ( ) ;', '{', '}', 'if ( AbstractFileConfiguration . EVENT RELOAD = = event . getType ( ) )'}}"
8262a735578ad84638e36c8597ea55a91dca4bfa,1.0,[ DIGESTER - 154 ] The DigesterBinder is not able to load primitive classes by name,"{'added_code': {'}', 'import java . util . Collections ;', 'return PRIMITIVE TYPES . get ( name ) ;', 'package org . apache . commons . digester3 . binder ;', 'primitiveTypes . put ( ""long"" , long . class ) ;', 'primitiveTypes . put ( ""double"" , double . class ) ;', 'HashMap < String , Class < ? > > primitiveTypes = new HashMap < String , Class < ? > > ( ) ;', 'public BinderClassLoader ( ClassLoader adaptedClassLoader )', 'return adaptedClassLoader ;', 'primitiveTypes . put ( ""byte"" , byte . class ) ;', 'primitiveTypes . put ( ""boolean"" , boolean . class ) ;', 'this . adaptedClassLoader = adaptedClassLoader ;', 'return adaptedClassLoader . loadClass ( name ) ;', 'final class BinderClassLoader', 'private final ClassLoader adaptedClassLoader ;', 'throws ClassNotFoundException', 'primitiveTypes . put ( ""char"" , char . class ) ;', 'import java . util . Map ;', 'import java . util . HashMap ;', 'PRIMITIVE TYPES = Collections . unmodifiableMap ( primitiveTypes ) ;', 'static', 'protected synchronized Class < ? > loadClass ( String name , boolean resolve )', 'private static final Map < String , Class < ? > > PRIMITIVE TYPES ;', '@ Override', 'public ClassLoader getAdaptedClassLoader ( )', 'primitiveTypes . put ( ""int"" , int . class ) ;', '{', 'primitiveTypes . put ( ""short"" , short . class ) ;', 'if ( PRIMITIVE TYPES . containsKey ( name ) )', 'extends ClassLoader', 'primitiveTypes . put ( ""float"" , float . class ) ;'}, 'removed_code': set()}"
c3f8825c6b07812567c37c2901fd13851154ae85,1.0,TrackedNodeModel now requires an InMemoryNodeModelSupport object . Access to the underlying model is now indirect . This caused some adaptations in multiple hierarchical configuration classes . Because access to the model is now guarded by the Synchronizer the remaining failing test for CombinedConfiguration is running now .,"{'added_code': {'public InMemoryNodeModel getNodeModel ( )', 'return getParent ( ) . getNodeModel ( ) ;', '{', '}', 'return new TrackedNodeModel ( getParent ( ) , getRootSelector ( ) , true ) ;', '@ Override'}, 'removed_code': {'return new TrackedNodeModel ( parentModel , getRootSelector ( ) , true ) ;'}}"
9ff7ca5e6079b51ffc3c1bd93380db8f5dbc6e86,1.0,NET - 507 Option to disable private IP replacement in FTP passive mode .,"{'added_code': {'""Could not parse passive host information . \\ nServer Reply : "" + reply ) ;', 'throw new MalformedServerReplyException (', 'if ( !remote . isSiteLocalAddress ( ) ) {', 'InetAddress remote = getRemoteAddress ( ) ;', 'String hostAddress = remote . getHostAddress ( ) ;', 'this . passiveNatWorkaround = enabled ;', 'try {', 'InetAddress host = InetAddress . getByName ( passiveHost ) ;', '}', '} catch ( UnknownHostException e ) {', 'fireReplyReceived ( 0 ,', 'public void setPassiveNatWorkaround ( boolean enabled ) {', 'passiveHost = hostAddress ;', 'private boolean passiveNatWorkaround = true ;', 'if ( passiveNatWorkaround ) {', 'if ( host . isSiteLocalAddress ( ) ) {', '"" [ Replacing site local address "" + passiveHost + "" with "" + hostAddress + "" ] \\ n"" ) ;'}, 'removed_code': {'""Could not parse passive host information . \\ nServer Reply : "" + reply ) ;', 'throw new MalformedServerReplyException (', 'if ( !remote . isSiteLocalAddress ( ) ) {', 'InetAddress remote = getRemoteAddress ( ) ;', 'try {', 'InetAddress host = InetAddress . getByName ( passiveHost ) ;', '} catch ( UnknownHostException e ) {', 'fireReplyReceived ( 0 ,', 'passiveHost = hostAddress ;', 'String hostAddress = remote . getHostAddress ( ) ;', 'if ( host . isSiteLocalAddress ( ) ) {', '"" [ Replacing site local address "" + passiveHost + "" with "" + hostAddress + "" ] \\ n"" ) ;'}}"
8ade49c09a726757d9a479f0a310d77d79d6819f,1.0,NET - 621 SubnetUtils#SubnetInfo - remove unnecessary accessors,"{'added_code': {'return ( isInclusiveHostCount ( ) ? broadcast :', 'return format ( toArray ( broadcast ) ) ;', 'return format ( toArray ( netmask ) ) ;', 'format ( toArray ( netmask ) )', 'return format ( toArray ( address ) ) ;', 'format ( toArray ( address ) ) ,', 'broadcastLong ( ) - networkLong ( ) > 1 ? network + 1 : 0 ) ;', 'broadcastLong ( ) - networkLong ( ) > 1 ? broadcast - 1 : 0 ) ;', 'return ( isInclusiveHostCount ( ) ? network :', 'return format ( toArray ( network ) ) ;'}, 'removed_code': {'return format ( toArray ( netmask ( ) ) ) ;', 'return ( isInclusiveHostCount ( ) ? network ( ) :', 'broadcastLong ( ) - networkLong ( ) > 1 ? broadcast ( ) - 1 : 0 ) ;', 'private int network ( ) { return network ; }', 'private int address ( ) { return address ; }', 'return ( isInclusiveHostCount ( ) ? broadcast ( ) :', 'return format ( toArray ( address ( ) ) ) ;', 'format ( toArray ( netmask ( ) ) )', 'format ( toArray ( address ( ) ) ) ,', 'broadcastLong ( ) - networkLong ( ) > 1 ? network ( ) + 1 : 0 ) ;', 'return format ( toArray ( broadcast ( ) ) ) ;', 'private int broadcast ( ) { return broadcast ; }', 'return format ( toArray ( network ( ) ) ) ;', 'private int netmask ( ) { return netmask ; }'}}"
8e0e1c32ff1ed1da4f09fc9917812e6457e6fef7,1.0,IVY - 1141 : dependencies failed using branch attribute ( and extra attributes ) Thanks to Stephen Haberman,"{'added_code': {'boolean sameBranch = ( askedBranch = = null ) ? foundBranch = = null', 'String foundBranch = foundMD . getModuleRevisionId ( ) . getBranch ( ) ;', 'String askedBranch = askedMrid . getBranch ( ) ;', ': askedBranch . equals ( foundBranch ) ;', 'if ( askedMrid . getBranch ( ) ! = null ) {', 'return true ;', '}', 'if ( !sameBranch ) {', 'return false ;', 'List < Status > statuses = StatusManager . getCurrent ( ) . getStatuses ( ) ;'}, 'removed_code': {'List statuses = StatusManager . getCurrent ( ) . getStatuses ( ) ;'}}"
210ecb5015a870f2501ed23eb7a896dfcfa981dc,1.0,Made CombinedConfigurationBuilder more extensible .,"{'added_code': {'private final Collection < ConfigurationBuilder < ? extends Configuration > > allBuilders ;', 'new LinkedList < ConfigurationBuilder < ? extends Configuration > > ( ) ;', 'return sourceData . getChildBuilders ( ) ;', 'return new FileBasedConfigurationBuilder < XMLConfiguration > (', 'allBuilders . add ( builder ) ;', 'BuilderParameters builderParams )', '{', '}', 'return allBuilders ;', 'allBuilders =', 'protected ConfigurationBuilder < ? extends HierarchicalConfiguration > createXMLDefinitionBuilder (', 'protected Collection < ConfigurationBuilder < ? extends Configuration > > getChildBuilders ( )', 'for ( ConfigurationBuilder < ? > b : getChildBuilders ( ) )', 'XMLConfiguration . class ) . configure ( builderParams ) ;', 'public Collection < ConfigurationBuilder < ? extends Configuration > > getChildBuilders ( )'}, 'removed_code': {'for ( ConfigurationBuilder < ? > b : namedBuilders . values ( ) )', 'return new FileBasedConfigurationBuilder < XMLConfiguration > (', 'BuilderParameters builderParams )', '{', '}', 'private static ConfigurationBuilder < ? extends HierarchicalConfiguration > createXMLDefinitionBuilder (', 'XMLConfiguration . class ) . configure ( builderParams ) ;'}}"
34074f97a0a0572518c8736a30f017563cd7e9b3,1.0,NET - 604 TFTP send & receive don't have progress indication,"{'added_code': {'totalBytesReceived = 0 ;', 'private long totalBytesSent = 0 ;', 'totalBytesReceived + = dataLength ;', '}', 'return totalBytesSent ;', 'public long getTotalBytesReceived ( ) {', 'return totalBytesReceived ;', 'public long getTotalBytesSent ( ) {', 'private long totalBytesReceived = 0 ;', 'totalBytesSent = 0L ;', 'totalBytesSent + = totalThisPacket ;'}, 'removed_code': set()}"
ad443210312d2420efef6d03a0296d71e71feb22,1.0,PARQUET - 297 : generate Version class using parquet - generator Author : Konstantin Shaposhnikov < Konstantin . Shaposhnikov @ sc . com > Author : Konstantin Shaposhnikov < k . shaposhnikov @ gmail . com > Closes #213 from kostya - sh / PARQUET - 297 2 and squashes the following commits : ddb469a [ Konstantin Shaposhnikov ] add comment about paddedByteCountFromBits coming from ByteUtils 6b47b04 [ Konstantin Shaposhnikov ] Change VersionGenerator to generate main ( ) method 10d0b38 [ Konstantin Shaposhnikov ] PARQUET - 297 : generate Version class using parquet - generator 11d29bc [ Konstantin Shaposhnikov ] parquet - generator : remove dependency on parquet - common,"{'added_code': {'add ( ""public class Version { \\ n"" ) ;', 'import java . io . InputStream ;', 'props . load ( in ) ;', 'add ( "" \\ "" ; \\ n \\ n"" ) ;', 'srcFile = srcFile . getAbsoluteFile ( ) ;', '"" * This class is auto - generated by { @ link org . apache . parquet . version . VersionGenerator } \\ n"" +', '}', 'import java . io . File ;', 'writer . close ( ) ;', 'Properties props = new Properties ( ) ;', 'if ( !parent . mkdirs ( ) ) {', 'public VersionGenerator ( File file ) throws IOException {', 'add ( ""package org . apache . parquet ; \\ n"" +', 'private final FileWriter writer ;', 'add ( "" System . out . println ( FULL VERSION ) ; \\ n"" ) ;', 'if ( in = = null ) {', 'import java . io . IOException ;', '"" / * * \\ n"" +', 'File srcFile = new File ( args [ 0 ] + "" / org / apache / parquet / Version . java"" ) ;', 'add ( "" public static final String FULL VERSION = \\ """" ) ;', 'new VersionGenerator ( srcFile ) . run ( ) ;', 'writer . write ( s ) ;', 'add ( "" public static void main ( String [ ] args ) { \\ n"" ) ;', 'throw new IOException ( "" / parquet - version . properties not found"" ) ;', 'add ( "" public static final String VERSION NUMBER = \\ """" ) ;', 'if ( !parent . exists ( ) ) {', 'import java . util . Properties ;', 'throw new IOException ( ""Couldn\'t mkdirs for "" + parent ) ;', 'InputStream in = VersionGenerator . class . getResourceAsStream ( "" / parquet - version . properties"" ) ;', 'import java . io . FileWriter ;', '"" * / \\ n"" ) ;', 'public static void main ( String [ ] args ) throws IOException {', '"" \\ n"" +', 'public class VersionGenerator {', 'private void add ( String s ) throws IOException {', '"" * Do not manually edit! \\ n"" +', 'File parent = srcFile . getParentFile ( ) ;', 'this . writer = new FileWriter ( file ) ;', 'add ( props . getProperty ( ""fullVersion"" ) ) ;', 'add ( props . getProperty ( ""versionNumber"" ) ) ;', 'package org . apache . parquet . version ;', 'add ( "" } \\ n"" ) ;', 'public void run ( ) throws IOException {', 'add ( "" \\ "" ; \\ n"" ) ;'}, 'removed_code': set()}"
516c38fd95fff30841f9af370f50cf1f7733c209,1.0,"Changed ZipArchiveEntry to use more optimized data structure for an overall performance improvement of about 10 % for the use case ""many small files"" , for instance a jar file . LinkedHashMap was not a very good structure for such small lists and performs badly in terms of locality","{'added_code': {'getAllExtraFields ( ) :', 'return getUnparseableOnly ( ) ;', 'extraFields = newFields . toArray ( new ZipExtraField [ newFields . size ( ) ] ) ;', 'extraFields = newResult . toArray ( new ZipExtraField [ newResult . size ( ) ] ) ;', 'extraFields [ 0 ] = ze ;', '} else {', 'zipExtraFields [ zipExtraFields . length ] = unparseableExtra ;', 'e . setExtraFields ( getAllExtraFieldsNoCopy ( ) ) ;', '}', 'return includeUnparseable ?', 'super . setExtra ( ExtraFieldUtils . mergeLocalFileDataData ( getAllExtraFieldsNoCopy ( ) ) ) ;', 'if ( !type . equals ( extraField . getHeaderId ( ) ) ) {', 'if ( copy ! = null ) {', 'private ZipExtraField [ ] getMergedFields ( ) {', 'extraFields = zipExtraFields ;', 'final ZipExtraField [ ] allExtraFieldsNoCopy = getAllExtraFieldsNoCopy ( ) ;', 'for ( ZipExtraField extraField : extraFields ) {', 'newResult . add ( extraField ) ;', 'return ( allExtraFieldsNoCopy = = extraFields ) ? copyOf ( allExtraFieldsNoCopy ) : allExtraFieldsNoCopy ;', 'return zipExtraFields ;', 'ZipExtraField [ ] copy = extraFields ;', 'private ZipExtraField [ ] getAllExtraFields ( ) {', 'return extraFields ;', 'final ZipExtraField [ ] parseableExtraFields = getParseableExtraFields ( ) ;', 'if ( extraFields . length = = newResult . size ( ) ) {', 'System . arraycopy ( copy , 0 , extraFields , 1 , extraFields . length - 1 ) ;', 'return extraField ;', 'return unparseableExtra = = null ? noExtraFields : new ZipExtraField [ ] { unparseableExtra } ;', 'List < ZipExtraField > newFields = new ArrayList < ZipExtraField > ( ) ;', 'private ZipExtraField [ ] getUnparseableOnly ( ) {', 'private ZipExtraField [ ] extraFields ;', 'if ( extraFields = = null ) {', 'int newLen = extraFields ! = null ? extraFields . length + 1 : 1 ;', 'return noExtraFields ;', 'return Arrays . copyOf ( src , src . length ) ;', 'if ( getExtraField ( ze . getHeaderId ( ) ) ! = null ) {', 'newFields . add ( field ) ;', 'extraFields = new ZipExtraField [ ] { ze } ;', 'setExtraFields ( getAllExtraFieldsNoCopy ( ) ) ;', 'if ( type . equals ( extraField . getHeaderId ( ) ) ) {', 'final ZipExtraField [ ] zipExtraFields = Arrays . copyOf ( extraFields , extraFields . length + 1 ) ;', 'return ExtraFieldUtils . mergeCentralDirectoryData ( getAllExtraFieldsNoCopy ( ) ) ;', 'return unparseableExtra ! = null ? getMergedFields ( ) : extraFields ;', 'return Arrays . copyOf ( parseableExtraFields , parseableExtraFields . length ) ;', '& & !name . contains ( "" / "" ) ) {', 'removeExtraField ( ze . getHeaderId ( ) ) ;', 'List < ZipExtraField > newResult = new ArrayList < ZipExtraField > ( ) ;', 'private static final ZipExtraField [ ] noExtraFields = new ZipExtraField [ 0 ] ;', 'private ZipExtraField [ ] getAllExtraFieldsNoCopy ( ) {', 'private ZipExtraField [ ] getParseableExtraFields ( ) {', 'zipExtraFields [ zipExtraFields . length - 1 ] = ze ;', 'extraFields = new ZipExtraField [ newLen ] ;', 'getParseableExtraFields ( ) ;', 'private ZipExtraField [ ] copyOf ( ZipExtraField [ ] src ) {'}, 'removed_code': {'return !includeUnparseable | | unparseableExtra = = null', 'extraFields . putAll ( copy ) ;', 'List < ZipExtraField > result =', 'if ( extraFields . remove ( type ) = = null ) {', 'extraFields = new LinkedHashMap < ZipShort , ZipExtraField > ( ) ;', 'if ( copy ! = null ) {', 'LinkedHashMap < ZipShort , ZipExtraField > copy = extraFields ;', 'e . setExtraFields ( getExtraFields ( true ) ) ;', 'return extraFields . get ( type ) ;', 'return ExtraFieldUtils . mergeCentralDirectoryData ( getExtraFields ( true ) ) ;', ': new ZipExtraField [ ] { unparseableExtra } ;', 'return result . toArray ( new ZipExtraField [ result . size ( ) ] ) ;', 'result . add ( unparseableExtra ) ;', 'extraFields . put ( ze . getHeaderId ( ) , ze ) ;', 'private LinkedHashMap < ZipShort , ZipExtraField > extraFields = null ;', '& & name . indexOf ( "" / "" ) = = - 1 ) {', 'super . setExtra ( ExtraFieldUtils . mergeLocalFileDataData ( getExtraFields ( true ) ) ) ;', 'if ( includeUnparseable & & unparseableExtra ! = null ) {', 'return getExtraFields ( false ) ;', 'setExtraFields ( entry . getExtraFields ( true ) ) ;', 'import java . util . LinkedHashMap ;', 'extraFields . put ( field . getHeaderId ( ) , field ) ;', 'new ArrayList < ZipExtraField > ( extraFields . values ( ) ) ;', '? new ZipExtraField [ 0 ]', 'copy . remove ( ze . getHeaderId ( ) ) ;'}}"
5bdd4dc1c46eb4949be1a41161ed12aac21b2add,1.0,CombinedConfigurationBuilder now creates child builders at a later stage . This makes it possible to enable enhanced interpolation in the definition configuration .,"{'added_code': {'decl . getName ( ) , decl . getAt ( ) ) ;', 'ConfigurationBuilder < ? extends Configuration > builder )', 'ConfigurationDeclaration decl =', 'catch ( ConfigurationException cex )', 'for ( ConfigurationBuilder < ? > b : namedBuilders . values ( ) )', 'else', 'builder . addBuilderListener ( changeListener ) ;', 'providerForTag ( src . getRootElementName ( ) ) ;', 'overrideBuilders . addAll ( config . childConfigurationsAt ( KEY OVERRIDE ) ) ;', 'if ( sourceData = = null )', '}', '( AbstractConfiguration ) builder . getConfiguration ( ) ,', 'overrideBuilders . addAll ( fetchTopLevelOverrideConfigs ( config ) ) ;', 'public Collection < SubnodeConfiguration > getUnionSources ( )', 'throw new ConfigurationException ( ""Information about child builders""', 'if ( !data . getUnionSources ( ) . isEmpty ( ) )', 'ConfigurationBuilder < ? extends Configuration > builder =', 'data . createAndAddConfigurations ( addConfig , data . getUnionSources ( ) ) ;', 'if ( provider = = null )', 'addChildConfiguration ( ccResult , decl , builder ) ;', 'Collection < SubnodeConfiguration > srcDecl )', 'for ( HierarchicalConfiguration src : srcDecl )', 'unionBuilders . addAll ( config . childConfigurationsAt ( KEY UNION ) ) ;', 'HierarchicalConfiguration src , ConfigurationDeclaration decl )', 'if ( decl . getName ( ) ! = null )', 'private ConfigurationBuilder < ? extends Configuration > createConfigurationBuilder (', 'return Collections . emptySet ( ) ;', 'new ConfigurationDeclaration (', 'createBuilderChangeListener ( ) ;', 'throws ConfigurationException', '""Unsupported configuration source : ""', 'throw cex ;', 'if ( !decl . isOptional ( ) )', 'ConfigurationDeclaration decl ,', 'CombinedConfigurationBuilder . this , src ) ;', 'createConfigurationBuilder ( src , decl ) ;', 'public Collection < SubnodeConfiguration > getOverrideSources ( )', 'private void addChildConfiguration ( CombinedConfiguration ccResult ,', 'private void createBuilderChangeListener ( )', 'return Collections . unmodifiableSet ( sourceData . builderNames ( ) ) ;', 'public void createAndAddConfigurations ( CombinedConfiguration ccResult ,', 'try', 'data . createAndAddConfigurations ( result , data . getOverrideSources ( ) ) ;', 'sourceData . getNamedBuilder ( name ) ;', 'ccResult . addConfiguration (', 'throw new ConfigurationException (', '+ src . getRootElementName ( ) ) ;', 'namedBuilders . put ( decl . getName ( ) , builder ) ;', 'new LinkedList < SubnodeConfiguration > ( ) ;', 'ConfigurationBuilderProvider provider =', 'return builder ;', 'provider . getConfigurationBuilder ( decl ) ;', 'private final Collection < SubnodeConfiguration > unionBuilders ;', '{', 'private final Collection < SubnodeConfiguration > overrideBuilders ;', 'namedBuilders . clear ( ) ;', '+ "" has not been setup yet! Call getConfiguration ( ) first . "" ) ;'}, 'removed_code': {'decl . getName ( ) , decl . getAt ( ) ) ;', 'private static void createAndAddConfigurations ( CombinedConfiguration cc ,', 'b . addBuilderListener ( changeListener ) ;', 'ConfigurationDeclaration decl =', 'catch ( ConfigurationException cex )', 'Collection < ? extends HierarchicalConfiguration > sources )', 'private final Collection < ConfigurationBuilder < ? extends Configuration > > overrideBuilders ;', 'providerForTag ( src . getRootElementName ( ) ) ;', 'for ( ConfigurationBuilder < ? extends Configuration > builder : builders )', '}', '( AbstractConfiguration ) builder . getConfiguration ( ) ,', '+ src . getRootElementName ( ) ) ;', 'if ( !data . getUnionBuilders ( ) . isEmpty ( ) )', 'assert decl ! = null : ""Cannot resolve builder!"" ;', 'ConfigurationBuilder < ? extends Configuration > builder =', 'public ConfigurationDeclaration getDeclaration (', 'createAndAddConfigurations ( addConfig , data . getUnionBuilders ( ) , data ) ;', 'new HashMap < ConfigurationBuilder < ? extends Configuration > , ConfigurationDeclaration > ( ) ;', 'if ( provider = = null )', 'public Collection < ConfigurationBuilder < ? extends Configuration > > getOverrideBuilders ( )', 'private final Collection < ConfigurationBuilder < ? extends Configuration > > allBuilders ;', 'allBuilders . addAll ( unionBuilders ) ;', 'private final Map < ConfigurationBuilder < ? extends Configuration > , ConfigurationDeclaration > declarations ;', 'if ( decl . getName ( ) ! = null )', 'cc . addConfiguration (', 'ConfigurationBuilder < ? > builder )', 'return Collections . unmodifiableSet ( getSourceData ( ) . builderNames ( ) ) ;', 'new ConfigurationDeclaration (', 'throws ConfigurationException', 'ConfigurationDeclaration decl = srcData . getDeclaration ( builder ) ;', '""Unsupported configuration source : ""', 'throw cex ;', 'if ( !decl . isOptional ( ) )', 'CombinedConfigurationBuilder . this , src ) ;', 'new LinkedList < ConfigurationBuilder < ? extends Configuration > > ( ) ;', 'for ( HierarchicalConfiguration src : sources )', 'try', 'allBuilders . addAll ( overrideBuilders ) ;', 'private final Collection < ConfigurationBuilder < ? extends Configuration > > unionBuilders ;', 'builders . add ( builder ) ;', 'config . childConfigurationsAt ( KEY OVERRIDE ) ) ;', 'fetchTopLevelOverrideConfigs ( config ) ) ;', 'createBuilders ( overrideBuilders ,', 'throw new ConfigurationException (', 'getSourceData ( ) . getNamedBuilder ( name ) ;', 'declarations . put ( builder , decl ) ;', 'Collection < ConfigurationBuilder < ? extends Configuration > > builders ,', 'namedBuilders . put ( decl . getName ( ) , builder ) ;', 'public Collection < ConfigurationBuilder < ? extends Configuration > > getUnionBuilders ( )', 'registerChangeListener ( ) ;', 'createBuilders ( unionBuilders ,', 'allBuilders =', 'declarations =', 'private void registerChangeListener ( )', 'ConfigurationBuilderProvider provider =', 'createAndAddConfigurations ( result , data . getOverrideBuilders ( ) , data ) ;', 'provider . getConfigurationBuilder ( decl ) ;', 'return declarations . get ( builder ) ;', 'for ( ConfigurationBuilder < ? > b : allBuilders )', 'config . childConfigurationsAt ( KEY UNION ) ) ;', 'ConfigurationSourceData srcData ) throws ConfigurationException', '{', 'private void createBuilders ('}}"
043a39baa8befc916faa0d4cca714b9fef2c19b3,1.0,VALIDATOR - 376 Revert the default behavior to the state prior to VALIDATOR - 273 .,"{'added_code': {'private static final EmailValidator EMAIL VALIDATOR WITH TLD = new EmailValidator ( false , true ) ;', '} else {', 'private static final EmailValidator EMAIL VALIDATOR WITH LOCAL = new EmailValidator ( true , false ) ;', 'public static EmailValidator getInstance ( boolean allowLocal , boolean allowTld ) {', '}', 'return getInstance ( allowLocal , false ) ;', 'this . allowLocal = allowLocal ;', 'protected EmailValidator ( boolean allowLocal , boolean allowTld ) {', 'if ( allowTld ) {', 'private final boolean allowTld ;', 'return EMAIL VALIDATOR ;', 'this . allowTld = allowTld ;', 'return EMAIL VALIDATOR WITH LOCAL ;', 'return EMAIL VALIDATOR WITH LOCAL WITH TLD ;', 'public static EmailValidator getInstance ( boolean allowLocal ) {', 'this . allowTld = false ;', 'return domainValidator . isValid ( domain ) | | domainValidator . isValidTld ( domain ) ;', 'super ( ) ;', 'return domainValidator . isValid ( domain ) ;', 'private static final EmailValidator EMAIL VALIDATOR WITH LOCAL WITH TLD = new EmailValidator ( true , true ) ;', 'return EMAIL VALIDATOR WITH TLD ;', 'private static final EmailValidator EMAIL VALIDATOR = new EmailValidator ( false , false ) ;'}, 'removed_code': {'public static EmailValidator getInstance ( boolean allowLocal ) {', 'private static final EmailValidator EMAIL VALIDATOR WITH LOCAL = new EmailValidator ( true ) ;', 'return EMAIL VALIDATOR ;', 'domainValidator . isValidTld ( domain ) ;', 'return EMAIL VALIDATOR WITH LOCAL ;', 'return domainValidator . isValid ( domain ) | |', 'private static final EmailValidator EMAIL VALIDATOR = new EmailValidator ( false ) ;'}}"
12d7f3d204a242de56a5a94ea8371bd3f9717504,1.0,Refactor the closing of DelegatingConnection and sub - classes to correctly handle closing and passivation of connections when one DelegatingConnection wraps another . The problem was discovered while exploring some refactoring options and is now tested using the additional unit test .,"{'added_code': {'( ( ResultSet ) trace ) . close ( ) ;', '}', '} else if ( trace instanceof ResultSet ) {', 'if ( trace instanceof Statement ) {', 'protected final Connection getDelegateInternal ( ) {', 'passivate ( ) ;', 'super . close ( ) ;', 'Object trace = traceIter . next ( ) ;', 'Iterator < AbandonedTrace > traceIter = traces . iterator ( ) ;', '} finally {', 'List < AbandonedTrace > traces = getTrace ( ) ;', '( ( Statement ) trace ) . close ( ) ;', 'conn . close ( ) ;', 'closed = true ;', 'clearTrace ( ) ;', 'if ( traces ! = null ) {', 'try {', 'setLastUsed ( 0 ) ;', 'while ( traceIter . hasNext ( ) ) {'}, 'removed_code': {'delegate . close ( ) ;', '( ( ResultSet ) trace ) . close ( ) ;', '}', 'if ( trace instanceof Statement ) {', 'protected Connection getDelegateInternal ( ) {', 'finally {', '} else if ( trace instanceof ResultSet ) {', 'passivate ( ) ;', '( ( DelegatingConnection ) conn ) . passivate ( ) ;', 'Object trace = traceIter . next ( ) ;', 'Iterator < AbandonedTrace > traceIter = traces . iterator ( ) ;', 'List < AbandonedTrace > traces = getTrace ( ) ;', '( ( Statement ) trace ) . close ( ) ;', 'conn . close ( ) ;', 'closed = true ;', 'clearTrace ( ) ;', 'if ( traces ! = null ) {', 'try {', 'getDelegateInternal ( ) . close ( ) ;', 'setLastUsed ( 0 ) ;', 'if ( conn instanceof DelegatingConnection ) {', 'while ( traceIter . hasNext ( ) ) {'}}"
5e305c6a2c7d0e3d2dfc9c07a702167f55944373,1.0,"NET - 514 IMAP APPEND multiple issues in IMapClient . Deprecated unusable append methods . Added new append method , as well as example IMapImportMbox class to make use of it .","{'added_code': {'return doCommand ( IMAPCommand . APPEND , args . toString ( ) ) ;', 'args . append ( DQUOTE ) . append ( datetime ) . append ( DQUOTE ) ;', '@ Deprecated', '} else {', '}', 'final int status = sendCommand ( IMAPCommand . APPEND , args . toString ( ) ) ;', 'private static final char DQUOTE = \'""\' ;', '& & IMAPReply . isSuccess ( sendData ( message ) ) ;', ""args . append ( ' { ' ) . append ( message . length ( ) ) . append ( ' } ' ) ;"", 'if ( message . startsWith ( DQUOTE S ) & & message . endsWith ( DQUOTE S ) ) {', 'args . append ( "" "" ) . append ( flags ) ;', 'if ( flags ! = null ) {', 'private static final String DQUOTE S = "" \\ """" ;', 'StringBuilder args = new StringBuilder ( mailboxName ) ;', 'args . append ( datetime ) ;', 'args . append ( "" "" ) ;', 'if ( datetime . charAt ( 0 ) = = DQUOTE ) {', 'args . append ( message ) ;', 'if ( datetime ! = null ) {', '{', 'public boolean append ( String mailboxName , String flags , String datetime , String message ) throws IOException', 'return IMAPReply . isContinuation ( status )'}, 'removed_code': set()}"
10a33f30954af3ca26ffd8eeaab1081cb0e8a360,1.0,Set correct generic type parameters in CombinedConfigurationBuilder . A ClassCastException was thrown in the tests because results of configurationsAt ( ) were cast to SubnodeConfigurations . The definition configuration can now have an arbitrary node type .,"{'added_code': {'HierarchicalConfiguration < ? > defConfig , Configuration resultConfig )', 'private HierarchicalConfiguration < ? > definitionConfiguration ;', 'for ( Iterator < ? extends HierarchicalConfiguration < ? > > it =', 'HierarchicalConfiguration < ? > config )', 'public Collection < HierarchicalConfiguration < ? > > getOverrideSources ( )', 'private List < ? extends HierarchicalConfiguration < ? > > fetchTopLevelOverrideConfigs (', 'protected ConfigurationBuilder < ? extends HierarchicalConfiguration < ? > > createXMLDefinitionBuilder (', 'HierarchicalConfiguration < ? > defConfig , String key )', 'private final Collection < HierarchicalConfiguration < ? > > overrideBuilders ;', 'protected HierarchicalConfiguration < ? > getDefinitionConfiguration ( )', 'List < ? extends HierarchicalConfiguration < ? > > configs =', 'HierarchicalConfiguration < ? > config ) throws ConfigurationException', 'protected FileSystem initFileSystem ( HierarchicalConfiguration < ? > config )', 'Collection < HierarchicalConfiguration < ? > > srcDecl )', 'public synchronized ConfigurationBuilder < ? extends HierarchicalConfiguration < ? > > getDefinitionBuilder ( )', 'new LinkedList < HierarchicalConfiguration < ? > > ( ) ;', 'protected ConfigurationBuilder < ? extends HierarchicalConfiguration < ? > > setupDefinitionBuilder (', 'for ( HierarchicalConfiguration < ? > config : nodes )', 'for ( String element : CONFIG SECTIONS )', 'HierarchicalConfiguration < ? > src , ConfigurationDeclaration decl )', 'configs . iterator ( ) ; it . hasNext ( ) ; )', 'List < ? extends HierarchicalConfiguration < ? > > nodes =', 'protected void configureEntityResolver ( HierarchicalConfiguration < ? > config ,', 'public Collection < HierarchicalConfiguration < ? > > getUnionSources ( )', 'private void registerConfiguredProviders ( HierarchicalConfiguration < ? > defConfig )', 'final ConfigurationBuilder < ? extends HierarchicalConfiguration < ? > > defBuilder )', '{', 'ConfigurationBuilder < ? extends HierarchicalConfiguration < ? > > defBuilder =', 'HierarchicalConfiguration < ? > config = getDefinitionConfiguration ( ) ;', 'for ( HierarchicalConfiguration < ? > src : srcDecl )', 'protected void initSystemProperties ( HierarchicalConfiguration < ? > config ,', 'private ConfigurationBuilder < ? extends HierarchicalConfiguration < ? > > definitionBuilder ;', 'private final Collection < HierarchicalConfiguration < ? > > unionBuilders ;'}, 'removed_code': {'HierarchicalConfiguration config = getDefinitionConfiguration ( ) ;', 'for ( Iterator < SubnodeConfiguration > it = configs . iterator ( ) ; it', 'HierarchicalConfiguration config ) throws ConfigurationException', 'protected ConfigurationBuilder < ? extends HierarchicalConfiguration > createXMLDefinitionBuilder (', 'private void registerConfiguredProviders ( HierarchicalConfiguration defConfig )', 'protected ConfigurationBuilder < ? extends HierarchicalConfiguration > setupDefinitionBuilder (', 'public Collection < SubnodeConfiguration > getUnionSources ( )', 'ConfigurationBuilder < ? extends HierarchicalConfiguration > defBuilder =', 'public synchronized ConfigurationBuilder < ? extends HierarchicalConfiguration > getDefinitionBuilder ( )', 'Collection < SubnodeConfiguration > srcDecl )', 'for ( HierarchicalConfiguration src : srcDecl )', 'protected FileSystem initFileSystem ( HierarchicalConfiguration config )', 'HierarchicalConfiguration src , ConfigurationDeclaration decl )', 'for ( SubnodeConfiguration config : nodes )', 'private HierarchicalConfiguration definitionConfiguration ;', 'public Collection < SubnodeConfiguration > getOverrideSources ( )', 'private List < SubnodeConfiguration > fetchTopLevelOverrideConfigs (', 'protected void configureEntityResolver ( HierarchicalConfiguration config ,', 'List < SubnodeConfiguration > configs =', 'List < SubnodeConfiguration > nodes =', 'private ConfigurationBuilder < ? extends HierarchicalConfiguration > definitionBuilder ;', 'new LinkedList < SubnodeConfiguration > ( ) ;', ';', '. hasNext ( ) ; )', 'protected void initSystemProperties ( HierarchicalConfiguration config ,', 'private final Collection < SubnodeConfiguration > unionBuilders ;', 'protected HierarchicalConfiguration getDefinitionConfiguration ( )', 'import org . apache . commons . configuration . SubnodeConfiguration ;', 'private final Collection < SubnodeConfiguration > overrideBuilders ;', 'HierarchicalConfiguration config )', 'HierarchicalConfiguration defConfig , Configuration resultConfig )', 'for ( String element : CONFIG SECTIONS ) {', 'HierarchicalConfiguration defConfig , String key )', 'final ConfigurationBuilder < ? extends HierarchicalConfiguration > defBuilder )'}}"
8267561e52a02bf9faf70a24484aac105cdcc9d0,1.0,GORA - 471 Datastore for Infinispan,"{'added_code': {'toPut . put ( key , val ) ;', 'public Configuration getConf ( ) {', 'conf = new Configuration ( ) ;', 'import org . slf4j . LoggerFactory ;', 'cacheExists = false ;', 'public boolean containsKey ( K key ) {', 'public void dropCache ( ) {', 'return ;', 'this . persistentClass = persistentClass ;', 'throw new RuntimeException ( e ) ;', 'private RemoteCacheManager cacheManager ;', 'public BasicCache < K , T > getCache ( ) {', 'ConfigurationBuilder builder = new ConfigurationBuilder ( ) ;', 'import java . util . Map ;', 'private boolean cacheExists ;', 'cacheManager . stop ( ) ;', 'this . keyClass = keyClass ;', 'private RemoteCache < K , T > cache ;', 'import org . slf4j . Logger ;', 'private Configuration conf ;', 'properties . setProperty ( ISPN CONNECTION STRING KEY , host ) ;', 'toPut = new HashMap < > ( ) ;', 'cache . clear ( ) ;', 'public void createCache ( ) {', 'LOG . debug ( ""close ( ) "" ) ;', 'cacheExists = true ;', 'private Class < T > persistentClass ;', 'cache . remove ( key ) ;', 'import org . infinispan . commons . api . BasicCache ;', 'conf . set ( ISPN CONNECTION STRING KEY , host ) ;', 'public static final String ISPN CONNECTION STRING KEY = ""infinispan . connectionstring"" ;', 'return this . persistentClass . getSimpleName ( ) ;', 'return conf ;', 'toPut . clear ( ) ;', 'public synchronized void put ( K key , T val ) {', 'public synchronized void initialize ( Class < K > keyClass , Class < T > persistentClass , Properties properties ) throws Exception {', 'public class InfinispanClient < K , T extends PersistentBase > implements Configurable {', 'import org . infinispan . avro . client . Support ;', 'public void setConf ( Configuration conf ) {', 'public InfinispanClient ( ) {', 'public void flush ( ) {', 'public static final String ISPN CONNECTION STRING DEFAULT = ""127 . 0 . 0 . 1 : 11222"" ;', 'public void deleteByKey ( K key ) {', 'getCache ( ) . stop ( ) ;', 'import org . infinispan . client . hotrod . configuration . ConfigurationBuilder ;', 'Marshaller < T > marshaller = new Marshaller < T > ( persistentClass ) ;', 'if ( cache! = null )', 'this . conf = conf ;', 'LOG . info ( ""Connecting client to "" + host ) ;', 'private Map < K , T > toPut ;', 'return cache . containsKey ( key ) ;', 'builder . addServers ( host ) ;', 'public T get ( K key ) {', 'import org . infinispan . client . hotrod . RemoteCache ;', '} catch ( InstantiationException | IllegalAccessException e ) {', 'private Class < K > keyClass ;', 'cacheManager . start ( ) ;', 'cache = cacheManager . getCache ( persistentClass . getSimpleName ( ) ) ;', 'import org . infinispan . avro . hotrod . QueryBuilder ;', 'public void putIfAbsent ( K key , T obj ) {', 'Support . registerSchema ( cacheManager , persistentClass . newInstance ( ) . getSchema ( ) ) ;', 'builder . marshaller ( marshaller ) ;', 'import org . infinispan . avro . client . Marshaller ;', 'public void createSchema ( ) {', 'return this . cache ;', 'flush ( ) ;', 'import java . util . HashMap ;', 'try {', 'import org . infinispan . client . hotrod . RemoteCacheManager ;', '@ Override', 'import org . apache . gora . persistency . impl . PersistentBase ;', 'public QueryBuilder getQueryBuilder ( ) {', 'package org . apache . gora . infinispan . store ;', 'import org . apache . hadoop . conf . Configuration ;', 'return cache . get ( key ) ;', 'getConf ( ) . get ( ISPN CONNECTION STRING KEY , ISPN CONNECTION STRING DEFAULT ) ) ;', 'String host = properties . getProperty ( ISPN CONNECTION STRING KEY ,', 'return ( QueryBuilder ) qf . from ( persistentClass ) ;', 'cacheManager = new RemoteCacheManager ( builder . build ( ) ) ;', '}', 'public boolean cacheExists ( ) {', 'import org . infinispan . avro . hotrod . QueryFactory ;', 'LOG . debug ( ""flush ( ) "" ) ;', 'import org . apache . hadoop . conf . Configurable ;', 'this . cache . putIfAbsent ( key , obj ) ;', 'createSchema ( ) ;', 'public String getCacheName ( ) {', 'return cacheExists ;', 'private QueryFactory qf ;', 'import java . util . Properties ;', 'public static final Logger LOG = LoggerFactory . getLogger ( InfinispanClient . class ) ;', 'public synchronized void close ( ) {', 'if ( !toPut . isEmpty ( ) ) cache . putAll ( toPut ) ;', 'qf = org . infinispan . avro . hotrod . Search . getQueryFactory ( cache ) ;'}, 'removed_code': set()}"
7e35f57ae9ba9e716da122dfa0bec418b1e2b6e8,1.0,COMPRESS - 327 write zip archives to arbitrary SeekableByteChannels,"{'added_code': {'} else if ( channel = = null ) {', 'import java . nio . file . StandardOpenOption ;', '& & channel ! = null & & mode ! = Zip64Mode . Never ) ;', '}', 'import java . nio . file . Files ;', '+ nameLen + 2 * SHORT ) ;', 'final long save = channel . position ( ) ;', 'channel = Files . newByteChannel ( file . toPath ( ) ,', 'SeekableByteChannel channel = null ;', 'private final SeekableByteChannel channel ;', 'StandardOpenOption . TRUNCATE EXISTING ) ) ;', 'if ( channel ! = null ) {', 'channel = null ;', 'return zipMethod = = DEFLATED & & channel = = null ;', 'streamCompressor = streamCompressor ;', 'channel . close ( ) ;', 'channel = channel ;', 'return channel ! = null ;', 'streamCompressor = StreamCompressor . create ( channel , def ) ;', 'EnumSet . of ( StandardOpenOption . CREATE , StandardOpenOption . WRITE ,', 'out = null ;', 'channel . position ( entry . localDataStart - 5 * SHORT ) ;', 'IOUtils . closeQuietly ( channel ) ;', 'this . channel = channel ;', 'if ( entry . entry . getMethod ( ) = = STORED & & channel = = null ) {', 'channel . position ( save ) ;', 'channel . position ( entry . localDataStart + 3 * WORD + 2 * SHORT', 'import java . util . EnumSet ;', 'public ZipArchiveOutputStream ( SeekableByteChannel channel ) throws IOException {', '} else if ( zipMethod = = DEFLATED | | channel ! = null ) {', 'this . channel = null ;', 'channel . position ( entry . localDataStart ) ;', 'if ( !phased & & channel ! = null ) {', 'if ( ze . getMethod ( ) ! = DEFLATED | | channel ! = null ) {', 'StreamCompressor streamCompressor = null ;', 'StandardOpenOption . READ ,', 'streamCompressor = StreamCompressor . create ( o , def ) ;', 'import java . nio . channels . SeekableByteChannel ;', 'def = new Deflater ( level , true ) ;', '| | channel ! = null'}, 'removed_code': {'} else if ( zipMethod = = DEFLATED | | raf ! = null ) {', 'import java . io . RandomAccessFile ;', 'raf = new RandomAccessFile ( file , ""rw"" ) ;', 'if ( ze . getMethod ( ) ! = DEFLATED | | raf ! = null ) {', '+ nameLen + 2 * SHORT ) ;', 'raf . seek ( entry . localDataStart + 3 * WORD + 2 * SHORT', 'return zipMethod = = DEFLATED & & raf = = null ;', 'private final RandomAccessFile raf ;', 'if ( entry . entry . getMethod ( ) = = STORED & & raf = = null ) {', 'RandomAccessFile raf = null ;', 'raf . seek ( entry . localDataStart ) ;', '& & raf ! = null & & mode ! = Zip64Mode . Never ) ;', 'if ( raf ! = null ) {', 'final long save = raf . getFilePointer ( ) ;', 'raf . seek ( entry . localDataStart - 5 * SHORT ) ;', 'raf = null ;', 'raf . setLength ( 0 ) ;', 'raf = raf ;', 'raf . seek ( save ) ;', 'this . raf = null ;', 'return raf ! = null ;', 'if ( !phased & & raf ! = null ) {', 'raf . close ( ) ;', 'IOUtils . closeQuietly ( raf ) ;', '| | raf ! = null', 'def = new Deflater ( level , true ) ;', 'streamCompressor = StreamCompressor . create ( raf , def ) ;', '} else if ( raf = = null ) {'}}"
dfecbe970917754511a081f8b86efac211e624f6,1.0,Introduce some more local variables to make the code better readable,"{'added_code': {'return new Locale ( language , country ) ;', 'isNumericAreaCode ( country ) ) {', 'variant . length ( ) > 0 ) {', 'return new Locale ( language , country , variant ) ;', 'final String country = segments [ 1 ] ;', 'if ( segments . length = = 2 ) {', '} else if ( segments . length = = 3 ) {', 'if ( isISO639LanguageCode ( language ) & & isISO3166CountryCode ( country ) | |', 'final String variant = segments [ 2 ] ;', '( country . length ( ) = = 0 | | isISO3166CountryCode ( country ) ) & &'}, 'removed_code': {'final int segmentCount = segments . length - 1 ;', 'segments [ 2 ] . length ( ) > 0 ) {', 'return new Locale ( language , segments [ 1 ] , segments [ 2 ] ) ;', 'if ( isISO639LanguageCode ( language ) & & isISO3166CountryCode ( segments [ 1 ] ) | |', 'if ( segmentCount = = 1 ) {', '} else if ( segmentCount = = 2 ) {', 'isNumericAreaCode ( segments [ 1 ] ) ) {', '( segments [ 1 ] . length ( ) = = 0 | | isISO3166CountryCode ( segments [ 1 ] ) ) & &', 'return new Locale ( language , segments [ 1 ] ) ;'}}"
0efde604a26e730631ae8bece0d1e137dfcfb5ca,1.0,Added a specialized combined configuration builder with reloading support .,"{'added_code': {'public synchronized ReloadingController getReloadingController ( )', 'import org . apache . commons . configuration . builder . BuilderParameters ;', 'getDefinitionBuilder ( ) ;', 'Collection < ReloadingController > subControllers , Object builder )', 'import org . apache . commons . configuration . reloading . ReloadingControllerSupport ;', 'subControllers . add ( ( ( ReloadingControllerSupport ) builder )', 'reloadingController = createReloadingController ( ) ;', 'protected void initResultInstance ( CombinedConfiguration result )', '. getReloadingController ( ) ) ;', '}', 'import java . util . LinkedList ;', 'protected ConfigurationBuilder < ? extends HierarchicalConfiguration > createXMLDefinitionBuilder (', 'obtainReloadingController ( subControllers , b ) ;', 'CombinedConfigurationBuilder implements ReloadingControllerSupport', 'ConfigurationBuilder < ? extends HierarchicalConfiguration > defBuilder =', 'public class ReloadingCombinedConfigurationBuilder extends', 'new LinkedList < ReloadingController > ( ) ;', 'public ReloadingCombinedConfigurationBuilder ( Map < String , Object > params ,', 'import org . apache . commons . configuration . ConfigurationException ;', 'BuilderParameters builderParams )', 'super . initResultInstance ( result ) ;', 'for ( ConfigurationBuilder < ? extends Configuration > b : getChildBuilders ( ) )', 'boolean allowFailOnInit )', 'package org . apache . commons . configuration . builder . combined ;', 'throws ConfigurationException', 'import org . apache . commons . configuration . Configuration ;', 'import org . apache . commons . configuration . HierarchicalConfiguration ;', 'import java . util . Map ;', 'private ReloadingController reloadingController ;', 'super ( params , allowFailOnInit ) ;', 'import org . apache . commons . configuration . reloading . ReloadingController ;', 'import java . util . Collection ;', 'protected ReloadingController createReloadingController ( )', 'return reloadingController ;', 'obtainReloadingController ( subControllers , defBuilder ) ;', 'Collection < ReloadingController > subControllers =', '@ Override', 'import org . apache . commons . configuration . builder . ReloadingFileBasedConfigurationBuilder ;', 'super ( ) ;', 'if ( builder instanceof ReloadingControllerSupport )', 'return new CombinedReloadingController ( subControllers ) ;', 'import org . apache . commons . configuration . CombinedConfiguration ;', 'public static void obtainReloadingController (', 'import org . apache . commons . configuration . builder . ConfigurationBuilder ;', 'public ReloadingCombinedConfigurationBuilder ( Map < String , Object > params )', 'super ( params ) ;', '{', 'public ReloadingCombinedConfigurationBuilder ( )', 'import org . apache . commons . configuration . reloading . CombinedReloadingController ;', 'import org . apache . commons . configuration . XMLConfiguration ;', 'return new ReloadingFileBasedConfigurationBuilder < XMLConfiguration > (', 'XMLConfiguration . class ) . configure ( builderParams ) ;'}, 'removed_code': set()}"
edbd9842cfca892b10c2e9c8da0384fe005cd67a,1.0,Restore binary compartibility,"{'added_code': {'protected FastDateParser ( final String pattern , final TimeZone timeZone , final Locale locale ) {', '}', 'this ( pattern , timeZone , locale , null ) ;'}, 'removed_code': set()}"
364232f781d0cc91cd4b83012e1f49e62fa81190,1.0,Restores type parameter in NameFinder This closes #34 See issue OPENNLP - 719,"{'added_code': {'private void overrideDefaultType ( Span [ ] names ) {', 'Span [ ] names = sample . getNames ( ) ;', 'String outcomes [ ] = codec . encode ( names , sample . getSentence ( ) . length ) ;', 'for ( int i = 0 ; i < names . length ; i + + ) {', 'names [ i ] = new Span ( n . getStart ( ) , n . getEnd ( ) , this . defaultType ,', 'if ( Objects . isNull ( n . getType ( ) ) ) {', 'if ( !Objects . isNull ( this . defaultType ) ) {', 'overrideDefaultType ( names ) ;', '}', 'private final String defaultType ;', 'Span n = names [ i ] ;', 'import java . util . Objects ;', 'this . defaultType = type ;', 'n . getProb ( ) ) ;', 'List < Event > events = new ArrayList < > ( outcomes . length ) ;', 'public NameFinderEventStream ( ObjectStream < NameSample > dataStream , String type , NameContextGenerator contextGenerator , SequenceCodec < String > codec ) {'}, 'removed_code': {'else', 'if ( type ! = null )', 'String type1 ;', 'String outcomes [ ] = codec . encode ( sample . getNames ( ) , sample . getSentence ( ) . length ) ;', 'type1 = type ;', 'List < Event > events = new ArrayList < Event > ( outcomes . length ) ;', 'public NameFinderEventStream ( ObjectStream < NameSample > dataStream , String type , NameContextGenerator contextGenerator , SequenceCodec codec ) {', 'type1 = ""default"" ;'}}"
caa82d3e1b0019b373c55c23168bb8c007fd6100,1.0,Replace all magic string with constants ( except error keys into the message table ) . Order all members . Change some variable names ( e . g . o - > obj ) . Add missing @ Override .,"{'added_code': {'if ( obj = = null | | this . getClass ( ) ! = obj . getClass ( ) )', 'public static final ProxyType PROXY HTTP = new ProxyType ( ""http"" ) ;', 'this . setParam ( opts , IDENTITIES , identityFiles ) ;', '. equals ( HOST KEY CHECK YES ) ) )', 'this . setParam ( opts , TIMEOUT , timeout ) ;', 'public int compareTo ( final ProxyType pType )', 'return this . proxyType . compareTo ( pType . proxyType ) ;', 'this . setParam ( opts , PREFERRED AUTHENTICATIONS , preferredAuthentications ) ;', 'this . setParam ( opts , STRICT HOST KEY CHECKING , hostKeyChecking ) ;', 'this . setParam ( opts , KNOWN HOSTS , sshdir ) ;', 'this . setParam ( opts , UserInfo . class . getName ( ) , info ) ;', 'public String getStrictHostKeyChecking ( final FileSystemOptions opts )', 'public UserInfo getUserInfo ( final FileSystemOptions opts )', 'return this . getInteger ( opts , PROXY PORT , 0 ) ;', 'public void setIdentities ( final FileSystemOptions opts , final File . . . identityFiles ) throws FileSystemException', 'this . setParam ( opts , COMPRESSION , compression ) ;', 'return ( String ) this . getParam ( opts , PREFERRED AUTHENTICATIONS ) ;', 'private static final String PROXY TYPE = PREFIX + "" . PROXY TYPE"" ;', 'if ( this . proxyType ! = null ? !this . proxyType . equals ( pType . proxyType ) : pType . proxyType ! = null )', 'public void setUserDirIsRoot ( final FileSystemOptions opts , final boolean userDirIsRoot )', 'if ( this = = obj )', 'private static final String PROXY HOST = PREFIX + "" . PROXY HOST"" ;', 'public boolean equals ( final Object obj )', 'public String getProxyHost ( final FileSystemOptions opts )', 'private static final String PREFERRED AUTHENTICATIONS = PREFIX + "" . PREFERRED AUTHENTICATIONS"" ;', 'public File getKnownHosts ( final FileSystemOptions opts )', 'this . setParam ( opts , PROXY PORT , Integer . valueOf ( proxyPort ) ) ;', 'return ( ProxyType ) this . getParam ( opts , PROXY TYPE ) ;', 'public String getCompression ( final FileSystemOptions opts )', 'protected Class < ? extends FileSystem > getConfigClass ( )', 'public File [ ] getIdentities ( final FileSystemOptions opts )', 'this . setParam ( opts , USER DIR IS ROOT , userDirIsRoot ? Boolean . TRUE : Boolean . FALSE ) ;', 'public void setStrictHostKeyChecking ( final FileSystemOptions opts , final String hostKeyChecking )', 'public void setKnownHosts ( final FileSystemOptions opts , final File sshdir ) throws FileSystemException', 'throw new FileSystemException ( ""vfs . provider . sftp / StrictHostKeyChecking - arg . error"" , hostKeyChecking ) ;', 'this . setParam ( opts , PROXY TYPE , proxyType ) ;', '{', 'public String getPreferredAuthentications ( final FileSystemOptions opts )', 'private static final String COMPRESSION = PREFIX + ""COMPRESSION"" ;', '| | ( !hostKeyChecking . equals ( HOST KEY CHECK ASK ) & & !hostKeyChecking . equals ( HOST KEY CHECK NO ) & & !hostKeyChecking', 'public void setProxyPort ( final FileSystemOptions opts , final int proxyPort )', 'return ( UserInfo ) this . getParam ( opts , UserInfo . class . getName ( ) ) ;', 'public Boolean getUserDirIsRoot ( final FileSystemOptions opts )', 'return SftpFileSystem . class ;', 'private static final String USER DIR IS ROOT = PREFIX + "" . USER DIR IS ROOT"" ;', 'private SftpFileSystemConfigBuilder ( )', 'private static final String TIMEOUT = PREFIX + "" . TIMEOUT"" ;', 'public Integer getTimeout ( final FileSystemOptions opts )', 'return this . getString ( opts , PROXY HOST ) ;', 'private static final SftpFileSystemConfigBuilder BUILDER = new SftpFileSystemConfigBuilder ( ) ;', 'public void setProxyType ( final FileSystemOptions opts , final ProxyType proxyType )', 'public void setPreferredAuthentications ( final FileSystemOptions opts , final String preferredAuthentications )', '@ Override', 'private static final String PROXY PORT = PREFIX + "" . PROXY PORT"" ;', 'private static final String HOST KEY CHECK NO = ""no"" ;', 'return ( File ) this . getParam ( opts , KNOWN HOSTS ) ;', 'return this . getBoolean ( opts , USER DIR IS ROOT , Boolean . TRUE ) ;', 'this . setParam ( opts , PROXY HOST , proxyHost ) ;', 'public int getProxyPort ( final FileSystemOptions opts )', 'public void setProxyHost ( final FileSystemOptions opts , final String proxyHost )', 'public static SftpFileSystemConfigBuilder getInstance ( )', 'return this . getInteger ( opts , TIMEOUT ) ;', 'return BUILDER ;', 'public void setUserInfo ( final FileSystemOptions opts , final UserInfo info )', 'return this . getString ( opts , COMPRESSION ) ;', 'public void setTimeout ( final FileSystemOptions opts , final Integer timeout )', 'final ProxyType pType = ( ProxyType ) obj ;', '}', 'private static final String HOST KEY CHECK YES = ""yes"" ;', 'if ( hostKeyChecking = = null', 'private static final String HOST KEY CHECK ASK = ""ask"" ;', 'private static final String STRICT HOST KEY CHECKING = PREFIX + "" . STRICT HOST KEY CHECKING"" ;', 'return ( File [ ] ) this . getParam ( opts , IDENTITIES ) ;', 'private static final String KNOWN HOSTS = PREFIX + "" . KNOWN HOSTS"" ;', 'public void setCompression ( final FileSystemOptions opts , final String compression ) throws FileSystemException', 'throws FileSystemException', 'public static final ProxyType PROXY SOCKS5 = new ProxyType ( ""socks"" ) ;', 'return this . getString ( opts , STRICT HOST KEY CHECKING , HOST KEY CHECK NO ) ;', 'private static final String PREFIX = SftpFileSystemConfigBuilder . class . getName ( ) ;', 'return this . proxyType . hashCode ( ) ;', 'super ( ""sftp . "" ) ;', 'private static final String IDENTITIES = PREFIX + "" . IDENTITIES"" ;', 'public ProxyType getProxyType ( final FileSystemOptions opts )'}, 'removed_code': {'setParam ( opts , ""proxyPort"" , Integer . valueOf ( proxyPort ) ) ;', 'public String getCompression ( FileSystemOptions opts )', 'return BUILDER ;', 'public void setUserDirIsRoot ( FileSystemOptions opts , boolean userDirIsRoot )', 'if ( proxyType ! = null ? !proxyType . equals ( proxyType1 . proxyType ) : proxyType1 . proxyType ! = null )', 'public void setIdentities ( FileSystemOptions opts , File [ ] identities ) throws FileSystemException', 'public void setKnownHosts ( FileSystemOptions opts , File sshdir ) throws FileSystemException', '}', 'public File [ ] getIdentities ( FileSystemOptions opts )', 'public void setProxyPort ( FileSystemOptions opts , int proxyPort )', 'public static final ProxyType PROXY HTTP = new ProxyType ( ""http"" ) ;', 'private static final String TIMEOUT = SftpFileSystemConfigBuilder . class . getName ( ) + "" . TIMEOUT"" ;', 'public void setUserInfo ( FileSystemOptions opts , UserInfo info )', 'public Boolean getUserDirIsRoot ( FileSystemOptions opts )', 'setParam ( opts , ""proxyType"" , proxyType ) ;', 'public void setTimeout ( FileSystemOptions opts , Integer timeout )', 'public void setStrictHostKeyChecking ( FileSystemOptions opts , String hostKeyChecking ) throws FileSystemException', 'return getInteger ( opts , ""proxyPort"" , 0 ) ;', 'return SftpFileSystem . class ;', '!hostKeyChecking . equals ( ""yes"" ) ) )', 'setParam ( opts , ""proxyHost"" , proxyHost ) ;', 'return getString ( opts , ""proxyHost"" ) ;', 'public String getPreferredAuthentications ( FileSystemOptions opts )', 'return ( ProxyType ) getParam ( opts , ""proxyType"" ) ;', 'public Integer getTimeout ( FileSystemOptions opts )', 'return ( File ) getParam ( opts , ""knownHosts"" ) ;', 'ProxyType proxyType1 = ( ProxyType ) o ;', 'setParam ( opts , USER DIR IS ROOT , userDirIsRoot ? Boolean . TRUE : Boolean . FALSE ) ;', 'public File getKnownHosts ( FileSystemOptions opts )', 'if ( this = = o )', 'setParam ( opts , ""StrictHostKeyChecking"" , hostKeyChecking ) ;', 'return getInteger ( opts , TIMEOUT ) ;', 'private SftpFileSystemConfigBuilder ( )', 'setParam ( opts , ""knownHosts"" , sshdir ) ;', 'setParam ( opts , UserInfo . class . getName ( ) , info ) ;', 'public int compareTo ( ProxyType o )', 'public void setPreferredAuthentications ( FileSystemOptions opts , String preferredAuthentications )', 'return ( UserInfo ) getParam ( opts , UserInfo . class . getName ( ) ) ;', 'if ( o = = null | | getClass ( ) ! = o . getClass ( ) )', 'public void setCompression ( FileSystemOptions opts , String compression ) throws FileSystemException', 'return getString ( opts , ""compression"" ) ;', 'setParam ( opts , ""PreferredAuthentications"" , preferredAuthentications ) ;', 'setParam ( opts , ""compression"" , compression ) ;', 'public boolean equals ( Object o )', 'private static final String USER DIR IS ROOT = SftpFileSystemConfigBuilder . class . getName ( ) + "" . USER DIR IS ROOT"" ;', 'protected Class < ? extends FileSystem > getConfigClass ( )', 'return ( String ) getParam ( opts , ""PreferredAuthentications"" ) ;', 'private static final SftpFileSystemConfigBuilder BUILDER = new SftpFileSystemConfigBuilder ( ) ;', 'setParam ( opts , TIMEOUT , timeout ) ;', 'public ProxyType getProxyType ( FileSystemOptions opts )', 'public int getProxyPort ( FileSystemOptions opts )', 'setParam ( opts , ""identities"" , identities ) ;', 'return getBoolean ( opts , USER DIR IS ROOT , Boolean . TRUE ) ;', 'return proxyType . hashCode ( ) ;', 'public String getStrictHostKeyChecking ( FileSystemOptions opts )', 'return ( File [ ] ) getParam ( opts , ""identities"" ) ;', 'public String getProxyHost ( FileSystemOptions opts )', 'public static final ProxyType PROXY SOCKS5 = new ProxyType ( ""socks"" ) ;', 'public void setProxyType ( FileSystemOptions opts , ProxyType proxyType )', '@ Override', 'throw new FileSystemException ( ""vfs . provider . sftp / StrictHostKeyChecking - arg . error"" , hostKeyChecking ) ;', 'return proxyType . compareTo ( o . proxyType ) ;', 'public void setProxyHost ( FileSystemOptions opts , String proxyHost )', '{', 'super ( ""sftp . "" ) ;', 'return getString ( opts , ""StrictHostKeyChecking"" , ""no"" ) ;', 'public static SftpFileSystemConfigBuilder getInstance ( )', 'if ( hostKeyChecking = = null | | ( !hostKeyChecking . equals ( ""ask"" ) & & !hostKeyChecking . equals ( ""no"" ) & &', 'public UserInfo getUserInfo ( FileSystemOptions opts )'}}"
4dc97b64005f0083b2facaa70f661138a4fa3fc0,1.0,[ IO - 505 ] Deprecated of all IOUtils . closeQuietly ( ) methods and use try - with - resources internally .,"{'added_code': {'if ( in ! = null ) {', ': new InputStreamReader ( new FileInputStream ( file1 ) , charsetName ) ;', 'public static void writeStringToFile ( final File file , final String data , final Charset encoding ,', '}', 'try ( OutputStream out = openOutputStream ( file , append ) ) {', 'InputStream input2 = new FileInputStream ( file2 ) ) {', 'Reader input2 = charsetName = = null', 'try ( OutputStream out = new BufferedOutputStream ( openOutputStream ( file , append ) ) ) {', 'FileOutputStream fos = new FileOutputStream ( destFile ) ;', 'FileChannel input = fis . getChannel ( ) ;', 'FileChannel output = fos . getChannel ( ) ) {', 'try ( InputStream in = source ;', 'ex . addSuppressed ( e ) ;', 'try ( InputStream in = source ) {', '} catch ( final IOException | RuntimeException ex ) {', 'final boolean append ) throws IOException {', 'try ( InputStream in = openInputStream ( file ) ) {', ': new InputStreamReader ( new FileInputStream ( file2 ) , charsetName ) ) {', 'in . close ( ) ;', 'IOUtils . writeLines ( lines , lineEnding , out , encoding ) ;', 'try ( InputStream in = new CheckedInputStream ( new FileInputStream ( file ) , checksum ) ) {', 'try ( FileInputStream fis = new FileInputStream ( srcFile ) ;', '? new InputStreamReader ( new FileInputStream ( file2 ) , Charset . defaultCharset ( ) )', 'try ( InputStream input1 = new FileInputStream ( file1 ) ;', 'try {', 'openOutputStream ( file ) . close ( ) ;', '? new InputStreamReader ( new FileInputStream ( file1 ) , Charset . defaultCharset ( ) )', 'catch ( final IOException e ) {', 'OutputStream out = openOutputStream ( destination ) ) {', 'copyToFile ( in , destination ) ;', 'IOUtils . copy ( in , out ) ;', 'try ( Reader input1 = charsetName = = null'}, 'removed_code': {'FileOutputStream out = null ;', 'final OutputStream out = openOutputStream ( file ) ;', 'Reader input2 = null ;', 'public static void writeStringToFile ( final File file , final String data , final Charset encoding , final boolean', 'input1 = new InputStreamReader ( new FileInputStream ( file1 ) , Charset . defaultCharset ( ) ) ;', 'output . close ( ) ;', '} else {', 'input2 = new InputStreamReader ( new FileInputStream ( file2 ) , Charset . defaultCharset ( ) ) ;', '}', 'append ) throws IOException {', 'final FileOutputStream output = openOutputStream ( destination ) ;', '} catch ( final RuntimeException ex ) {', 'IOUtils . closeQuietly ( in ) ;', 'InputStream input2 = null ;', 'IOUtils . copy ( source , output ) ;', 'fos = new FileOutputStream ( destFile ) ;', 'FileChannel input = null ;', 'fos . close ( ) ;', 'fos = null ;', 'if ( charsetName = = null ) {', 'fis = null ;', 'IOUtils . closeQuietly ( input1 ) ;', '} finally {', 'fis . close ( ) ;', 'input = fis . getChannel ( ) ;', 'InputStream in = null ;', 'input = null ;', 'input1 = new FileInputStream ( file1 ) ;', 'IOUtils . closeQuietly ( output ) ;', 'IOUtils . writeLines ( lines , lineEnding , buffer , encoding ) ;', 'IOUtils . closeQuietly ( input2 ) ;', 'input2 = new InputStreamReader ( new FileInputStream ( file2 ) , charsetName ) ;', 'final BufferedOutputStream buffer = new BufferedOutputStream ( out ) ;', 'throw ex ;', 'InputStream input1 = null ;', 'in = openInputStream ( file ) ;', 'copyToFile ( source , destination ) ;', 'try {', 'FileInputStream fis = null ;', 'Reader input1 = null ;', 'FileChannel output = null ;', 'OutputStream out = null ;', 'IOUtils . closeQuietly ( source ) ;', 'output = fos . getChannel ( ) ;', 'input1 = new InputStreamReader ( new FileInputStream ( file1 ) , charsetName ) ;', 'IOUtils . closeQuietly ( output , fos , input , fis ) ;', 'out . close ( ) ;', 'IOUtils . closeQuietly ( out ) ;', '} catch ( final IOException ex ) {', 'buffer . flush ( ) ;', 'input2 = new FileInputStream ( file2 ) ;', 'output = null ;', 'input . close ( ) ;', 'out = openOutputStream ( file , append ) ;', 'in = new CheckedInputStream ( new FileInputStream ( file ) , checksum ) ;', 'fis = new FileInputStream ( srcFile ) ;', 'FileOutputStream fos = null ;'}}"
05f878016d583b58806e59de862fca60e2e69d67,1.0,Statement unnecessarily nested within else clause .,"{'added_code': {'rules = new ArrayList < Rule > ( ) ;', 'List < Rule > rules = lines . get ( patternKey ) ;', 'lines . put ( patternKey , rules ) ;', '}', 'final String patternKey = r . pattern . substring ( 0 , 1 ) ;', 'sb . append ( "" , lcon = \'"" ) . append ( lCon ) . append ( \' \\ \'\' ) ;', 'public boolean isMatch ( final CharSequence input ) {', 'sb . append ( "" , rcon = \'"" ) . append ( rCon ) . append ( \' \\ \'\' ) ;', 'if ( rules = = null ) {', 'private final int myLine = cLine ;', 'final StringBuilder sb = new StringBuilder ( ) ;', 'return sb . toString ( ) ;', 'sb . append ( "" , pat = \'"" ) . append ( pat ) . append ( \' \\ \'\' ) ;', 'return parsePhoneme ( ph ) ;', 'throw new IllegalStateException ( ""Problem parsing line \'"" + currentLine + ""\' in "" +', '} catch ( final IllegalArgumentException e ) {', 'lines . putAll ( parseRules ( createScanner ( incl ) , location + "" - > "" + incl ) ) ;', 'final PhonemeExpr ph = parsePhonemeExpr ( stripQuotes ( parts [ 3 ] ) ) ;', 'location , e ) ;', 'final String lCon = stripQuotes ( parts [ 1 ] ) ;', '} ;', 'sb . append ( "" , loc = \'"" ) . append ( loc ) . append ( \' \\ \'\' ) ;', 'rules . add ( r ) ;', 'return new RPattern ( ) {', 'try {', 'private final String loc = location ;', '@ Override', 'final String pat = stripQuotes ( parts [ 0 ] ) ;', 'return new Phoneme ( ph , Languages . ANY LANGUAGE ) ;', 'sb . append ( "" { line = "" ) . append ( myLine ) ;', 'final Rule r = new Rule ( pat , lCon , rCon , ph ) {', 'public String toString ( ) {', 'return input . equals ( content ) ;', 'final int cLine = currentLine ;', 'final String rCon = stripQuotes ( parts [ 2 ] ) ;', ""sb . append ( ' } ' ) ;"", 'sb . append ( ""Rule"" ) ;'}, 'removed_code': {'rules = new ArrayList < Rule > ( ) ;', 'List < Rule > rules = lines . get ( patternKey ) ;', '} else {', 'lines . put ( patternKey , rules ) ;', '}', 'final String patternKey = r . pattern . substring ( 0 , 1 ) ;', 'sb . append ( "" , lcon = \'"" ) . append ( lCon ) . append ( \' \\ \'\' ) ;', 'public boolean isMatch ( final CharSequence input ) {', 'sb . append ( "" , rcon = \'"" ) . append ( rCon ) . append ( \' \\ \'\' ) ;', 'if ( rules = = null ) {', 'private final int myLine = cLine ;', 'final StringBuilder sb = new StringBuilder ( ) ;', 'return sb . toString ( ) ;', 'sb . append ( "" , pat = \'"" ) . append ( pat ) . append ( \' \\ \'\' ) ;', 'return parsePhoneme ( ph ) ;', 'throw new IllegalStateException ( ""Problem parsing line \'"" + currentLine + ""\' in "" +', '} catch ( final IllegalArgumentException e ) {', 'lines . putAll ( parseRules ( createScanner ( incl ) , location + "" - > "" + incl ) ) ;', 'final PhonemeExpr ph = parsePhonemeExpr ( stripQuotes ( parts [ 3 ] ) ) ;', 'location , e ) ;', 'final String lCon = stripQuotes ( parts [ 1 ] ) ;', '} ;', 'sb . append ( "" , loc = \'"" ) . append ( loc ) . append ( \' \\ \'\' ) ;', 'rules . add ( r ) ;', 'return new RPattern ( ) {', 'try {', 'private final String loc = location ;', '@ Override', 'final String pat = stripQuotes ( parts [ 0 ] ) ;', 'return new Phoneme ( ph , Languages . ANY LANGUAGE ) ;', 'sb . append ( "" { line = "" ) . append ( myLine ) ;', 'final Rule r = new Rule ( pat , lCon , rCon , ph ) {', 'public String toString ( ) {', 'return input . equals ( content ) ;', 'final int cLine = currentLine ;', 'final String rCon = stripQuotes ( parts [ 2 ] ) ;', ""sb . append ( ' } ' ) ;"", 'sb . append ( ""Rule"" ) ;'}}"
989135e762d3f00767240e7b42ee9e1cccbe43dd,1.0,BEANUTILS - 291 - Re - create class reference if lost - fixes problem on JRockit JDK - thanks to Jrg Schaible,"{'added_code': {'return null ;', 'if ( clazz ! = null ) {', 'if ( classLoader ! = null ) {', 'if ( clazz = = null ) {', 'classRef = new WeakReference ( clazz ) ;', 'ClassLoader classLoader = Thread . currentThread ( ) . getContextClassLoader ( ) ;', '} catch ( Throwable t ) {', 'clazz = reLoadClass ( ) ;', 'try {', 'private Class reLoadClass ( ) {', '}', 'return classLoader . loadClass ( className ) ;'}, 'removed_code': set()}"
a433f625f89c1d464b05186411ff20802e292fb4,1.0,Added headers to recognize PKWARE crypto headers .,"{'added_code': {'this . bitlen = ZipShort . getValue ( data , offset + 4 ) ;', 'if ( rcount = = 0 ) {', 'this . algId = EncryptionAlgorithm . getAlgorithmByCode ( ZipShort . getValue ( data , offset + 2 ) ) ;', 'this . vData = new byte [ vSize - 4 ] ;', 'this . ivData = new byte [ ivSize ] ;', 'System . arraycopy ( data , offset + 4 , this . ivData , 0 , ivSize ) ;', 'public void setLocalFileDataData ( byte [ ] data ) {', 'private int bitlen ;', 'private static final ZipShort HEADER ID = new ZipShort ( 0x0017 ) ;', 'System . arraycopy ( data , offset , tmp , 0 , length ) ;', 'public void parseCentralDirectoryFormat ( byte [ ] data , int offset , int length ) {', 'int ivSize = ZipShort . getValue ( data , offset ) ;', 'System . arraycopy ( data , offset + ivSize + 22 + erdSize , this . vData , 0 , vSize - 4 ) ;', 'return getLocalFileDataData ( ) ;', 'public ZipShort getCentralDirectoryLength ( ) {', 'for ( int i = 0 ; i < this . rcount ; i + + ) {', 'public class X0017 StrongEncryptionHeader extends PKWareExtraHeader implements ZipExtraField {', 'System . arraycopy ( data , offset + ivSize + 16 , this . erdData , 0 , erdSize ) ;', 'private byte [ ] localData ;', 'setCentralDirectoryData ( tmp ) ;', 'public void parseFromCentralDirectoryData ( byte [ ] data , int offset , int length ) {', 'public EncryptionAlgorithm getEncryptionAlgorithm ( ) {', 'this . format = ZipShort . getValue ( data , offset + ivSize + 6 ) ;', 'return HEADER ID ;', 'return hashAlg ;', 'private byte vCRC32 [ ] ;', 'public void setCentralDirectoryData ( byte [ ] data ) {', 'this . rcount = ZipLong . getValue ( data , offset + 8 ) ;', 'private long rcount ;', 'this . hashAlg = HashAlgorithm . getAlgorithmByCode ( ZipShort . getValue ( data , offset + 12 ) ) ;', 'public byte [ ] getCentralDirectoryData ( ) {', 'this . hashSize = ZipShort . getValue ( data , offset + ivSize + 22 + erdSize ) ;', 'this . flags = ZipShort . getValue ( data , offset + ivSize + 12 ) ;', 'System . arraycopy ( data , offset + ivSize + 22 + erdSize + resize + vSize - 4 , vCRC32 , 0 , 4 ) ;', 'public byte [ ] getLocalFileDataData ( ) {', 'System . arraycopy ( data , offset + ivSize + 22 + erdSize + vSize - 4 , vCRC32 , 0 , 4 ) ;', 'public ZipShort getLocalFileDataLength ( ) {', 'return rcount ;', 'private int format ;', 'centralData = ZipUtil . copy ( data ) ;', 'System . out . println ( ""rcount : "" + rcount ) ;', 'private static final long serialVersionUID = 1L ;', 'int vSize = ZipShort . getValue ( data , offset + ivSize + 26 + erdSize + resize ) ;', 'if ( centralData ! = null ) {', '} else {', 'private byte vData [ ] ;', 'private byte ivData [ ] ;', 'this . recipientKeyHash = new byte [ this . hashSize ] ;', 'byte [ ] tmp = new byte [ length ] ;', 'localData = ZipUtil . copy ( data ) ;', 'this . hashAlg = HashAlgorithm . getAlgorithmByCode ( ZipShort . getValue ( data , offset + ivSize + 20 + erdSize ) ) ;', 'this . hashSize = ZipShort . getValue ( data , offset + 14 ) ;', 'private byte keyBlob [ ] ;', 'this . vCRC32 = new byte [ 4 ] ;', 'return ZipUtil . copy ( localData ) ;', 'public long getRecordCount ( ) {', 'System . arraycopy ( data , offset + ivSize + 24 + erdSize , this . recipientKeyHash , 0 , this . hashSize ) ;', 'int resize = ZipShort . getValue ( data , offset + ivSize + 24 + erdSize ) ;', 'this . flags = ZipShort . getValue ( data , offset + 6 ) ;', 'return new ZipShort ( localData ! = null ? localData . length : 0 ) ;', 'public void parseFromLocalFileData ( byte [ ] data , int offset , int length ) {', 'return new ZipShort ( centralData . length ) ;', 'long size = ZipLong . getValue ( data , offset + ivSize + 2 ) ;', 'System . arraycopy ( data , offset + ivSize + 24 + erdSize + this . hashSize , this . keyBlob , 0 , resize - this . hashSize ) ;', 'int erdSize = ZipShort . getValue ( data , offset + ivSize + 14 ) ;', 'int vSize = ZipShort . getValue ( data , offset + ivSize + 20 + erdSize ) ;', 'this . format = ZipShort . getValue ( data , offset ) ;', 'return ZipUtil . copy ( centralData ) ;', 'public void parseFileFormat ( byte [ ] data , int offset , int length ) {', 'private int flags ;', 'private byte recipientKeyHash [ ] ;', 'public ZipShort getHeaderId ( ) {', 'System . arraycopy ( data , offset + ivSize + 22 + erdSize + resize , this . vData , 0 , vSize - 4 ) ;', 'this . keyBlob = new byte [ resize - this . hashSize ] ;', 'package org . apache . commons . compress . archivers . zip ;', 'for ( int j = 0 ; j < this . hashSize ; j + + ) {', '}', 'private int hashSize ;', 'this . algId = EncryptionAlgorithm . getAlgorithmByCode ( ZipShort . getValue ( data , offset + ivSize + 8 ) ) ;', 'this . bitlen = ZipShort . getValue ( data , offset + ivSize + 10 ) ;', 'this . rcount = ZipLong . getValue ( data , offset + ivSize + 16 + erdSize ) ;', 'if ( rcount > 0 ) {', 'return getLocalFileDataLength ( ) ;', 'parseCentralDirectoryFormat ( data , offset , length ) ;', 'private byte [ ] centralData ;', 'parseFileFormat ( data , offset , length ) ;', 'return algId ;', 'private byte erdData [ ] ;', 'private HashAlgorithm hashAlg ;', 'private EncryptionAlgorithm algId ;', 'public HashAlgorithm getHashAlgorithm ( ) {', 'this . erdData = new byte [ erdSize ] ;'}, 'removed_code': set()}"
c8ee9f781900f874b075433141de779723b3e110,1.0,COMPRESS - 459 use ZipEncoding consistently,"{'added_code': {'if ( encoding = = null ) {', 'import java . nio . ByteBuffer ;', 'import org . apache . commons . compress . archivers . zip . ZipEncoding ;', '} catch ( IOException ex ) {', 'try {', '}', 'import java . io . IOException ;', 'return getHeaderPadCount ( buf . limit ( ) - buf . position ( ) ) ;', 'pad ( entry . getHeaderPadCount ( zipEncoding ) ) ;', 'throw new RuntimeException ( ""cannot encode "" + name , ex ) ;', 'public int getHeaderPadCount ( ZipEncoding encoding ) {', 'final ByteBuffer buf = encoding . encode ( name ) ;'}, 'removed_code': {'public int getHeaderPadCount ( Charset charset ) {', 'pad ( entry . getHeaderPadCount ( Charset . forName ( encoding ) ) ) ;', 'import java . nio . charset . Charset ;', 'return getHeaderPadCount ( name . getBytes ( charset ) . length ) ;', 'if ( charset = = null ) {'}}"
b10528a62e51b2c5fdc0c4b7884cc93f03f8ce96,1.0,COMPRESS - 382 and COMPRESS - 386 - - break out unit tests ; add memory limit for xz .,"{'added_code': {'public MemoryLimitException ( String message ) {', 'return in . skip ( n ) ;', '}', 'this ( inputStream , decompressConcatenated , - 1 ) ;', 'return ret ;', 'import org . apache . commons . compress . MemoryLimitException ;', 'return new ZCompressorInputStream ( in , memoryLimitInKb ) ;', 'return new LZMACompressorInputStream ( in , memoryLimitInKb ) ;', 'in = new LZMAInputStream ( inputStream , memoryLimitInKb ) ;', 'import java . io . IOException ;', 'package org . apache . commons . compress ;', 'in = new XZInputStream ( inputStream , memoryLimitInKb ) ;', 'throw new MemoryLimitException ( ""Excedded memory limit"" , e ) ;', 'throws MemoryLimitException {', 'public MemoryLimitException ( String message , Exception e ) {', 'boolean decompressConcatenated , int memoryLimitInKb )', 'return new XZCompressorInputStream ( in , actualDecompressConcatenated , memoryLimitInKb ) ;', 'public XZCompressorInputStream ( InputStream inputStream ,', 'final int ret = in . read ( buf , off , len ) ;', '} catch ( org . tukaani . xz . MemoryLimitException e ) {', 'public class MemoryLimitException extends IOException {', 'throw new MemoryLimitException ( ""Tried to allocate "" + maxTableSize +', 'count ( ret = = - 1 ? - 1 : 1 ) ;', 'count ( ret ) ;', 'try {', 'final int ret = in . read ( ) ;', 'throws IOException {', 'in = new SingleXZInputStream ( inputStream , memoryLimitInKb ) ;', 'throw new MemoryLimitException ( ""exceeded calculated memory limit"" , e ) ;', 'throw new MemoryLimitException ( ""Exceeded memory limit"" , e ) ;'}, 'removed_code': {'public class CompressorMemoryLimitException extends CompressorException {', '} catch ( MemoryLimitException e ) {', 'return in . skip ( n ) ;', '}', 'return ret ;', 'return new ZCompressorInputStream ( in , memoryLimitInKb ) ;', 'return new LZMACompressorInputStream ( in , memoryLimitInKb ) ;', 'in = new XZInputStream ( inputStream ) ;', 'in = new LZMAInputStream ( inputStream , memoryLimitInKb ) ;', 'throws CompressorMemoryLimitException {', 'public CompressorMemoryLimitException ( String message ) {', 'final int ret = in . read ( buf , off , len ) ;', 'in = new SingleXZInputStream ( inputStream ) ;', 'throw new CompressorMemoryLimitException ( ""Tried to allocate "" + maxTableSize +', 'count ( ret = = - 1 ? - 1 : 1 ) ;', 'count ( ret ) ;', 'try {', 'package org . apache . commons . compress . compressors ;', 'final int ret = in . read ( ) ;', 'throw new CompressorMemoryLimitException ( e . getMessage ( ) ) ;', 'public CompressorMemoryLimitException ( String message , Exception e ) {', '} catch ( ZCompressorInputStream . IOExceptionWrappingMemoryLimitException e ) {', 'throw new CompressorMemoryLimitException ( ""exceeded calculated memory limit"" , e ) ;', 'return new XZCompressorInputStream ( in , actualDecompressConcatenated ) ;', 'import org . apache . commons . compress . compressors . CompressorMemoryLimitException ;', 'import org . tukaani . xz . MemoryLimitException ;'}}"
bb014c3ebfe20bf7a7fce5e7a8124121de695350,1.0,Fixed SubCircle behaviour in parallel circles case .,"{'added_code': {'import org . apache . commons . math3 . geometry . euclidean . threed . Vector3D ;', 'return ( ( ArcsSet ) getRemainingRegion ( ) ) . side ( thisCircle . getInsideArc ( otherCircle ) ) ;', 'final double angle = Vector3D . angle ( thisCircle . getPole ( ) , otherCircle . getPole ( ) ) ;', '} else if ( angle > FastMath . PI - thisCircle . getTolerance ( ) ) {', 'final ArcsSet plus = split . getPlus ( ) ;', 'return new SplitSubHyperplane < Sphere2D > ( this , null ) ;', 'if ( angle < thisCircle . getTolerance ( ) ) {', 'final ArcsSet . Split split = ( ( ArcsSet ) getRemainingRegion ( ) ) . split ( arc ) ;', '} else {', 'import org . apache . commons . math3 . util . FastMath ;', '}', 'minus = = null ? null : new SubCircle ( thisCircle . copySelf ( ) , minus ) ) ;', 'if ( angle < thisCircle . getTolerance ( ) | | angle > FastMath . PI - thisCircle . getTolerance ( ) ) {', 'final Arc arc = thisCircle . getInsideArc ( otherCircle ) ;', 'return new SplitSubHyperplane < Sphere2D > ( plus = = null ? null : new SubCircle ( thisCircle . copySelf ( ) , plus ) ,', 'return new SplitSubHyperplane < Sphere2D > ( null , this ) ;', 'final ArcsSet minus = split . getMinus ( ) ;', 'return Side . HYPER ;'}, 'removed_code': {'return ( ( ArcsSet ) getRemainingRegion ( ) ) . side ( arc ) ;', 'return new SplitSubHyperplane < Sphere2D > ( new SubCircle ( thisCircle . copySelf ( ) , split . getPlus ( ) ) ,', 'final ArcsSet . Split split = ( ( ArcsSet ) getRemainingRegion ( ) ) . split ( arc ) ;', 'final Arc arc = thisCircle . getInsideArc ( otherCircle ) ;', 'new SubCircle ( thisCircle . copySelf ( ) , split . getMinus ( ) ) ) ;'}}"
cfa7c5e3bba0efbc88dfb2fcafb983723a1606bc,1.0,"IMPROVEMENT : write home page , description and license info in XmlModuleDescriptorWriter . This is useful to be sure we don't lose information parsed in poms , license information being especially useful ( related to IVY - 892 )","{'added_code': {'} else {', 'out . print ( "" < license "" ) ;', 'return md . getExtraInfo ( ) . size ( ) > 0', '| | md . getHomePage ( ) ! = null', '}', 'out . print ( ""url = \\ """" + license . getUrl ( ) + "" \\ "" "" ) ;', 'if ( license . getName ( ) ! = null ) {', '| | md . getLicenses ( ) . length > 0 ;', 'if ( md . getHomePage ( ) ! = null | | md . getDescription ( ) ! = null ) {', 'License license = licenses [ i ] ;', 'if ( requireInnerInfoElement ( md ) ) {', 'out . println ( """" + md . getDescription ( ) ) ;', 'out . println ( "" > "" ) ;', 'out . print ( "" < description"" ) ;', 'for ( int i = 0 ; i < licenses . length ; i + + ) {', 'out . println ( "" < / description > "" ) ;', 'if ( md . getDescription ( ) ! = null & & md . getDescription ( ) . trim ( ) . length ( ) > 0 ) {', 'if ( md . getHomePage ( ) ! = null ) {', 'import org . apache . ivy . core . module . descriptor . License ;', 'out . println ( "" / > "" ) ;', 'if ( license . getUrl ( ) ! = null ) {', 'private static boolean requireInnerInfoElement ( ModuleDescriptor md ) {', '| | ( md . getDescription ( ) ! = null & & md . getDescription ( ) . trim ( ) . length ( ) > 0 )', 'out . print ( ""name = \\ """" + license . getName ( ) + "" \\ "" "" ) ;', 'License [ ] licenses = md . getLicenses ( ) ;', 'out . print ( "" homepage = \\ """" + md . getHomePage ( ) + "" \\ """" ) ;'}, 'removed_code': {'if ( md . getExtraInfo ( ) . size ( ) > 0 ) {'}}"
3c644cf87ec8c0e6313b3a10b6cfd66279b8093f,1.0,[ MATH - 749 ] Change the way the line segments are computed as they can not be serialized . Use the array only as cache and create them as needed .,"{'added_code': {'private final double tolerance ;', 'Vector2D lastPoint = null ;', '} else {', 'lastPoint = point ;', '}', '} else if ( size = = 2 ) {', 'Vector2D firstPoint = null ;', 'return lineSegments ;', 'this . tolerance = tolerance ;', 'if ( lastPoint = = null ) {', 'final int size = vertices . length ;', 'this . lineSegments [ 0 ] = new Segment ( p1 , p2 , new Line ( p1 , p2 , tolerance ) ) ;', 'this . lineSegments [ index + + ] =', 'firstPoint = point ;', 'final Vector2D p2 = vertices [ 1 ] ;', 'for ( int i = 0 ; i < segments . length ; i + + ) {', 'final Vector2D p1 = vertices [ 0 ] ;', 'private Segment [ ] retrieveLineSegments ( ) {', 'int index = 0 ;', 'new Segment ( lastPoint , point , new Line ( lastPoint , point , tolerance ) ) ;', 'private transient Segment [ ] lineSegments ;', 'return retrieveLineSegments ( ) . clone ( ) ;', 'if ( size < = 1 ) {', 'if ( lineSegments = = null ) {', 'this . lineSegments = new Segment [ 0 ] ;', 'this . lineSegments = new Segment [ 1 ] ;', 'final Segment [ ] segments = retrieveLineSegments ( ) ;', 'final Line [ ] lineArray = new Line [ segments . length ] ;', 'lineArray [ i ] = segments [ i ] . getLine ( ) ;', 'this . lineSegments = new Segment [ size ] ;', 'for ( Vector2D point : vertices ) {', 'new Segment ( lastPoint , firstPoint , new Line ( lastPoint , firstPoint , tolerance ) ) ;', 'this . lineSegments [ index ] ='}, 'removed_code': {'final int size = vertices . size ( ) ;', 'Vector2D lastPoint = null ;', 'final Vector2D p2 = it . next ( ) ;', '} else {', 'lastPoint = point ;', '}', '} else if ( size = = 2 ) {', 'Vector2D firstPoint = null ;', 'final Iterator < Vector2D > it = vertices . iterator ( ) ;', 'if ( lastPoint = = null ) {', 'final Vector2D p1 = it . next ( ) ;', 'this . lineSegments [ 0 ] = new Segment ( p1 , p2 , new Line ( p1 , p2 , tolerance ) ) ;', 'this . lineSegments [ index + + ] =', 'firstPoint = point ;', 'final Line [ ] lineArray = new Line [ lineSegments . length ] ;', 'private final Segment [ ] lineSegments ;', 'int index = 0 ;', 'for ( int i = 0 ; i < lineSegments . length ; i + + ) {', 'new Segment ( lastPoint , point , new Line ( lastPoint , point , tolerance ) ) ;', 'if ( size < = 1 ) {', 'this . lineSegments = new Segment [ 0 ] ;', 'return lineSegments . clone ( ) ;', 'this . lineSegments = new Segment [ 1 ] ;', 'lineArray [ i ] = lineSegments [ i ] . getLine ( ) ;', 'import java . util . Iterator ;', 'this . lineSegments = new Segment [ size ] ;', 'for ( Vector2D point : vertices ) {', 'new Segment ( lastPoint , firstPoint , new Line ( lastPoint , firstPoint , tolerance ) ) ;', 'this . lineSegments [ index ] ='}}"
423b7ab26233e24cbaf6aa21f2fe97b7671d1341,1.0,FIX : Maven 'orbit' and 'pear' packaging is now supported ( IVY - 899 ) ( merged from trunk ),"{'added_code': {'""jbi - component"" , ""jbi - shared - library"" , ""orbit"" } ) ;', 'ext = ""phar"" ;', '} else if ( ""pear"" . equals ( packaging ) ) {'}, 'removed_code': {'""jbi - component"" , ""jbi - shared - library"" } ) ;'}}"
21c42878ac1e8c3a8c5cee99cd72ce7a92092379,1.0,Sort methods in AB order .,"{'added_code': {'else', 'final Header header = method . getResponseHeader ( ""last - modified"" ) ;', 'public HttpInputStream ( final GetMethod method )', 'protected FileType doGetType ( ) throws Exception', '}', 'protected void setupMethod ( final HttpMethod method ) throws FileSystemException , URIException', 'throw new FileSystemException ( ""vfs . provider . http / head . error"" , getName ( ) , Integer . valueOf ( status ) ) ;', 'this . method = method ;', 'method . releaseConnection ( ) ;', 'private final GetMethod method ;', 'return URIUtil . encodePath ( decodedPath ) ;', 'return new HttpRandomAccessContent ( this , mode ) ;', 'protected void onClose ( ) throws IOException', 'if ( status = = HttpURLConnection . HTTP OK )', 'static class HttpInputStream extends MonitorInputStream', 'return FileType . IMAGINARY ;', 'super ( method . getResponseBodyAsStream ( ) ) ;', 'protected long doGetLastModifiedTime ( ) throws Exception', 'return FileType . FILE ;', 'return urlCharset ;', 'final String pathEncoded = ( ( URLFileName ) getName ( ) ) . getPathQueryEncoded ( this . getUrlCharset ( ) ) ;', 'if ( header = = null )', 'throw new Exception ( ""Not implemented . "" ) ;', 'return DateUtil . parseDate ( header . getValue ( ) ) . getTime ( ) ;', 'protected String encodePath ( final String decodedPath ) throws URIException', 'method . setPath ( pathEncoded ) ;', '@ Override', 'method . setFollowRedirects ( this . getFollowRedirect ( ) ) ;', 'protected String getUrlCharset ( )', 'throws IOException', 'method . setRequestHeader ( ""User - Agent"" , ""Jakarta - Commons - VFS"" ) ;', '| | status = = HttpURLConnection . HTTP GONE )', '{', 'else if ( status = = HttpURLConnection . HTTP NOT FOUND', 'protected String [ ] doListChildren ( ) throws Exception', 'throw new FileSystemException ( ""vfs . provider . http / last - modified . error"" , getName ( ) ) ;', 'final int status = this . getHeadMethod ( ) . getStatusCode ( ) ;', 'protected RandomAccessContent doGetRandomAccessContent ( final RandomAccessMode mode ) throws Exception'}, 'removed_code': {'else', 'final Header header = method . getResponseHeader ( ""last - modified"" ) ;', 'public HttpInputStream ( final GetMethod method )', 'protected FileType doGetType ( ) throws Exception', '}', 'protected void setupMethod ( final HttpMethod method ) throws FileSystemException , URIException', 'throw new FileSystemException ( ""vfs . provider . http / head . error"" , getName ( ) , Integer . valueOf ( status ) ) ;', 'this . method = method ;', 'method . releaseConnection ( ) ;', 'private final GetMethod method ;', 'return URIUtil . encodePath ( decodedPath ) ;', 'return new HttpRandomAccessContent ( this , mode ) ;', 'protected void onClose ( ) throws IOException', 'if ( status = = HttpURLConnection . HTTP OK )', 'static class HttpInputStream extends MonitorInputStream', 'return FileType . IMAGINARY ;', 'super ( method . getResponseBodyAsStream ( ) ) ;', 'protected long doGetLastModifiedTime ( ) throws Exception', 'return FileType . FILE ;', 'return urlCharset ;', 'final String pathEncoded = ( ( URLFileName ) getName ( ) ) . getPathQueryEncoded ( this . getUrlCharset ( ) ) ;', 'if ( header = = null )', 'throw new Exception ( ""Not implemented . "" ) ;', 'return DateUtil . parseDate ( header . getValue ( ) ) . getTime ( ) ;', 'protected String encodePath ( final String decodedPath ) throws URIException', 'method . setPath ( pathEncoded ) ;', '@ Override', 'method . setFollowRedirects ( this . getFollowRedirect ( ) ) ;', 'protected String getUrlCharset ( )', 'throws IOException', 'method . setRequestHeader ( ""User - Agent"" , ""Jakarta - Commons - VFS"" ) ;', '| | status = = HttpURLConnection . HTTP GONE )', '{', 'else if ( status = = HttpURLConnection . HTTP NOT FOUND', 'protected String [ ] doListChildren ( ) throws Exception', 'throw new FileSystemException ( ""vfs . provider . http / last - modified . error"" , getName ( ) ) ;', 'final int status = this . getHeadMethod ( ) . getStatusCode ( ) ;', 'protected RandomAccessContent doGetRandomAccessContent ( final RandomAccessMode mode ) throws Exception'}}"
70594bcaff1d553cbd35312bb63a33bcba0680d3,1.0,COMPRESS - 382 first draft of preventing OOM in LZMA,"{'added_code': {'in = new LZMAInputStream ( inputStream , memoryLimitKb ) ;', 'public void setLzmaMemoryLimitKb ( int lzmaMemoryLimitKb ) {', 'throws IOException {', 'public LZMACompressorInputStream ( final InputStream inputStream , int memoryLimitKb )', 'this . lzmaMemoryLimitKb = lzmaMemoryLimitKb ;', '}', 'in = new LZMAInputStream ( inputStream , - 1 ) ;', 'return new LZMACompressorInputStream ( in , lzmaMemoryLimitKb ) ;', 'private volatile int lzmaMemoryLimitKb = - 1 ;', 'public LZMACompressorInputStream ( final InputStream inputStream )'}, 'removed_code': {'return new LZMACompressorInputStream ( in ) ;', 'public LZMACompressorInputStream ( final InputStream inputStream )', 'in = new LZMAInputStream ( inputStream ) ;'}}"
9cedc7d76f2bbe52b3d1cc4caf8024e730266f83,1.0,GIRAPH - 873 : Specialized edge stores,"{'added_code': {'Map < Integer , OutEdges < IntWritable , E > > partitionEdges ) {', 'OutEdges < LongWritable , E > outEdges = partitionEdges . get ( vertexId . get ( ) ) ;', 'Map < K , OutEdges < I , E > > partitionEdgesIn ) ;', 'return ( ( Int2ObjectMap < OutEdges < IntWritable , E > > ) partitionEdges )', '. iterator ( ) ;', 'partitionEdges = ( ConcurrentMap < I , OutEdges < I , E > > )', 'final BlockingQueue < Integer > partitionIdQueue =', '( Long2ObjectMap < OutEdges < LongWritable , E > > ) partitionEdgesIn ;', 'if ( vertex . getNumEdges ( ) = = 0 ) {', 'protected OutEdges < IntWritable , E > removePartitionEdges (', 'ByteArrayVertexIdEdges < I , E > . VertexIdEdgeIterator vertexIdEdgeIterator =', 'import it . unimi . dsi . fastutil . ints . Int2ObjectMaps ;', 'public class LongEdgeStore < V extends Writable , E extends Writable >', 'new Int2ObjectOpenHashMap < OutEdges < IntWritable , E > > ( ) ) ;', 'ByteArrayVertexIdEdges < IntWritable , E > . VertexIdEdgeIterator', 'return ;', 'protected LongWritable createVertexId (', 'Map . Entry < I , OutEdges < I , E > > > {', 'OutEdges < I , E > outEdges = convertInputToComputeEdges (', 'if ( partitionEdges = = null ) {', 'protected OutEdges < I , E > getVertexOutEdges (', 'extends AbstractEdgeStore < LongWritable , V , E , Long ,', 'this . configuration = configuration ;', 'import org . apache . giraph . edge . AbstractEdgeStore ;', 'configuration . getNettyServerExecutionConcurrency ( ) ) . makeMap ( ) ;', 'if ( createSourceVertex ) {', 'Int2ObjectMaps . synchronize (', 'new MapMaker ( ) . concurrencyLevel (', 'Vertex < I , V , E > vertex = partition . getVertex ( vertexId ) ;', 'vertex . addEdge ( edge ) ;', 'protected Iterator < Long2ObjectMap . Entry < OutEdges < LongWritable , E > > >', 'getPartitionEdgesIterator ( partitionEdges ) ;', 'Map < I , OutEdges < I , E > > partitionEdges ) {', 'this . service = service ;', 'return configuration . createAndInitializeOutEdges ( inputEdges ) ;', 'import java . util . Map ;', 'protected IntWritable getVertexId (', 'outEdges = configuration . createAndInitializeInputOutEdges ( ) ;', '( Int2ObjectMap < OutEdges < IntWritable , E > > )', 'protected abstract Map < K , OutEdges < I , E > > getPartitionEdges ( int partitionId ) ;', 'LOG . info ( ""moveEdgesToVertices : Finished moving incoming edges to "" +', 'import java . util . concurrent . BlockingQueue ;', 'protected abstract I getVertexId ( Et entry , I representativeVertexId ) ;', 'Long2ObjectMap < OutEdges < LongWritable , E > > newPartitionEdges =', 'partitionEdges = newPartitionEdges ;', 'ConcurrentMap < I , OutEdges < I , E > > newPartitionEdges =', 'Partition < I , V , E > partition =', 'partitionEdges = ( Int2ObjectMap < OutEdges < IntWritable , E > > )', 'partitionEdges . put ( vertexId . get ( ) , outEdges ) ;', 'import java . util . concurrent . ArrayBlockingQueue ;', 'Integer partitionId ;', 'private static final Logger LOG = Logger . getLogger ( AbstractEdgeStore . class ) ;', 'Long2ObjectMap . Entry < OutEdges < LongWritable , E > > entry ) {', 'Int2ObjectMap . Entry < OutEdges < IntWritable , E > > entry ,', 'import org . apache . hadoop . io . Writable ;', 'public IntEdgeStore (', 'Long2ObjectMap . Entry < OutEdges < LongWritable , E > > entry ,', 'extends AbstractEdgeStore < I , V , E , I ,', 'LOG . info ( ""moveEdgesToVertices : Moving incoming edges to vertices . "" ) ;', 'outEdges = partitionEdges . putIfAbsent ( vertexId , newOutEdges ) ;', 'return partitionEdges . put ( entry . getLongKey ( ) , null ) ;', 'protected boolean useInputOutEdges ;', 'partitionEdges = ( Long2ObjectMap < OutEdges < LongWritable , E > > )', 'return ( ( Long2ObjectMap < OutEdges < LongWritable , E > > ) partitionEdges )', 'protected OutEdges < I , E > removePartitionEdges (', 'outEdges = newOutEdges ;', 'while ( iterator . hasNext ( ) ) {', 'public AbstractEdgeStore (', '( Long2ObjectMap < OutEdges < LongWritable , E > > )', 'Iterator < Et > iterator =', 'LongWritable vertexId = vertexIdEdgeIterator . getCurrentVertexId ( ) ;', 'package org . apache . giraph . edge ;', 'protected abstract Iterator < Et >', 'vertex . setEdges ( outEdges ) ;', 'import org . apache . hadoop . util . Progressable ;', 'Int2ObjectMap . Entry < OutEdges < IntWritable , E > > entry ) {', 'private OutEdges < I , E > convertInputToComputeEdges (', 'representativeVertexId . set ( entry . getLongKey ( ) ) ;', 'Map < K , OutEdges < I , E > > partitionEdges ) ;', 'import it . unimi . dsi . fastutil . longs . Long2ObjectMap ;', 'protected Int2ObjectMap < OutEdges < IntWritable , E > > getPartitionEdges (', 'OutEdges < IntWritable , E > outEdges = partitionEdges . get ( vertexId . get ( ) ) ;', 'package org . apache . giraph . edge . primitives ;', 'public Void call ( ) throws Exception {', 'return representativeVertexId ;', 'transientEdges = new MapMaker ( ) . concurrencyLevel (', 'protected Iterator < Int2ObjectMap . Entry < OutEdges < IntWritable , E > > >', 'getPartitionEdgesIterator (', 'OutEdges < I , E > newOutEdges =', 'partition . saveVertex ( vertex ) ;', 'return inputEdges ;', 'import org . apache . giraph . utils . ProgressableUtils ;', 'import it . unimi . dsi . fastutil . ints . Int2ObjectOpenHashMap ;', 'implements EdgeStore < I , V , E > {', 'public void addPartitionEdges (', 'return new IntWritable ( entry . getIntKey ( ) ) ;', 'transientEdges . clear ( ) ;', 'edges . getVertexIdEdgeIterator ( ) ;', 'this . progressable = progressable ;', 'if ( transientEdges . isEmpty ( ) ) {', 'vertex = configuration . createVertex ( ) ;', 'LOG . info ( ""moveEdgesToVertices : No edges to move"" ) ;', 'import org . apache . hadoop . io . IntWritable ;', 'Et entry = iterator . next ( ) ;', 'service . getPartitionStore ( ) . putPartition ( partition ) ;', 'OutEdges < I , E > inputEdges ) {', 'Long2ObjectMap . Entry < OutEdges < LongWritable , E > > > {', 'import it . unimi . dsi . fastutil . longs . Long2ObjectOpenHashMap ;', 'protected OutEdges < IntWritable , E > getVertexOutEdges (', 'ProgressableUtils . getResultsWithNCallables ( callableFactory , numThreads ,', 'ImmutableClassesGiraphConfiguration < I , V , E > configuration ,', 'super ( service , configuration , progressable ) ;', '. long2ObjectEntrySet ( )', 'public abstract class AbstractEdgeStore < I extends WritableComparable ,', 'ByteArrayVertexIdEdges < I , E > . VertexIdEdgeIterator vertexIdEdgeIterator ,', 'extends DefaultImmutableClassesGiraphConfigurable < I , V , E >', 'Long2ObjectMap < OutEdges < LongWritable , E > > partitionEdges =', 'partitionEdges ) ;', 'V extends Writable , E extends Writable >', 'getPartitionEdgesIterator ( Map < K , OutEdges < I , E > > partitionEdges ) ;', 'import org . apache . giraph . conf . ImmutableClassesGiraphConfiguration ;', '} else {', 'protected ConcurrentMap < I , OutEdges < I , E > > getPartitionEdges (', 'Int2ObjectMap . Entry < OutEdges < IntWritable , E > > > {', 'protected abstract OutEdges < I , E > removePartitionEdges ( Et entry ,', 'public SimpleEdgeStore (', 'if ( vertex = = null ) {', 'int partitionId , ByteArrayVertexIdEdges < I , E > edges ) {', 'representativeVertexId ) ;', 'protected Iterator < Map . Entry < I , OutEdges < I , E > > >', 'I vertexId = getVertexId ( entry ,', 'configuration . createVertexValue ( ) , outEdges ) ;', 'Map < Long , OutEdges < LongWritable , E > > partitionEdgesIn ) {', 'Map < K , OutEdges < I , E > > partitionEdges =', 'public class SimpleEdgeStore < I extends WritableComparable ,', 'import org . apache . hadoop . io . LongWritable ;', 'return partitionEdges . put ( entry . getIntKey ( ) , null ) ;', '( ConcurrentMap < I , OutEdges < I , E > > ) transientEdges . get ( partitionId ) ;', 'import org . apache . giraph . edge . OutEdges ;', 'protected ConcurrentMap < Integer , Map < K , OutEdges < I , E > > > transientEdges ;', 'return partitionEdges . put ( entry . getKey ( ) , null ) ;', '""vertices . "" ) ;', 'Map . Entry < I , OutEdges < I , E > > entry ,', '( ConcurrentMap < I , OutEdges < I , E > > ) partitionEdgesIn ;', 'protected Long2ObjectMap < OutEdges < LongWritable , E > > getPartitionEdges (', 'useInputOutEdges = configuration . useInputOutEdges ( ) ;', '} ;', 'if ( outEdges = = null ) {', '. int2ObjectEntrySet ( )', 'Edge < I , E > edge = reuseEdgeObjects ?', 'I representativeVertexId = configuration . createVertexId ( ) ;', 'return partitionEdges . entrySet ( ) . iterator ( ) ;', 'I vertexId = vertexIdEdgeIterator . getCurrentVertexId ( ) ;', 'Long2ObjectMaps . synchronize (', 'import java . util . concurrent . Callable ;', 'import org . apache . giraph . conf . DefaultImmutableClassesGiraphConfigurable ;', 'for ( Edge < I , E > edge : outEdges ) {', 'OutEdges < I , E > outEdges = getVertexOutEdges ( vertexIdEdgeIterator ,', 'vertexIdEdgeIterator . getCurrentEdge ( ) :', 'Map < Long , OutEdges < LongWritable , E > > partitionEdges ) {', 'public void moveEdgesToVertices ( ) {', '@ Override', 'Map < I , OutEdges < I , E > > partitionEdgesIn ) {', 'import org . apache . giraph . graph . Vertex ;', 'V extends Writable , E extends Writable , K , Et >', 'new Long2ObjectOpenHashMap < OutEdges < LongWritable , E > > ( ) ) ;', 'new ArrayBlockingQueue < > ( transientEdges . size ( ) ) ;', 'IntWritable representativeVertexId ) {', 'synchronized ( outEdges ) {', 'outEdges . add ( edge ) ;', 'LongWritable representativeVertexId ) {', 'service . getPartitionStore ( ) . getOrCreatePartition ( partitionId ) ;', 'return new Callable < Void > ( ) {', 'import com . google . common . collect . MapMaker ;', 'vertexIdEdgeIterator . releaseCurrentVertexId ( ) ;', 'representativeVertexId . set ( entry . getIntKey ( ) ) ;', 'I representativeVertexId ) {', 'protected abstract I createVertexId ( Et entry ) ;', 'import java . util . Iterator ;', 'CentralizedServiceWorker < I , V , E > service ,', 'import it . unimi . dsi . fastutil . ints . Int2ObjectMap ;', 'import org . apache . hadoop . io . WritableComparable ;', 'outEdges = partitionEdges . get ( vertexId . get ( ) ) ;', 'protected CentralizedServiceWorker < I , V , E > service ;', 'while ( ( partitionId = partitionIdQueue . poll ( ) ) ! = null ) {', 'import org . apache . giraph . utils . CallableFactory ;', 'import org . apache . giraph . partition . Partition ;', 'import java . util . concurrent . ConcurrentMap ;', 'int partitionId ) {', 'IntWritable vertexId = vertexIdEdgeIterator . getCurrentVertexId ( ) ;', 'import org . apache . giraph . utils . ByteArrayVertexIdEdges ;', 'protected IntWritable createVertexId (', '}', 'protected Progressable progressable ;', 'Progressable progressable ) {', 'newPartitionEdges ) ;', 'protected ImmutableClassesGiraphConfiguration < I , V , E > configuration ;', 'public class IntEdgeStore < V extends Writable , E extends Writable >', 'protected I getVertexId ( Map . Entry < I , OutEdges < I , E > > entry ,', 'vertexIdEdgeIterator . releaseCurrentEdge ( ) ;', 'CentralizedServiceWorker < IntWritable , V , E > service ,', 'return entry . getKey ( ) ;', 'return new LongWritable ( entry . getLongKey ( ) ) ;', 'protected OutEdges < LongWritable , E > getVertexOutEdges (', 'partitionIdQueue . addAll ( transientEdges . keySet ( ) ) ;', 'transientEdges . putIfAbsent ( partitionId , newPartitionEdges ) ;', '""move - edges - % d"" , progressable ) ;', 'getPartitionEdgesIterator ( Map < I , OutEdges < I , E > > partitionEdges ) {', 'configuration . createAndInitializeInputOutEdges ( ) ;', 'while ( vertexIdEdgeIterator . hasNext ( ) ) {', 'protected boolean reuseEdgeObjects ;', 'ImmutableClassesGiraphConfiguration < LongWritable , V , E > configuration ,', 'reuseEdgeObjects = configuration . reuseEdgeObjects ( ) ;', 'public LongEdgeStore (', 'ImmutableClassesGiraphConfiguration < IntWritable , V , E > configuration ,', 'ConcurrentMap < I , OutEdges < I , E > > partitionEdges =', 'Int2ObjectMap < OutEdges < IntWritable , E > > partitionEdges =', 'final boolean createSourceVertex = configuration . getCreateSourceVertex ( ) ;', 'protected I createVertexId ( Map . Entry < I , OutEdges < I , E > > entry ) {', 'partition . putVertex ( vertex ) ;', 'vertexIdEdgeIterator ,', 'protected abstract OutEdges < I , E > getVertexOutEdges (', 'Map < Integer , OutEdges < IntWritable , E > > partitionEdgesIn ) {', 'Int2ObjectMap < OutEdges < IntWritable , E > > newPartitionEdges =', 'protected OutEdges < LongWritable , E > removePartitionEdges (', 'Map < K , OutEdges < I , E > > partitionEdges = getPartitionEdges ( partitionId ) ;', 'OutEdges < I , E > outEdges = partitionEdges . get ( vertexId ) ;', 'CallableFactory < Void > callableFactory = new CallableFactory < Void > ( ) {', 'extends AbstractEdgeStore < IntWritable , V , E , Integer ,', 'vertex . initialize ( createVertexId ( entry ) ,', 'return null ;', 'return outEdges ;', 'import org . apache . giraph . bsp . CentralizedServiceWorker ;', 'if ( !useInputOutEdges ) {', 'return partitionEdges ;', 'synchronized ( partitionEdges ) {', 'removePartitionEdges ( entry , partitionEdges ) ) ;', 'transientEdges . putIfAbsent ( partitionId ,', 'ByteArrayVertexIdEdges < LongWritable , E > . VertexIdEdgeIterator', 'if ( LOG . isInfoEnabled ( ) ) {', 'transientEdges . remove ( partitionId ) ;', 'transientEdges . get ( partitionId ) ;', '( Int2ObjectMap < OutEdges < IntWritable , E > > ) partitionEdgesIn ;', 'int numThreads = configuration . getNumInputSplitsThreads ( ) ;', 'import org . apache . log4j . Logger ;', 'CentralizedServiceWorker < LongWritable , V , E > service ,', 'import it . unimi . dsi . fastutil . longs . Long2ObjectMaps ;', 'vertexIdEdgeIterator . next ( ) ;', 'protected LongWritable getVertexId (', 'public Callable < Void > newCallable ( int callableId ) {'}, 'removed_code': set()}"
68b033741b02c3ae54d649e858790732bc5c2d27,1.0,IMPROVEMENT : Added support for NTLM authentication ( IVY - 1094 ) ( thanks to Mathieu Anquetin ),"{'added_code': {'import org . apache . ivy . util . HostUtil ;', 'new MultiThreadedHttpConnectionManager ( ) ;', 'HostUtil . getLocalHostName ( ) , proxyRealm ) ) ;', 'throw new IOException ( ""The HTTP response code for "" + src', 'throw new IOException ( ""The HTTP response code for "" + url', 'httpClient . getParams ( ) . setParameter ( ""http . useragent"" ,', '+ ""commons - httpclient HeadMethod . Please use commons - httpclient 3 . 0 or ""', 'new AuthScope ( c . getHost ( ) , AuthScope . ANY PORT , c . getRealm ( ) ) ,', 'proxyRealm = System . getProperty ( ""http . auth . ntlm . domain"" ) ;', 'import org . apache . commons . httpclient . auth . AuthScope ;', 'HostUtil . getLocalHostName ( ) , c . getRealm ( ) ) ) ;', 'httpClient . getState ( ) . setProxyCredentials (', 'final MultiThreadedHttpConnectionManager connManager =', '+ proxyUserName ) ;', '+ "" did not indicate a success . "" + "" See log for more detail . "" ) ;', 'new AuthScope ( proxyHost , proxyPort , proxyRealm ) ,', 'List authPrefs = new ArrayList ( 3 ) ;', '""Apache Ivy / "" + Ivy . getIvyVersion ( ) ) ;', '+ ""a proxy server that is not well configured . "" ) ;', 'new NTCredentials ( c . getUserName ( ) , c . getPasswd ( ) ,', 'Message . verbose ( ""proxy configured : host = "" + proxyHost + "" port = "" + proxyPort + "" user = ""', 'authPrefs . add ( AuthPolicy . NTLM ) ;', 'import org . apache . commons . httpclient . NTCredentials ;', '+ ""use ivy with sufficient security permissions . "" ) ;', 'new NTCredentials ( proxyUserName , proxyPasswd ,'}, 'removed_code': {'List authPrefs = new ArrayList ( 2 ) ;', 'throw new IOException (', 'import org . apache . commons . httpclient . UsernamePasswordCredentials ;', '+ ""commons - httpclient HeadMethod . Please use commons - httpclient 3 . 0 or ""', '+ "" See log for more detail . "" ) ;', 'httpClient . getState ( ) . setProxyCredentials ( proxyRealm , proxyHost ,', '= new MultiThreadedHttpConnectionManager ( ) ;', 'httpClient . getState ( ) . setCredentials ( c . getRealm ( ) , c . getHost ( ) ,', 'new UsernamePasswordCredentials ( c . getUserName ( ) , c . getPasswd ( ) ) ) ;', '""The HTTP response code for "" + src + "" did not indicate a success . ""', 'final MultiThreadedHttpConnectionManager connManager', '""http . useragent"" , ""Apache Ivy / "" + Ivy . getIvyVersion ( ) ) ;', 'new UsernamePasswordCredentials ( proxyUserName , proxyPasswd ) ) ;', 'Message . verbose ( ""proxy configured : host = "" + proxyHost + "" port = "" + proxyPort', 'proxyRealm = null ;', '+ "" user = "" + proxyUserName ) ;', 'httpClient . getParams ( ) . setParameter (', '+ ""a proxy server that is not well configured . "" ) ;', '+ ""use ivy with sufficient security permissions . "" ) ;', '""The HTTP response code for "" + url + "" did not indicate a success . ""'}}"
50a7fdcaf8fb9a684a96568ceeb8643b4941c475,1.0,IO - 297 CharSequenceInputStream to efficiently stream content of a CharSequence,"{'added_code': {'public CharSequenceInputStream ( final CharSequence s , final Charset charset , int bufferSize ) {', 'if ( result . isError ( ) ) {', 'skipped + + ;', 'this . mark = this . cbuf . position ( ) ;', 'this . bbuf = ByteBuffer . allocate ( 124 ) ;', 'int bytesRead = 0 ;', 'import java . io . IOException ;', 'this . cbuf = CharBuffer . wrap ( s ) ;', 'this . bbuf . flip ( ) ;', 'this ( s , Charset . forName ( charset ) , bufferSize ) ;', 'private final ByteBuffer bbuf ;', 'import java . nio . CharBuffer ;', 'public CharSequenceInputStream ( final CharSequence s , final Charset charset ) {', 'if ( this . mark ! = - 1 ) {', 'import java . nio . charset . CharsetEncoder ;', 'off + = chunk ;', 'bytesRead + = chunk ;', 'fillBuffer ( ) ;', 'public void mark ( int readlimit ) {', 'return - 1 ;', 'private final CharsetEncoder encoder ;', 'this ( s , charset , 2048 ) ;', 'import java . nio . charset . CoderResult ;', 'throw new IndexOutOfBoundsException ( ""Array Size = "" + b . length +', 'this . encoder = charset . newEncoder ( )', '. onUnmappableCharacter ( CodingErrorAction . REPLACE ) ;', 'import java . nio . charset . Charset ;', 'public class CharSequenceInputStream extends InputStream {', 'this . cbuf . position ( this . mark ) ;', 'for ( ; ; ) {', 'private int mark ;', '"" , offset = "" + off + "" , length = "" + len ) ;', 'result . throwException ( ) ;', 'public void close ( ) throws IOException {', 'int skipped = 0 ;', 'public int read ( ) throws IOException {', '} else {', 'if ( len < 0 | | ( off + len ) > b . length ) {', 'while ( len > 0 ) {', 'private void fillBuffer ( ) throws IOException {', 'return skipped ;', 'this . bbuf . get ( b , off , chunk ) ;', 'if ( this . bbuf . hasRemaining ( ) ) {', 'CoderResult result = this . encoder . encode ( this . cbuf , this . bbuf , true ) ;', 'public boolean markSupported ( ) {', 'import java . nio . ByteBuffer ;', 'public long skip ( long n ) throws IOException {', 'if ( !this . bbuf . hasRemaining ( ) & & !this . cbuf . hasRemaining ( ) ) {', '@ Override', 'public int read ( byte [ ] b , int off , int len ) throws IOException {', 'import java . nio . charset . CodingErrorAction ;', 'super ( ) ;', 'len - = chunk ;', 'private final CharBuffer cbuf ;', 'while ( n > 0 & & this . cbuf . hasRemaining ( ) ) {', 'import java . io . InputStream ;', 'throw new NullPointerException ( ""Byte array is null"" ) ;', '}', 'return bytesRead = = 0 & & !this . cbuf . hasRemaining ( ) ? - 1 : bytesRead ;', '. onMalformedInput ( CodingErrorAction . REPLACE )', 'return this . bbuf . get ( ) & 0xFF ;', 'this . bbuf . compact ( ) ;', 'public CharSequenceInputStream ( final CharSequence s , final String charset ) {', 'break ;', 'public void reset ( ) throws IOException {', 'package org . apache . commons . io . input ;', 'this . cbuf . get ( ) ;', 'if ( b = = null ) {', 'int chunk = Math . min ( this . bbuf . remaining ( ) , len ) ;', 'n - - ;', 'public CharSequenceInputStream ( final CharSequence s , final String charset , int bufferSize ) {', 'public int available ( ) throws IOException {', 'this . mark = - 1 ;', 'return this . cbuf . remaining ( ) ;', 'return read ( b , 0 , b . length ) ;', 'return true ;', 'public int read ( byte [ ] b ) throws IOException {'}, 'removed_code': set()}"
fb7e1e265dd9e560b3a3127a6593b6602f60026c,1.0,MATH - 1274 : representation of Kolmogorov - Smirnov statistic as integral value,"{'added_code': {'final double tol = 1e - 12 ;', 'else {', 'if ( curD > = d ) {', 'else if ( - curD > supD ) {', '}', 'final long d = integralKolmogorovSmirnovStatistic ( x , y ) ;', 'return upperBound + 1l ;', 'private double integralExactP ( long d , int n , int m ) {', 'curD + = m ;', 'return integralExactP ( calculateIntegralD ( d , n , m , strict ) , n , m ) ;', 'if ( curD < = - d ) {', 'long curD = 0l ;', 'return integralMonteCarloP ( integralKolmogorovSmirnovStatistic ( x , y ) + ( ( strict ) ? 1l : 0l ) , x . length , y . length , MONTE CARLO ITERATIONS ) ;', 'break ;', 'long nm = n * ( long ) m ;', 'long upperBound = ( long ) FastMath . ceil ( ( d - tol ) * nm ) ;', 'if ( b [ j ] ) {', 'final long curD = integralKolmogorovSmirnovStatistic ( nSet , mSet ) ;', 'curD - = nn ;', 'return integralKolmogorovSmirnovStatistic ( x , y ) / ( ( double ) ( x . length * ( long ) y . length ) ) ;', 'private double integralMonteCarloP ( final long d , final int n , final int m , final int iterations ) {', 'curD - = n ;', 'supD = - curD ;', 'curD + = mm ;', 'return integralMonteCarloP ( calculateIntegralD ( d , n , m , strict ) , n , m , iterations ) ;', 'private static long calculateIntegralD ( double d , int n , int m , boolean strict ) {', 'tail + + ;', 'long supD = 0l ;', 'return upperBound ;', 'private long integralKolmogorovSmirnovStatistic ( double [ ] x , double [ ] y ) {', 'if ( strict & & lowerBound = = upperBound ) {', 'if ( curD > d | | ( curD = = d & & !strict ) ) {', 'return integralExactP ( integralKolmogorovSmirnovStatistic ( x , y ) + ( ( strict ) ? 1l : 0l ) , x . length , y . length ) ;', 'long lowerBound = ( long ) FastMath . floor ( ( d + tol ) * nm ) ;', 'for ( int j = 0 ; j < b . length ; + + j ) {'}, 'removed_code': {'final double curD = kolmogorovSmirnovStatistic ( nSet , mSet ) ;', 'final double tol = 1e - 12 ;', 'final double cdf m = rankM / ( double ) mm ;', 'final double d = kolmogorovSmirnovStatistic ( x , y ) ;', 'previous = b [ j ] ;', '}', 'final int order = Precision . compareTo ( curD , d , tol ) ;', 'final double cdf x = rankX / ( double ) n ;', 'for ( int j = 1 ; j < b . length ; + + j ) {', 'return monteCarloP ( kolmogorovSmirnovStatistic ( x , y ) , x . length , y . length , strict , MONTE CARLO ITERATIONS ) ;', 'import org . apache . commons . math4 . util . Precision ;', 'final double cdf n = rankN / ( double ) nn ;', 'int rankN = b [ 0 ] ? 1 : 0 ;', 'int rankM = b [ 0 ] ? 0 : 1 ;', 'final double curD = FastMath . abs ( cdf x - cdf y ) ;', 'final double curD = FastMath . abs ( cdf n - cdf m ) ;', 'if ( b [ j ] ) {', 'if ( order > 0 | | ( order = = 0 & & !strict ) ) {', 'final double cdf y = rankY / ( double ) m ;', 'rankN + + ;', 'rankM + + ;', 'return exactP ( kolmogorovSmirnovStatistic ( x , y ) , x . length , y . length , strict ) ;', 'if ( b [ j ] ! = previous ) {', 'boolean previous = b [ 0 ] ;', 'double supD = 0d ;'}}"
16e434606776d7961f8b67b7d1062e15f23facf0,1.0,[ VFS - 291 ] ZIP archives are not properly closed after unzipping and cannot be deleted until the JVM exists .,"{'added_code': {'getAbstractFileSystem ( ) . getZipFile ( ) ;', 'protected void doAttach ( ) throws Exception {', '}', 'getAbstractFileSystem ( ) . close ( ) ;', '@ Override', 'protected void doDetach ( ) throws Exception {'}, 'removed_code': set()}"
00513a091d6cebf1ed4c5e2b6619dc36a4b5bbc6,1.0,"Workaround for VFS - 245 - equals ( ) , hashcode ( ) and compareTo ( ) will return the same results regardless of the FileType changing","{'added_code': {'return ( getKey ( ) . equals ( that . getKey ( ) ) ) ;', 'if ( key = = null )', '}', 'private String key = null ;', 'key = createURI ( true , true ) ;', 'return createURI ( false , false ) ;', 'return false ;', 'if ( this = = o )', 'appendRootUri ( buffer , usePassword ) ;', 'if ( o = = null | | getClass ( ) ! = o . getClass ( ) )', 'return key ;', 'return getKey ( ) . compareTo ( name . getKey ( ) ) ;', 'public String getFriendlyURI ( )', 'public boolean equals ( Object o )', 'private String getKey ( )', 'buffer . append ( useAbsolutePath ? absPath : getPath ( ) ) ;', 'return getKey ( ) . hashCode ( ) ;', 'public int hashCode ( )', 'AbstractFileName that = ( AbstractFileName ) o ;', '{', 'return createURI ( false , true ) ;', 'return true ;', 'private String createURI ( boolean useAbsolutePath , boolean usePassword )'}, 'removed_code': {'buffer . append ( getPath ( ) ) ;', 'calculatedHashCode = getRootURI ( ) . hashCode ( ) ^ getPath ( ) . hashCode ( ) ;', 'calculateHashCode = false ;', '}', 'final StringBuilder buffer = new StringBuilder ( ) ;', 'return ret ;', 'public boolean equals ( final Object obj )', 'int ret = getRootURI ( ) . compareTo ( name . getRootURI ( ) ) ;', 'return buffer . toString ( ) ;', 'appendRootUri ( buffer , true ) ;', 'if ( ! ( obj instanceof AbstractFileName ) )', 'private boolean calculateHashCode = true ;', 'return false ;', 'if ( calculateHashCode )', 'appendRootUri ( buffer , false ) ;', 'if ( ret ! = 0 )', 'return getRootURI ( ) . equals ( name . getRootURI ( ) ) & & getPath ( ) . equals ( name . getPath ( ) ) ;', 'try', 'public String getFriendlyURI ( )', 'throw new RuntimeException ( e . getMessage ( ) ) ;', 'return getPathDecoded ( ) . compareTo ( name . getPathDecoded ( ) ) ;', 'return calculatedHashCode ;', 'public int hashCode ( )', 'catch ( FileSystemException e )', '{', 'private int calculatedHashCode ;', 'final AbstractFileName name = ( AbstractFileName ) obj ;'}}"
f1cbfeab32df7fa41945204568e01fb2d4c4a4b8,1.0,Replace StringTokenizer with OpenNLP Tokenizer The StringTokenizer was used to perform white space tokenization long before the WhitespaceTokenizer became a part of OpenNLP . This change also allows to pass in some tokenizer to make it easier to tokenize an input sentence without using pipes . See issue OPENNLP - 857 for more details . Thanks to Tristan Nixon for providing a patch!,"{'added_code': {'Parser parser = ParserFactory . create ( model , beamSize , advancePercentage ) ;', '}', 'import java . util . Arrays ;', 'import opennlp . tools . tokenize . TokenizerME ;', 'Tokenizer tokenizer = WhitespaceTokenizer . INSTANCE ;', 'import opennlp . tools . tokenize . WhitespaceTokenizer ;', 'if ( tokenizerModelName ! = null ) {', 'TokenizerModel tokenizerModel = new TokenizerModelLoader ( ) . load ( new File ( tokenizerModelName ) ) ;', 'import opennlp . tools . cmdline . tokenizer . TokenizerModelLoader ;', 'return parseLine ( line , parser , WhitespaceTokenizer . INSTANCE , numParses ) ;', 'public static Parse [ ] parseLine ( String line , Parser parser , Tokenizer tokenizer , int numParses ) {', 'List < String > tokens = Arrays . asList ( tokenizer . tokenize ( line ) ) ;', 'public static Parse [ ] parseLine ( String line , Parser parser , int numParses ) {', '+ "" - k n : Show the top n parses . This will also display their log - probablities . \\ n""', 'String tokenizerModelName = CmdLineUtil . getParameter ( "" - tk"" , args ) ;', 'import opennlp . tools . tokenize . Tokenizer ;', 'import opennlp . tools . tokenize . TokenizerModel ;', 'import opennlp . tools . parser . Parser ;', 'Parse [ ] parses = parseLine ( line , parser , tokenizer , numParses ) ;', 'return ""Usage : "" + CLI . CMD + "" "" + getName ( ) + "" [ - bs n - ap n - k n - tk tok model ] model < sentences \\ n""', '+ "" - tk tok model : Use the specified tokenizer model to tokenize the sentences . Defaults to a WhitespaceTokenizer . "" ;', 'tokenizer = new TokenizerME ( tokenizerModel ) ;', 'for ( String tok : tokens ) {', 'String text = sb . substring ( 0 , sb . length ( ) ) ;'}, 'removed_code': {'String text = sb . substring ( 0 , sb . length ( ) - 1 ) ;', 'List < String > tokens = new ArrayList < String > ( ) ;', 'while ( str . hasMoreTokens ( ) ) {', 'Parse [ ] parses = parseLine ( line , parser , numParses ) ;', 'import java . util . StringTokenizer ;', '+ "" - k n : Show the top n parses . This will also display their log - probablities . "" ;', 'tokens . add ( tok ) ;', 'String tok = str . nextToken ( ) ;', 'import java . util . ArrayList ;', 'opennlp . tools . parser . Parser parser =', 'StringTokenizer str = new StringTokenizer ( line ) ;', 'return ""Usage : "" + CLI . CMD + "" "" + getName ( ) + "" [ - bs n - ap n - k n ] model < sentences \\ n""', 'public static Parse [ ] parseLine ( String line , opennlp . tools . parser . Parser parser , int numParses ) {', 'ParserFactory . create ( model , beamSize , advancePercentage ) ;'}}"
007ccb24ec4b6f9b8480ec0cfd9bc1894bfdee0e,1.0,Reworked XMLBeanDeclaration to work with new hierarchical configurations . The can now deal with arbitrary node types for which a node handler is available .,"{'added_code': {'Object value = nd . getAttribute ( attr ) ;', 'return handler . getAttributeValue ( node , key ) ;', 'nested . put ( child . nodeName ( ) , createBeanDeclaration ( child ) ) ;', 'import java . util . Set ;', 'protected boolean isReservedName ( String name )', 'private void initSubnodeConfiguration ( HierarchicalConfiguration < ? > conf )', 'return wrapInNodeData ( handler . getChildren ( node ) ) ;', '+ node . nodeName ( ) ) ;', 'public NodeData ( T nd , NodeHandler < T > hndlr )', 'tmpconfiguration = new BaseHierarchicalConfiguration ( ) ;', 'return name = = null | | name . startsWith ( RESERVED PREFIX ) ;', 'BeanDeclaration createBeanDeclaration ( NodeData < ? > node )', 'return getConfiguration ( ) . getString ( ATTR BEAN FACTORY , null ) ;', 'private static boolean isBeanDeclarationArgument ( NodeData < ? > nd )', '}', 'import org . apache . commons . configuration . BaseHierarchicalConfiguration ;', 'NodeData < ? > getNode ( )', 'private List < NodeData < T > > wrapInNodeData ( List < T > nodes )', 'public Object getAttribute ( String key )', 'this . node = createNodeDataFromConfiguration ( tmpconfiguration ) ;', 'for ( NodeData < ? > child : getNode ( ) . getChildren ( ) )', 'return handler . getAttributes ( node ) ;', 'static class NodeData < T >', 'HierarchicalConfiguration < T > config )', '. equals ( node ) ;', 'public < T > XMLBeanDeclaration ( HierarchicalConfiguration < T > config , String key )', 'return !nd . getAttributes ( ) . contains ( ATTR BEAN CLASS NAME ) ;', 'props . put ( key , interpolate ( getNode ( ) . getAttribute ( key ) ) ) ;', 'import org . apache . commons . configuration . tree . NodeHandler ;', 'for ( String key : getNode ( ) . getAttributes ( ) )', 'private final NodeHandler < T > handler ;', 'throw new ConfigurationRuntimeException ( ""Unable to match node for ""', 'handler = hndlr ;', 'node = nd ;', 'private final T node ;', 'public String nodeName ( )', 'return config . getNodeModel ( ) . getNodeHandler ( ) . getRootNode ( )', 'if ( !isReservedName ( key ) )', 'return new XMLBeanDeclaration ( config , node ) ;', 'NodeHandler < T > handler = config . getNodeModel ( ) . getNodeHandler ( ) ;', 'private static < T > NodeData < T > createNodeDataFromConfiguration (', 'if ( node . matchesConfigRootNode ( config ) )', 'NodeData < ? > node )', 'private String getAttribute ( NodeData < ? > nd , String attr )', 'List < NodeData < T > > result = new ArrayList < NodeData < T > > ( nodes . size ( ) ) ;', 'for ( T node : nodes )', 'if ( nested . containsKey ( child . nodeName ( ) ) )', 'return handler . nodeName ( node ) ;', 'if ( !isReservedName ( child . nodeName ( ) ) )', 'return wrapInNodeData ( handler . getChildren ( node , name ) ) ;', 'public < T > XMLBeanDeclaration ( HierarchicalConfiguration < T > config )', '. configurationsAt ( node . nodeName ( ) ) )', 'return ( value = = null ) ? null : String . valueOf ( interpolate ( value ) ) ;', 'public List < NodeData < T > > getChildren ( String name )', 'catch ( ConfigurationRuntimeException iex )', 'result . add ( new NodeData < T > ( node , handler ) ) ;', 'public Set < String > getAttributes ( )', 'nested . put ( child . nodeName ( ) , list ) ;', 'private ConstructorArg createConstructorArg ( NodeData < ? > child )', 'public List < NodeData < T > > getChildren ( )', 'private final HierarchicalConfiguration < ? > configuration ;', 'private final NodeData < ? > node ;', 'Object obj = nested . get ( child . nodeName ( ) ) ;', 'public HierarchicalConfiguration < ? > getConfiguration ( )', 'return node ;', '{', 'public < T > XMLBeanDeclaration ( HierarchicalConfiguration < T > config , String key ,', 'for ( HierarchicalConfiguration < ? > config : getConfiguration ( )', 'XMLBeanDeclaration ( HierarchicalConfiguration < ? > config ,', 'public boolean matchesConfigRootNode ( HierarchicalConfiguration < ? > config )', 'return result ;', 'HierarchicalConfiguration < ? > tmpconfiguration ;', 'getConfiguration ( ) . getInterpolator ( ) ;', 'return new NodeData < T > ( handler . getRootNode ( ) , handler ) ;', 'for ( NodeData < ? > child : getNode ( ) . getChildren ( ELEM CTOR ARG ) )'}, 'removed_code': {'Object obj = nested . get ( child . getName ( ) ) ;', 'private void initSubnodeConfiguration ( SubnodeConfiguration conf )', 'tmpnode = new DefaultConfigurationNode ( ) ;', 'conf . setThrowExceptionOnMissing ( false ) ;', 'public ConfigurationNode getNode ( )', 'else', 'if ( node = = null )', 'private static boolean isBeanDeclarationArgument ( ConfigurationNode nd )', 'for ( ConfigurationNode child : getNode ( ) . getChildren ( ) )', '. valueOf ( interpolate ( attributes . get ( 0 ) . getValue ( ) ) ) ;', '}', 'private final ConfigurationNode node ;', '""Configuration must not be null!"" ) ;', 'public SubnodeConfiguration getConfiguration ( )', 'Iterator < SubnodeConfiguration > iter = list . iterator ( ) ;', 'return attributes . isEmpty ( ) ? null : String', 'tmpnode = tmpconfiguration . getRootNode ( ) ;', 'getConfiguration ( ) . getParent ( ) . getInterpolator ( ) ;', 'if ( nested . containsKey ( child . getName ( ) ) )', 'return nd . getAttributes ( ATTR BEAN CLASS NAME ) . isEmpty ( ) ;', 'private String getAttribute ( ConfigurationNode nd , String attr )', 'import org . apache . commons . configuration . tree . DefaultConfigurationNode ;', 'SubnodeConfiguration tmpconfiguration = null ;', 'ConfigurationNode tmpnode = null ;', 'public XMLBeanDeclaration ( HierarchicalConfiguration config )', 'protected BeanDeclaration createBeanDeclaration ( ConfigurationNode node )', 'catch ( IllegalArgumentException iex )', 'if ( !isReservedNode ( attr ) )', 'props . put ( attr . getName ( ) , interpolate ( attr . getValue ( ) ) ) ;', 'throw new IllegalArgumentException (', 'SubnodeConfiguration config = iter . next ( ) ;', 'return new XMLBeanDeclaration ( config , node ) ;', 'for ( ConfigurationNode attr : getNode ( ) . getAttributes ( ) )', 'this . node = tmpnode ;', 'if ( config . getRootNode ( ) . equals ( node ) )', 'if ( config = = null )', 'while ( iter . hasNext ( ) )', 'public XMLBeanDeclaration ( HierarchicalConfiguration config , String key )', 'for ( ConfigurationNode child : getNode ( ) . getChildren ( ELEM CTOR ARG ) )', 'List < ConfigurationNode > attributes = nd . getAttributes ( attr ) ;', 'return new XMLBeanDeclaration ( list . get ( 0 ) , node ) ;', 'return getConfiguration ( ) . getString ( ATTR BEAN FACTORY ) ;', 'throw new IllegalArgumentException ( ""Node must not be null!"" ) ;', 'tmpconfiguration = config . configurationAt ( null ) ;', 'private final SubnodeConfiguration configuration ;', 'public XMLBeanDeclaration ( HierarchicalConfiguration config , String key ,', 'public XMLBeanDeclaration ( SubnodeConfiguration config ,', 'if ( list . size ( ) = = 1 )', 'throw new ConfigurationRuntimeException ( ""Unable to match node for "" + node . getName ( ) ) ;', 'if ( !isReservedNode ( child ) )', 'import org . apache . commons . configuration . tree . ConfigurationNode ;', 'return node ;', 'nested . put ( child . getName ( ) , createBeanDeclaration ( child ) ) ;', 'import org . apache . commons . configuration . SubnodeConfiguration ;', 'import java . util . Iterator ;', '{', 'ConfigurationNode node )', 'List < SubnodeConfiguration > list = getConfiguration ( ) . configurationsAt ( node . getName ( ) ) ;', 'protected boolean isReservedNode ( ConfigurationNode nd )', 'private ConstructorArg createConstructorArg ( ConfigurationNode child )', 'return nd . getName ( ) = = null | | nd . getName ( ) . startsWith ( RESERVED PREFIX ) ;', 'nested . put ( child . getName ( ) , list ) ;'}}"
25ad33cb9e0c73a0898be36f3dbbf96a5e14efe0,1.0,MATH - 989 Added method to check whether a point is within the interpolation range .,"{'added_code': {'y > yval [ yval . length - 1 ] ) {', 'public boolean isValidPoint ( double x , double y ) {', '} else {', 'y < yval [ 0 ] | |', 'return true ;', 'x > xval [ xval . length - 1 ] | |', '}', 'if ( x < xval [ 0 ] | |', 'return false ;'}, 'removed_code': set()}"
f9ce41a0d6be994f6aceeafaed71f23487770aa5,1.0,Sandbox was not dependent on vfs2 . Convert many StringBuffers to StringBuilder . Convert HashMap to ConcurrentHashMap in Messages class,"{'added_code': {'public AbstractFileName ( final String scheme , final String absPath , FileType type )', 'final StringBuilder buffer = new StringBuilder ( ) ;', 'protected abstract void appendRootUri ( StringBuilder buffer , boolean addPassword ) ;'}, 'removed_code': {'final String absPath , FileType type )', 'public AbstractFileName ( final String scheme ,', 'protected abstract void appendRootUri ( StringBuffer buffer , boolean addPassword ) ;', 'final StringBuffer buffer = new StringBuffer ( ) ;'}}"
84e490b66f61e11366b62efc42e64b60ae7db35b,1.0,IMPROVEMENT : Ivy doesn't support Maven 2 . 0 . 9 'import' scope ( IVY - 807 ),"{'added_code': {'for ( Iterator it2 = depMgt . iterator ( ) ; it2 . hasNext ( ) ; ) {', 'ResolvedModuleRevision importModule = parseOtherPom ( ivySettings ,', 'ModuleRevisionId importModRevID = ModuleRevisionId . newInstance (', 'throw new IOException ( ""Impossible to import module for "" + descriptorURL + "" . ""', 'mdBuilder . addDependencyMgt ( ( PomDependencyMgt ) it2 . next ( ) ) ;', 'if ( ""import"" . equals ( dep . getScope ( ) ) ) {', 'importModRevID ) ;', 'if ( importModule ! = null ) {', 'dep . getGroupId ( ) ,', '+ "" Import = "" + importModRevID ) ;', '}', 'List depMgt = PomModuleDescriptorBuilder . getDependencyManagements ( importDescr ) ;', '} else {', 'mdBuilder . addDependencyMgt ( dep ) ;', 'dep . getArtifactId ( ) ,', 'dep . getVersion ( ) ) ;', 'ModuleDescriptor importDescr = importModule . getDescriptor ( ) ;'}, 'removed_code': {'mdBuilder . addDependencyMgt ( dep ) ;'}}"
ce8cb2ab13dfe6b68fc1ecbf7ae0f165e51014bd,1.0,FIX : Maven 'orbit' and 'pear' packaging is now supported ( IVY - 899 ),"{'added_code': {'""jbi - component"" , ""jbi - shared - library"" , ""orbit"" } ) ;', 'ext = ""phar"" ;', '} else if ( ""pear"" . equals ( packaging ) ) {'}, 'removed_code': {'""jbi - component"" , ""jbi - shared - library"" } ) ;'}}"
d8bbd2f6cb457e84429ef13425851beb272a09af,1.0,NET - 442 StringIndexOutOfBoundsException : String index out of range : - 1 if server respond with root is current directory,"{'added_code': {'int end = reply . lastIndexOf ( "" \\ "" "" ) ;', 'int begin = reply . indexOf ( \'""\' ) ;', 'if ( begin = = - 1 ) {', 'if ( end ! = - 1 ) {', 'return reply . substring ( begin + 1 , end ) . replace ( "" \\ "" \\ """" , "" \\ """" ) ;', '}', 'private static String parsePathname ( String reply )', 'return reply . substring ( REPLY CODE LEN + 1 ) ;'}, 'removed_code': {'return reply . substring ( begin , end ) ;', 'int begin = reply . indexOf ( \'""\' ) + 1 ;', 'private String parsePathname ( String reply )', 'int end = reply . indexOf ( \'""\' , begin ) ;'}}"
24bed1a9bdbe3a1edd46bc3b2af83ee385e041a9,1.0,"GIRAPH - 1046 : Add a way to synchronize full GC calls across workers Summary : In applications which use memory more heavily , we can see full GC pauses happening on different workers at different times , and each of these is causing some delay because other workers are often waiting on something from the worker in GC ( closing open requests , finishing superstep , etc ) . Having a way to coordinate when full GCs are called could help them have less effect on job performance . Test Plan : Ran some memory heavy jobs where I observed overall better performance from using this feature . Differential Revision : https : / / reviews . facebook . net / D55347","{'added_code': {'private static final Logger LOG = Logger . getLogger ( MemoryObserver . class ) ;', 'LOG . info ( ""Manual gc call done"" ) ;', 'import java . util . concurrent . atomic . AtomicLong ;', 'import org . apache . zookeeper . CreateMode ;', 'freeMemoryFraction < freeMemoryFractionForGc ) {', 'import org . apache . zookeeper . KeeperException ;', 'return ;', '""For which fraction of free memory will we issue manual gc calls"" ) ;', 'CreateMode . EPHEMERAL ,', 'import org . apache . giraph . conf . IntConfOption ;', 'Thread . sleep ( MEMORY OBSERVER SLEEP MS ) ;', 'zk . createExt (', 'false ) ;', 'FREE MEMORY FRACTION FOR GC . get ( conf ) ;', 'LOG . warn ( ""Exception occurred"" , e ) ;', 'private static final int MEMORY OBSERVER SLEEP MS = 1000 ;', 'private void setWatcher ( ) {', 'public static final IntConfOption MIN MS BETWEEN FULL GCS =', 'while ( true ) {', 'private final ZooKeeperExt zk ;', 'minMsBetweenFullGcs = MIN MS BETWEEN FULL GCS . get ( conf ) ;', 'freeMemoryFraction + "" % free ) "" ) ;', 'public static final FloatConfOption FREE MEMORY FRACTION FOR GC =', 'setWatcher ( ) ;', 'public static final BooleanConfOption USE MEMORY OBSERVER =', 'final String zkPath , GiraphConfiguration conf ) {', 'new byte [ 0 ] ,', 'if ( msFromLastGc > minMsBetweenFullGcs & &', 'Thread thread = new Thread ( new Runnable ( ) {', 'public void callGc ( ) {', 'private final int minMsBetweenFullGcs ;', 'long msFromLastGc = System . currentTimeMillis ( ) - lastManualGc . get ( ) ;', 'this . zk = zk ;', 'zk . createOnceExt ( zkPath , null , ZooDefs . Ids . OPEN ACL UNSAFE ,', '""Minimum milliseconds between two manual gc calls"" ) ;', 'ZooDefs . Ids . OPEN ACL UNSAFE ,', 'long last = lastManualGc . get ( ) ;', 'if ( System . currentTimeMillis ( ) - last > minMsBetweenFullGcs & &', 'this . zkPath = zkPath ;', 'private final String zkPath ;', 'CreateMode . PERSISTENT , true ) ;', 'public class MemoryObserver {', 'try {', 'zk . getChildrenExt ( zkPath , true , false , false ) ;', 'LOG . info ( ""Calling gc manually"" ) ;', '@ Override', 'final float freeMemoryFractionForGc =', 'public MemoryObserver ( final ZooKeeperExt zk ,', 'System . gc ( ) ;', 'import org . apache . giraph . utils . MemoryUtils ;', 'zkPath + "" / "" + System . currentTimeMillis ( ) ,', 'import org . apache . giraph . conf . FloatConfOption ;', 'package org . apache . giraph . worker ;', 'import org . apache . giraph . conf . GiraphConfiguration ;', '""Whether or not to use memory observer"" ) ;', 'LOG . info ( ""Notifying others about low memory ( "" +', 'import org . apache . giraph . zk . ZooKeeperExt ;', '}', '} catch ( InterruptedException e ) {', 'lastManualGc . compareAndSet ( last , System . currentTimeMillis ( ) ) ) {', 'import org . apache . giraph . conf . BooleanConfOption ;', 'public void run ( ) {', 'if ( !USE MEMORY OBSERVER . get ( conf ) ) {', 'thread . start ( ) ;', 'LOG . info ( ""Exception occurred"" , e ) ;', 'private final AtomicLong lastManualGc = new AtomicLong ( ) ;', 'import org . apache . zookeeper . ZooDefs ;', 'double freeMemoryFraction = MemoryUtils . freeMemoryFraction ( ) ;', 'new BooleanConfOption ( ""giraph . memoryObserver . enabled"" , false ,', '} ) ;', 'thread . setName ( ""memory - observer"" ) ;', 'thread . setDaemon ( true ) ;', 'new IntConfOption ( ""giraph . memoryObserver . minMsBetweenFullGcs"" , 60 * 1000 ,', 'if ( LOG . isInfoEnabled ( ) ) {', 'import org . apache . log4j . Logger ;', '} catch ( KeeperException | InterruptedException e ) {', 'new FloatConfOption ( ""giraph . memoryObserver . freeMemoryFractionForGc"" , 0 . 1f ,'}, 'removed_code': set()}"
ccf1b0aa6159ad15c07cbc75ce6b9f17ad18f9f0,1.0,OPENNLP - 1119 Select sentences randomly and shuffle order of samples The samples should be build from randomly picked lines taken from a sentences file . The samples in the stream should be shuffled .,"{'added_code': {'while ( ( line = lineStream . read ( ) ) ! = null ) {', 'sampleString . append ( line . substring ( textStart ) + "" "" ) ;', 'import java . util . Set ;', 'return new LanguageSample ( new Language ( lang ) , sampleString ) ;', 'int lineIndex = 0 ;', 'count + + ;', 'Collections . shuffle ( indexes , random ) ;', '}', 'import java . util . Collections ;', '. boxed ( ) . collect ( Collectors . toList ( ) ) ;', 'import java . util . List ;', 'import java . nio . file . Files ;', 'private final Random random ;', 'random = new Random ( 23 ) ;', 'int count = 0 ;', 'lineIndex + + ;', 'StringBuilder sampleString = new StringBuilder ( ) ;', 'Collections . shuffle ( sentences , random ) ;', 'if ( selectedLines . contains ( lineIndex ) ) {', 'List < Integer > indexes = IntStream . range ( 0 , totalLineCount )', 'String line = lineIterator . next ( ) ;', 'if ( tabIndex ! = - 1 ) {', 'while ( count < sentencesPerSample & & lineIterator . hasNext ( ) ) {', ""int textStart = line . indexOf ( '' ) + 1 ;"", 'import java . util . HashSet ;', 'indexes . subList ( 0 , sentencesPerSample * numberOfSamples ) ) ;', 'import java . util . Random ;', 'Set < Integer > selectedLines = new HashSet < > (', 'int totalLineCount = ( int ) Files . lines ( sentencesFile . toPath ( ) ) . count ( ) ;', 'try ( ObjectStream < String > lineStream = new PlainTextByLineStream (', 'lineIterator = sentences . iterator ( ) ;', 'String line ;', 'import java . util . ArrayList ;', ""int tabIndex = line . indexOf ( '' ) ;"", 'if ( sampleString . length ( ) > 0 ) {', 'this . lang = lang ;', 'List < String > sentences = new ArrayList < > ( ) ;', 'new MarkableFileInputStreamFactory ( sentencesFile ) , StandardCharsets . UTF 8 ) ) {', 'sentences . add ( line ) ;', 'import java . util . stream . IntStream ;', 'private Iterator < String > lineIterator ;'}, 'removed_code': {'sampleString . append ( line . substring ( textStart ) + "" "" ) ;', 'return new LanguageSample ( new Language ( lang ) , sampleString ) ;', '10 , 100000 ) ;', 'public static void main ( String [ ] args ) throws Exception {', 'count + + ;', 'while ( count < sentencesPerSample & & ( line = lineStream . read ( ) ) ! = null ) {', '}', 'new LeipzigLanguageSampleStream ( new File ( "" / home / blue / opennlp - data - dir / leipzig - lang"" ) ,', 'private int sampleCount ;', 'int count = 0 ;', 'StringBuilder sampleString = new StringBuilder ( ) ;', ""int textStart = line . indexOf ( '' ) + 1 ;"", 'sampleCount + + ;', 'String line ;', 'if ( sampleString . length ( ) > 0 ) {', 'this . numberOfSamples = numberOfSamples ;', 'System . out . println ( sentencesFile ) ;', 'this . lang = sentencesFile . getName ( ) . substring ( 0 , 3 ) ;', 'this . sentencesPerSample = sentencesPerSample ;', 'private ObjectStream < String > lineStream ;', 'private int numberOfSamples ;', 'private int sentencesPerSample ;', 'lineStream = new PlainTextByLineStream ( new MarkableFileInputStreamFactory ( sentencesFile ) ,', 'StandardCharsets . UTF 8 ) ;', 'if ( sampleCount < numberOfSamples ) {'}}"
160a0d35f64a52b9e31a725adc2672498d1f3f29,1.0,"GIRAPH - 1087 : Retry requests after channel failure Summary : We currently don't have a callback to retry requests after channel failure , and would either wait for request timeout or not retrying request at all at places where we don't wait for open requests . Test Plan : Hard to reproduce the issue ( ran many jobs but was unable to ) , we'll see if the problem happens again in prod with this change . Differential Revision : https : / / reviews . facebook . net / D60675","{'added_code': {'super . channelUnregistered ( ctx ) ;', 'checkRequestsAfterChannelFailure ( future . channel ( ) ) ;', 'private void checkRequestsAfterChannelFailure ( final Channel channel ) {', 'LOG . error ( ""Channel failed "" + ctx . channel ( ) ) ;', 'channel . remoteAddress ( ) ) ;', '}', 'Exception {', 'checkRequestsAfterChannelFailure ( ctx . channel ( ) ) ;', 'public void channelUnregistered ( ChannelHandlerContext ctx ) throws', 'return requestInfo . getWriteFuture ( ) . channel ( ) . remoteAddress ( ) . equals (', '@ Override', 'import io . netty . channel . ChannelHandlerContext ;'}, 'removed_code': {'private void checkRequestsAfterChannelFailure ( final ChannelFuture future ) {', 'checkRequestsAfterChannelFailure ( future ) ;', 'return requestInfo . getWriteFuture ( ) = = future ;'}}"
9e2996fef15bac17b20c641900f4e641c40c6aa0,1.0,Checkstyle : Method length is 199 lines ( max allowed is 150 ) . Refactor large method .,"{'added_code': {'private static void setKnownHosts ( JSch jsch , File sshDir , File knownHostsFile ) throws FileSystemException', 'for ( final File privateKeyFile : identities )', 'sshDir = findSshDir ( ) ;', 'else', 'String strictHostKeyChecking = builder . getStrictHostKeyChecking ( fileSystemOptions ) ;', 'if ( identities ! = null )', '}', 'knownHostsFile = new File ( sshDir , ""known hosts"" ) ;', 'addIdentities ( jsch , sshDir , identities ) ;', 'jsch . setKnownHosts ( knownHostsFile . getAbsolutePath ( ) ) ;', 'final File privateKeyFile = new File ( sshDir , ""id rsa"" ) ;', 'if ( knownHostsFile . isFile ( ) & & knownHostsFile . canRead ( ) )', 'setKnownHosts ( jsch , sshDir , knownHostsFile ) ;', 'private static void addIndentity ( JSch jsch , final File privateKeyFile ) throws FileSystemException', 'if ( knownHostsFile ! = null )', 'if ( privateKeyFile . isFile ( ) & & privateKeyFile . canRead ( ) )', 'catch ( final JSchException e )', 'throw new FileSystemException ( ""vfs . provider . sftp / known - hosts . error"" , knownHostsFile . getAbsolutePath ( ) , e ) ;', 'try', 'jsch . addIdentity ( privateKeyFile . getAbsolutePath ( ) ) ;', 'catch ( JSchException e )', 'addIndentity ( jsch , privateKeyFile ) ;', 'session = jsch . getSession ( new String ( username ) , hostname , port ) ;', 'throw new FileSystemException ( ""vfs . provider . sftp / load - private - key . error"" , privateKeyFile , e ) ;', '{', 'String preferredAuthentications = builder . getPreferredAuthentications ( fileSystemOptions ) ;', 'private static void addIdentities ( JSch jsch , File sshDir , File [ ] identities ) throws FileSystemException'}, 'removed_code': {'String strictHostKeyChecking =', 'throw new FileSystemException ( ""vfs . provider . sftp / known - hosts . error"" ,', 'for ( final File privateKeyFile : identities )', 'sshDir = findSshDir ( ) ;', 'else', 'if ( identities ! = null )', '}', 'builder . getStrictHostKeyChecking ( fileSystemOptions ) ;', 'session = jsch . getSession ( new String ( username ) ,', 'knownHostsFile = new File ( sshDir , ""known hosts"" ) ;', 'getPreferredAuthentications ( fileSystemOptions ) ;', 'jsch . setKnownHosts ( knownHostsFile . getAbsolutePath ( ) ) ;', 'final File privateKeyFile = new File ( sshDir , ""id rsa"" ) ;', 'String preferredAuthentications = builder .', 'if ( knownHostsFile . isFile ( ) & & knownHostsFile . canRead ( ) )', 'hostname ,', 'if ( knownHostsFile ! = null )', 'if ( privateKeyFile . isFile ( ) & & privateKeyFile . canRead ( ) )', 'catch ( final JSchException e )', 'try', 'jsch . addIdentity ( privateKeyFile . getAbsolutePath ( ) ) ;', 'catch ( JSchException e )', 'port ) ;', 'knownHostsFile . getAbsolutePath ( ) , e ) ;', 'throw new FileSystemException ( ""vfs . provider . sftp / load - private - key . error"" , privateKeyFile , e ) ;', '{', 'if ( sshDir = = null )'}}"
5035d291aafe4ddf3de657ac41ed4f68521c45b8,1.0,Started rework of INIConfiguration to be compatible with immutable nodes . Loading the configuration now creates a hierarchy of immutable nodes .,"{'added_code': {'for ( Map . Entry < String , ImmutableNode . Builder > e : sectionBuilders', 'String key , String value )', 'private static boolean isSectionNode ( ImmutableNode node )', 'return rootBuilder . create ( ) ;', 'createValueNodes ( sectionBuilder , key , value ) ;', 'import org . apache . commons . configuration . tree . InMemoryNodeModel ;', '}', 'rootBuilder . addChild ( e . getValue ( ) . name ( e . getKey ( ) ) . create ( ) ) ;', 'sectionBuilders . put ( section , sectionBuilder ) ;', 'Map < String , ImmutableNode . Builder > sectionBuilders = new LinkedHashMap < String , ImmutableNode . Builder > ( ) ;', 'line = in . readLine ( ) ;', 'import org . apache . commons . configuration . tree . NodeSelector ;', 'sectionBuilder = sectionBuilders . get ( section ) ;', 'for ( ImmutableNode node : getRootNode ( ) . getChildren ( ) )', 'ImmutableNode . Builder rootBuilder ,', 'InMemoryNodeModel parentModel = getSubConfigurationParentModel ( ) ;', 'private static ImmutableNode createNewRootNode (', 'String line = in . readLine ( ) ;', 'public INIConfiguration ( HierarchicalConfiguration < ImmutableNode > c )', 'private void createValueNodes ( ImmutableNode . Builder sectionBuilder ,', 'Collection < String > values =', 'Configuration subset = getSection ( section ) ;', 'import org . apache . commons . configuration . tree . ImmutableNode ;', 'ImmutableNode rootNode = createNewRootNode ( rootBuilder , sectionBuilders ) ;', 'public HierarchicalConfiguration < ImmutableNode > getSection ( String name )', 'sectionBuilder . addChild ( new ImmutableNode . Builder ( ) . name ( key )', '/ /', 'return !node . getChildren ( ) . isEmpty ( ) ;', 'import java . util . Map ;', 'sectionBuilder = new ImmutableNode . Builder ( ) ;', 'String key ;', 'NodeSelector selector = parentModel . trackChildNodeWithCreation ( null , name , this ) ;', '. value ( v ) . create ( ) ) ;', 'if ( sectionBuilder = = null )', 'import org . apache . commons . configuration . ex . ConfigurationRuntimeException ;', 'createNodeBuilders ( bufferedReader , rootBuilder , sectionBuilders ) ;', 'for ( String section : getSections ( ) )', 'ImmutableNode . Builder sectionBuilder = rootBuilder ;', 'catch ( ConfigurationRuntimeException iex )', 'return null ;', 'value = parseValue ( line . substring ( index + 1 ) , in ) ;', 'throws IOException', 'private void createNodeBuilders ( BufferedReader in ,', 'import java . util . LinkedHashMap ;', 'ImmutableNode . Builder rootBuilder = new ImmutableNode . Builder ( ) ;', 'sections . add ( node . getNodeName ( ) ) ;', 'return createSubConfigurationForTrackedNode ( selector , parentModel ) ;', '{', 'getListDelimiterHandler ( ) . split ( value , false ) ;', '. entrySet ( ) )', 'Map < String , ImmutableNode . Builder > sectionBuilders )', 'addNodes ( null , rootNode . getChildren ( ) ) ;'}, 'removed_code': {'return node . getReference ( ) ! = null | | node . getChildrenCount ( ) > 0 ;', 'import org . apache . commons . configuration . tree . ViewNode ;', 'return createAndInitializeSubnodeConfiguration ( parent , null , false ) ;', 'private ConfigurationNode getSectionNode ( String sectionName )', 'else', 'Collection < String > values = getListDelimiterHandler ( ) . split ( value , false ) ;', 'beginWrite ( false ) ;', 'node . setValue ( v ) ;', 'for ( ConfigurationNode node : getRootNode ( ) . getChildren ( ) )', '}', 'import java . util . List ;', 'String section = it . next ( ) ;', 'createValueNodes ( sectionNode , key , value ) ;', 'value =', 'List < ConfigurationNode > nodes = getRootNode ( ) . getChildren ( sectionName ) ;', 'sections . add ( node . getName ( ) ) ;', 'endWrite ( ) ;', 'catch ( IllegalArgumentException iex )', 'return createAndInitializeSubnodeConfiguration (', 'getRootNode ( ) . addChild ( node ) ;', 'finally', 'String value )', 'while ( it . hasNext ( ) )', 'parent . addChild ( node ) ;', 'try', 'line = bufferedReader . readLine ( ) ;', 'bufferedReader ) ;', 'ConfigurationNode sectionNode = getRootNode ( ) ;', 'String line = bufferedReader . readLine ( ) ;', 'parseValue ( line . substring ( index + 1 ) ,', 'ViewNode parent = new ViewNode ( ) ;', 'markSectionNode ( node ) ;', 'subset = getSection ( null ) ;', 'if ( !isSectionNode ( node ) )', 'String key = """" ;', 'public SubnodeConfiguration getSection ( String name )', 'if ( !nodes . isEmpty ( ) )', 'private static void markSectionNode ( ConfigurationNode node )', 'sectionNode = getSectionNode ( section ) ;', 'Configuration subset ;', 'private void createValueNodes ( ConfigurationNode sectionNode , String key ,', 'node . setReference ( Boolean . TRUE ) ;', 'return node ;', 'import org . apache . commons . configuration . tree . ConfigurationNode ;', 'public INIConfiguration ( HierarchicalConfiguration c )', '{', 'ConfigurationNode node = createNode ( sectionName ) ;', 'subset = createSubnodeConfiguration ( getSectionNode ( section ) , null ) ;', 'return nodes . get ( 0 ) ;', 'private static boolean isSectionNode ( ConfigurationNode node )', 'getSectionNode ( name ) , null , false ) ;', 'Iterator < String > it = getSections ( ) . iterator ( ) ;', 'sectionNode . addChild ( node ) ;', 'ConfigurationNode node = createNode ( key ) ;'}}"
bf30b1f2af61a37d8e1215e1af6022ede913dc2d,1.0,[ BCEL - 304 ] ClassPath . getClassFile does not work with Java 9 and higher .,"{'added_code': {'return ""classes / "" + packageToFolder ( name ) + suffix ;', 'Module ( final ZipFile zip ) {', 'public ClassFile getClassFile ( final String name ) throws IOException {', 'for ( final String module : modules ) {', 'return classPath ;', 'abstract ClassFile getClassFile ( String name , String suffix ) throws IOException ;', 'private static class Module extends AbstractZip {', 'private static class Dir extends AbstractPathEntry {', 'return classPath . hashCode ( ) + parent . hashCode ( ) ;', 'public InputStream getInputStream ( final String name , final String suffix ) throws IOException {', 'private abstract static class AbstractPathEntry {', '}', 'private static abstract class AbstractZip extends AbstractPathEntry {', 'return file . exists ( ) ? new FileInputStream ( file ) : null ;', '} else if ( path . endsWith ( "" . jmod"" ) ) {', 'return entry ! = null ? new URL ( ""jar : file : "" + zip . getName ( ) + ""! / "" + name ) : null ;', 'return name . endsWith ( "" . jmod"" ) ;', 'ClassFile getClassFile ( final String name , final String suffix ) throws IOException {', 'Jar ( final ZipFile zip ) {', 'String modules path = System . getProperty ( ""java . modules . path"" ) ;', 'private final AbstractPathEntry [ ] paths ;', 'public ClassFile getClassFile ( final String name , final String suffix ) throws IOException {', 'private final ZipFile zip ;', 'for ( final AbstractPathEntry path : paths ) {', 'modules path = System . getProperty ( ""java . home"" ) + File . separator + ""jmods"" ;', 'return cf ;', 'AbstractZip ( final ZipFile zip ) {', 'list . add ( new Module ( new ZipFile ( file ) ) ) ;', 'return classPath . hashCode ( ) ;', 'this . zip = zip ;', 'final List < AbstractPathEntry > list = new ArrayList < > ( ) ;', ""return new File ( dir + File . separatorChar + name . replace ( ' / ' , File . separatorChar ) ) ;"", 'return classPath . equals ( cp . toString ( ) ) ;', 'public String getPath ( String name ) throws IOException {', '} ;', 'public String getPath ( final String name , final String suffix ) throws IOException {', 'list . add ( modules dir . getPath ( ) + File . separatorChar + module ) ;', 'return entry ! = null ? zip . getInputStream ( entry ) : null ;', 'final String [ ] modules = modules dir . list ( MODULES FILTER ) ;', ""return name . replace ( ' . ' , ' / ' ) ;"", 'private final String classPath ;', 'list . add ( new Jar ( new ZipFile ( file ) ) ) ;', 'final ClassPath cp = ( ClassPath ) o ;', 'private static void getPathComponents ( final String path , final List < String > list ) {', 'if ( modules dir . exists ( ) ) {', 'public boolean accept ( final File dir , String name ) {', 'if ( modules path = = null | | modules path . trim ( ) . isEmpty ( ) ) {', 'super ( zip ) ;', 'this . classPath = class path ;', '@ Override', 'return null ;', 'protected String toEntryName ( final String name , final String suffix ) {', 'final ClassFile cf = path . getClassFile ( name , suffix ) ;', 'name = name . toLowerCase ( Locale . ENGLISH ) ;', 'private static class Jar extends AbstractZip {', 'return parent + File . pathSeparator + classPath ;', 'public String toString ( ) {', 'public boolean equals ( final Object o ) {', 'return zip . getName ( ) ;', 'public byte [ ] getBytes ( final String name ) throws IOException {', 'final ZipEntry entry = zip . getEntry ( toEntryName ( name , suffix ) ) ;', 'return packageToFolder ( name ) + suffix ;', 'private static final FilenameFilter MODULES FILTER = new FilenameFilter ( ) {', 'final File modules dir = new File ( modules path ) ;', 'static String packageToFolder ( final String name ) {', ""final File file = new File ( dir + File . separatorChar + name . replace ( ' . ' , File . separatorChar ) + suffix ) ;"", 'public InputStream getInputStream ( final String name ) throws IOException {', 'private File toFile ( final String name ) {', 'final File file = toFile ( name ) ;', 'paths = new AbstractPathEntry [ list . size ( ) ] ;', 'if ( cf ! = null ) {', 'protected abstract String toEntryName ( final String name , final String suffix ) ;', 'return getInputStream ( packageToFolder ( name ) , "" . class"" ) ;'}, 'removed_code': {'public ClassFile getClassFile ( final String name ) throws IOException {', 'abstract ClassFile getClassFile ( String name , String suffix ) throws IOException ;', 'private final String class path ;', 'list . add ( new Zip ( new ZipFile ( file ) ) ) ;', 'return class path ;', 'final List < PathEntry > list = new ArrayList < > ( ) ;', 'public InputStream getInputStream ( final String name , final String suffix ) throws IOException {', '}', 'return file . exists ( ) ? new FileInputStream ( file ) : null ;', 'private abstract static class PathEntry {', ""+ name . replace ( ' . ' , File . separatorChar ) + suffix ) ;"", 'ClassFile getClassFile ( final String name , final String suffix ) throws IOException {', 'public ClassFile getClassFile ( final String name , final String suffix ) throws IOException {', 'for ( final PathEntry path : paths ) {', 'return class path . equals ( cp . toString ( ) ) ;', 'private final ZipFile zip ;', 'return cf ;', 'public String getPath ( String name ) throws IOException {', 'public String getPath ( final String name , final String suffix ) throws IOException {', 'private static class Dir extends PathEntry {', 'return parent + File . pathSeparator + class path ;', 'zip = z ;', 'final ClassPath cp = ( ClassPath ) o ;', 'private static void getPathComponents ( final String path , final List < String > list ) {', 'public boolean accept ( final File dir , String name ) {', 'return getInputStream ( name . replace ( \' . \' , \' / \' ) , "" . class"" ) ;', 'return ( entry ! = null ) ? new URL ( ""jar : file : "" + zip . getName ( ) + ""! / "" + name ) : null ;', 'paths = new PathEntry [ list . size ( ) ] ;', 'this . class path = class path ;', 'final File file = new File ( dir + File . separatorChar', 'return null ;', 'final ClassFile cf = path . getClassFile ( name , suffix ) ;', 'private static class Zip extends PathEntry {', 'Zip ( final ZipFile z ) {', 'public boolean equals ( final Object o ) {', 'public byte [ ] getBytes ( final String name ) throws IOException {', ""final File file = new File ( dir + File . separatorChar + name . replace ( ' / ' , File . separatorChar ) ) ;"", 'public InputStream getInputStream ( final String name ) throws IOException {', ""final ZipEntry entry = zip . getEntry ( name . replace ( ' . ' , ' / ' ) + suffix ) ;"", 'private final PathEntry [ ] paths ;', 'return class path . hashCode ( ) + parent . hashCode ( ) ;', 'return class path . hashCode ( ) ;', 'if ( cf ! = null ) {', 'return ( entry ! = null ) ? zip . getInputStream ( entry ) : null ;'}}"
020f71e5fb37fc3ea1f547dd466190910bc78749,1.0,[ IVY - 1299 ] Ivy does not apply overridden properties to parent dependency versions specified using properties,"{'added_code': {'return pomDependencyData ;', 'private PomDependencyDescriptor ( PomDependencyData pomDependencyData ,', 'super ( moduleDescriptor , revisionId , true , false , true ) ;', 'ModuleDescriptor moduleDescriptor , ModuleRevisionId revisionId ) {', 'private final PomDependencyData pomDependencyData ;', 'this . pomDependencyData = pomDependencyData ;', '}', 'public static class PomDependencyDescriptor extends DefaultDependencyDescriptor {', 'DefaultDependencyDescriptor dd = new PomDependencyDescriptor ( dep , ivyModuleDescriptor , moduleRevId ) ;', 'public PomDependencyData getPomDependencyData ( ) {'}, 'removed_code': {'DefaultDependencyDescriptor dd = new DefaultDependencyDescriptor ( ivyModuleDescriptor ,', 'moduleRevId , true , false , true ) ;'}}"
2d1614a2077eab0b981d4a0c4c6e10a7ecda71cf,1.0,[ MATH - 898 ] Finish FuzzyKMeans clustering algorithm .,"{'added_code': {'public FuzzyKMeansClusterer ( final int k , final double fuzziness ) throws NumberIsTooSmallException {', '}', 'if ( fuzziness < = 1 . 0d ) {', 'objFunction + = ( dist * dist ) * FastMath . pow ( membershipMatrix [ i ] [ j ] , fuzziness ) ;', 'throw new MathIllegalStateException ( ) ;', 'this ( k , fuzziness , - 1 , new EuclideanDistance ( ) ) ;', 'private final double fuzziness ;', 'this . fuzziness = fuzziness ;', 'public double getEpsilon ( ) {', 'public FuzzyKMeansClusterer ( final int k , final double fuzziness ,', 'import org . apache . commons . math3 . exception . MathIllegalStateException ;', 'final double dist = distance ( point , cluster . getCenter ( ) ) ;', 'throw new NumberIsTooSmallException ( fuzziness , 1 . 0 , false ) ;', 'sum + = FastMath . pow ( distA / distB , 2 . 0 / ( fuzziness - 1 . 0 ) ) ;', 'return fuzziness ;', 'this ( k , fuzziness , maxIterations , measure , DEFAULT EPSILON , new JDKRandomGenerator ( ) ) ;', 'if ( membershipMatrix = = null ) {', 'public double getFuzziness ( ) {', 'final double u = FastMath . pow ( membershipMatrix [ i ] [ j ] , fuzziness ) ;', 'return epsilon ;'}, 'removed_code': {'private final double fuzzyness ;', 'throw new NumberIsTooSmallException ( fuzzyness , 1 . 0 , false ) ;', 'double dist = distance ( point , cluster . getCenter ( ) ) ;', 'this . fuzzyness = fuzzyness ;', 'return fuzzyness ;', 'this ( k , fuzzyness , maxIterations , measure , DEFAULT EPSILON , new JDKRandomGenerator ( ) ) ;', 'public FuzzyKMeansClusterer ( final int k , final double fuzzyness ) throws NumberIsTooSmallException {', 'sum + = FastMath . pow ( distA / distB , 2 . 0 / ( fuzzyness - 1 . 0 ) ) ;', 'public FuzzyKMeansClusterer ( final int k , final double fuzzyness ,', 'return 0 ;', 'public double getFuzzyness ( ) {', 'final double u = FastMath . pow ( membershipMatrix [ i ] [ j ] , fuzzyness ) ;', 'if ( fuzzyness < = 1 . 0d ) {', 'this ( k , fuzzyness , - 1 , new EuclideanDistance ( ) ) ;', 'objFunction + = ( dist * dist ) * FastMath . pow ( membershipMatrix [ i ] [ j ] , fuzzyness ) ;'}}"
d41364faa4f73fc885dcc9e99a838e8fa4c95998,1.0,Fixed EmpiricalDistrubiton#cumulativeProbability to correctly handle constant bin kernels . JIRA : MATH - 1208 .,"{'added_code': {'final RealDistribution kernel = k ( x ) ;', '}', 'if ( kernel instanceof ConstantRealDistribution ) {', 'return pBminus + pB ;'}, 'removed_code': {'final RealDistribution kernel = k ( x ) ;'}}"
1642b00d67b96de87cad44223efb9ab5b4fb7be5,1.0,[ COLLECTIONS - 580 ] Proposed fix for remote code exploits by disabling de - serialization of InvokerTransformer by default .,"{'added_code': {'} catch ( SecurityException ex ) {', 'public final static String DESERIALIZE', '}', 'public Object run ( ) {', 'String deserializeProperty ;', 'import java . io . IOException ;', '( String ) AccessController . doPrivileged ( new PrivilegedAction ( ) {', 'deserializeProperty = null ;', 'try {', 'import java . security . AccessController ;', 'import java . io . ObjectInputStream ;', 'deserializeProperty =', '} ) ;', 'private void readObject ( ObjectInputStream is ) throws ClassNotFoundException , IOException {', '= ""org . apache . commons . collections . invokertransformer . enableDeserialization"" ;', 'if ( deserializeProperty = = null | | !deserializeProperty . equalsIgnoreCase ( ""true"" ) ) {', 'throw new UnsupportedOperationException ( ""Deserialization of InvokerTransformer is disabled , "" ) ;', 'return System . getProperty ( DESERIALIZE ) ;', 'is . defaultReadObject ( ) ;', 'import java . security . PrivilegedAction ;'}, 'removed_code': set()}"
6e1845426045c86a0d2ba96783c4f2ca8c5d0689,1.0,[ VFS - 442 ] Add an HDFS FileSystem Provider . First commit .,"{'added_code': {'catch ( final IOException e )', 'import org . apache . commons . vfs2 . provider . AbstractFileName ;', 'import org . apache . hadoop . fs . Path ;', 'public boolean equals ( final Object o )', 'else', 'if ( null = = stat )', 'throw new FileNotFolderException ( this ) ;', 'public class HdfsFileObject extends AbstractFileObject < HdfsFileSystem >', 'capabilities . addAll ( HdfsFileProvider . CAPABILITIES ) ;', 'final FileStatus [ ] files = this . hdfs . listStatus ( this . path ) ;', 'super ( rootName , null , fileSystemOptions ) ;', 'if ( this . doGetType ( ) ! = FileType . FOLDER )', 'return this . stat . getModificationTime ( ) ;', 'return ;', 'private final FileSystem hdfs ;', 'final Path filePath = new Path ( path ) ;', 'super . close ( ) ;', 'throw new FileSystemException ( ""Error connecting to filesystem "" + hdfsUri , e ) ;', 'return stat . getLen ( ) ;', 'import java . io . IOException ;', 'private FileSystem fs ;', 'import org . apache . commons . vfs2 . FileSystemOptions ;', 'return false ;', 'import org . apache . commons . vfs2 . Capability ;', 'if ( null ! = fs )', 'final FileObject [ ] fo = new FileObject [ children . length ] ;', 'protected long doGetContentSize ( ) throws Exception', 'import org . apache . commons . vfs2 . FileType ;', 'final Map < String , Object > attrs = new HashMap < String , Object > ( ) ;', 'catch ( final FileNotFoundException fnfe )', 'try', 'import java . util . Map ;', 'catch ( final Exception e )', 'for ( int i = 0 ; i < children . length ; i + + )', 'protected boolean doSetLastModifiedTime ( final long modtime ) throws Exception', 'this . putFileToCache ( file ) ;', 'attrs . put ( HdfsFileAttributes . OWNER . toString ( ) , this . stat . getOwner ( ) ) ;', 'conf . set ( org . apache . hadoop . fs . FileSystem . FS DEFAULT NAME KEY , hdfsUri ) ;', 'this . fs = fs ;', 'public boolean exists ( ) throws FileSystemException', 'return this . stat ! = null ;', 'package org . apache . commons . vfs2 . provider . hdfs ;', 'this . fs = null ;', 'attrs . put ( HdfsFileAttributes . LENGTH . toString ( ) , this . stat . getLen ( ) ) ;', 'private final Path path ;', 'return file ;', 'public FileObject resolveFile ( final FileName name ) throws FileSystemException', 'if ( stat . isDir ( ) )', 'throw new FileSystemException ( ""Unable to check existance "" , e ) ;', 'protected RandomAccessContent doGetRandomAccessContent ( final RandomAccessMode mode ) throws Exception', 'import org . apache . commons . vfs2 . FileSystemException ;', 'fs . close ( ) ;', 'doAttach ( ) ;', 'for ( final FileStatus status : files )', 'protected boolean doIsSameFile ( final FileObject destFile ) throws FileSystemException', 'protected FileObject createFile ( final AbstractFileName name ) throws Exception', 'throw new UnsupportedOperationException ( ) ;', 'if ( null = = file )', 'return - 1 ;', 'return fo ;', 'if ( null ! = this . stat )', 'import java . net . URLDecoder ;', 'if ( null = = o )', 'import org . apache . hadoop . fs . FileStatus ;', 'if ( null = = this . fs )', 'protected void doAttach ( ) throws Exception', 'import org . apache . commons . vfs2 . FileNotFolderException ;', 'protected FileObject [ ] doListChildrenResolved ( ) throws Exception', 'return FileType . FOLDER ;', 'import java . io . FileNotFoundException ;', 'FileObject file = this . getFileFromCache ( name ) ;', 'private FileStatus stat ;', 'throw new FileSystemException ( ""Operation not supported"" ) ;', 'return this . path . getName ( ) . toString ( ) . hashCode ( ) ;', 'attrs . put ( HdfsFileAttributes . MODIFICATION TIME . toString ( ) , this . stat . getModificationTime ( ) ) ;', 'this . stat = this . hdfs . getFileStatus ( this . path ) ;', 'import org . apache . commons . logging . LogFactory ;', 'protected void doRemoveAttribute ( final String attrName ) throws Exception', 'private static final Log log = LogFactory . getLog ( HdfsFileSystem . class ) ;', 'return super . doGetAttributes ( ) ;', '{', 'if ( o instanceof HdfsFileObject )', 'import org . apache . hadoop . fs . FileSystem ;', 'private final HdfsFileSystem fs ;', 'protected FileType doGetType ( ) throws Exception', 'if ( null = = this . stat )', 'final Configuration conf = new Configuration ( true ) ;', 'synchronized ( this )', 'public boolean canRenameTo ( final FileObject newfile )', 'final HdfsFileObject other = ( HdfsFileObject ) o ;', 'protected InputStream doGetInputStream ( ) throws Exception', 'attrs . put ( HdfsFileAttributes . BLOCK SIZE . toString ( ) , this . stat . getBlockSize ( ) ) ;', 'attrs . put ( HdfsFileAttributes . PERMISSIONS . toString ( ) , this . stat . getPermission ( ) . toString ( ) ) ;', 'this . hdfs = hdfs ;', 'import org . apache . commons . vfs2 . provider . AbstractFileSystem ;', 'log . error ( ""Error connecting to filesystem "" + hdfsUri , e ) ;', 'import org . apache . commons . vfs2 . provider . AbstractFileObject ;', 'final String hdfsUri = name . getRootURI ( ) ;', 'file = new HdfsFileObject ( ( AbstractFileName ) name , this , fs , filePath ) ;', 'protected long doGetLastModifiedTime ( ) throws Exception', 'if ( other . path . equals ( this . path ) )', 'import java . util . HashMap ;', 'final Path p = new Path ( this . path , children [ i ] ) ;', 'import java . util . Collection ;', 'path = name . getPath ( ) ;', 'return attrs ;', 'final String [ ] children = new String [ files . length ] ;', 'String path = null ;', '@ Override', 'import org . apache . commons . vfs2 . FileObject ;', 'protected HdfsFileSystem ( final FileName rootName , final FileSystemOptions fileSystemOptions )', 'fs = org . apache . hadoop . fs . FileSystem . get ( conf ) ;', 'import org . apache . commons . vfs2 . util . RandomAccessMode ;', 'public int hashCode ( )', 'throw new RuntimeException ( ""Error closing HDFS client"" , e ) ;', 'protected HdfsFileObject ( final AbstractFileName name , final HdfsFileSystem fs , final FileSystem hdfs , final Path p )', 'protected void doSetAttribute ( final String attrName , final Object value ) throws Exception', 'import org . apache . hadoop . conf . Configuration ;', 'attrs . put ( HdfsFileAttributes . GROUP . toString ( ) , this . stat . getGroup ( ) ) ;', 'public void close ( )', 'protected String [ ] doListChildren ( ) throws Exception', 'public class HdfsFileSystem extends AbstractFileSystem', 'protected boolean doIsWriteable ( ) throws Exception', 'import org . apache . commons . vfs2 . FileName ;', 'super ( name , fs ) ;', 'return children ;', 'protected boolean doIsReadable ( ) throws Exception', 'import java . io . InputStream ;', 'import java . io . UnsupportedEncodingException ;', 'children [ i + + ] = status . getPath ( ) . getName ( ) ;', 'attrs . put ( HdfsFileAttributes . LAST ACCESS TIME . toString ( ) , this . stat . getAccessTime ( ) ) ;', '}', 'catch ( final FileNotFoundException e )', 'return new HdfsRandomAccessContent ( this . path , this . hdfs ) ;', 'protected boolean doIsHidden ( ) throws Exception', 'import org . apache . commons . vfs2 . RandomAccessContent ;', 'if ( mode . equals ( RandomAccessMode . READWRITE ) )', 'return FileType . IMAGINARY ;', 'return this . hdfs . open ( this . path ) ;', 'catch ( final UnsupportedEncodingException e )', 'return FileType . FILE ;', 'if ( o = = this )', 'this . path = p ;', 'int i = 0 ;', 'path = URLDecoder . decode ( name . getPath ( ) , ""UTF - 8"" ) ;', 'catch ( final FileNotFoundException fne )', 'return null ;', 'final String [ ] children = doListChildren ( ) ;', 'import org . apache . commons . logging . Log ;', 'fo [ i ] = this . fs . resolveFile ( p . toUri ( ) . toString ( ) ) ;', 'return true ;', 'protected Map < String , Object > doGetAttributes ( ) throws Exception', 'protected void addCapabilities ( final Collection < Capability > capabilities )'}, 'removed_code': set()}"
03cadc209ee3d5145eadaeb8abb0842ab09a4a17,1.0,Sort in AB order .,"{'added_code': {'protected OutputStream doGetOutputStream ( final boolean bAppend ) throws Exception', 'catch ( final PrivilegedActionException e )', 'fileInfo . setDepth ( curDepth ) ;', 'if ( !getParent ( ) . isWriteable ( ) )', 'return doIsWriteable ( ) ;', '& & fs . hasCapability ( Capability . GET LAST MODIFIED ) )', 'protected boolean doSetExecutable ( final boolean writable , final boolean ownerOnly ) throws Exception', 'finally', 'return fs . getFileSystemManager ( ) . getFileContentInfoFactory ( ) ;', 'selected . add ( file ) ;', 'for ( final FileObject srcFile : files )', 'traverse ( fileInfo , selector , depthwise , selected ) ;', 'protected void doRename ( final FileObject newFile ) throws Exception', 'for ( int iterObjects = 0 ; iterObjects < objects . length ; iterObjects + + )', 'else if ( files . length = = 0 )', 'protected boolean doIsSameFile ( final FileObject destFile ) throws FileSystemException', 'if ( selector . includeFile ( fileInfo ) )', 'return childrenObjects ;', 'removeChildrenCache ( ) ;', 'public FileObject getChild ( final String name ) throws FileSystemException', 'list . remove ( childName ) ;', 'protected void onChildrenChanged ( final FileName child , final FileType newType ) throws Exception', 'protected void doAttach ( ) throws Exception', 'selected . add ( index , file ) ;', 'throw new FileSystemException ( ""vfs . provider / get - type . error"" , e , fileName ) ;', 'if ( depthwise )', 'public OutputStream getOutputStream ( final boolean bAppend ) throws FileSystemException', 'final String scheme = UriParser . extractScheme ( fileName . getURI ( ) , buf ) ;', 'throw new FileSystemException ( ""vfs . provider / get - last - modified - not - supported . error"" ) ;', 'buf . toString ( ) , new DefaultURLStreamHandler ( fs . getContext ( ) , fs . getFileSystemOptions ( ) ) ) ;', 'if ( content ! = null )', 'private static void traverse ( final DefaultFileSelectorInfo fileInfo ,', 'handleDelete ( ) ;', 'throw new FileSystemException ( ""vfs . provider / delete . error"" , exc , fileName ) ;', 'final List < FileObject > list = this . listFiles ( selector ) ;', 'if ( child . getBaseName ( ) . equals ( name ) )', '{', 'protected void childrenChanged ( final FileName childName , final FileType newType ) throws Exception', 'children = EMPTY FILE ARRAY ;', 'notifyParent ( this . getName ( ) , FileType . IMAGINARY ) ;', 'public boolean isHidden ( ) throws FileSystemException', 'final FileSelector selector ,', '& & destFile . getFileSystem ( ) . hasCapability ( Capability . SET LAST MODIFIED FOLDER ) )', 'return exists ( ) ? doIsExecutable ( ) : false ;', 'if ( children = = null )', 'info . setFile ( this ) ;', 'if ( parent = = null )', 'throw new FileSystemException ( ""vfs . provider / remove - attribute - not - supported . error"" ) ;', 'private void attach ( ) throws FileSystemException', 'destFile . createFolder ( ) ;', 'if ( exists ( ) & & !isFile ( ) )', '@ Override', 'int nuofDeleted = 0 ;', 'public boolean isExecutable ( ) throws FileSystemException', 'file . findFiles ( selector , false , files ) ;', 'exc = e ;', 'final int curDepth = fileInfo . getDepth ( ) ;', 'return fileName . getURI ( ) ;', 'final List < FileObject > selected ) throws FileSystemException', 'protected boolean doIsReadable ( ) throws Exception', 'return nuofDeleted ;', 'files = doListChildren ( ) ;', 'content = null ;', 'private FileName [ ] extractNames ( final FileObject [ ] objects )', 'public FileObject resolveFile ( final String path ) throws FileSystemException', 'public void close ( ) throws FileSystemException', 'public boolean isReadable ( ) throws FileSystemException', 'catch ( final FileSystemException exc )', 'public URL getURL ( ) throws FileSystemException', 'if ( !exists ( ) | | selector = = null )', 'public boolean isWriteable ( ) throws FileSystemException', 'fs . fireFileDeleted ( this ) ;', 'public String toString ( )', 'getParent ( ) . getName ( ) ) ;', 'return Collections . emptyMap ( ) ;', 'return resolveFiles ( children ) ;', 'return fs = = newfile . getFileSystem ( ) ;', 'onChange ( ) ;', 'protected void onChange ( ) throws Exception', 'if ( getType ( ) . hasChildren ( ) )', 'public FileObject [ ] findFiles ( final FileSelector selector ) throws FileSystemException', 'throw new FileSystemException ( ""vfs . provider / write . error"" , exc , fileName ) ;', 'throw new FileSystemException ( ""vfs . provider / find - files . error"" , fileName , e ) ;', 'for ( int i = 0 ; i < count ; i + + )', 'public FileObject [ ] getChildren ( ) throws FileSystemException', 'protected boolean isSameFile ( final FileObject destFile ) throws FileSystemException', 'private boolean deleteSelf ( ) throws FileSystemException', 'return resolveFile ( child ) ;', 'destFile . copyFrom ( this , Selectors . SELECT SELF ) ;', 'throw new FileSystemException ( ""vfs . provider / create - file . error"" , fileName , e ) ;', 'public Iterator < FileObject > iterator ( )', 'throw new FileSystemException ( ""vfs . provider / list - children . error"" , exc , fileName ) ;', 'public boolean delete ( ) throws FileSystemException', 'protected void doDelete ( ) throws Exception', 'return parent ;', 'throw new FileSystemException ( ""vfs . provider / create - folder . error"" , fileName , exc ) ;', 'public boolean isContentOpen ( )', 'throw new FileSystemException ( ""vfs . provider / set - executable . error"" , fileName , exc ) ;', 'if ( !exists ( ) )', 'public int deleteAll ( ) throws FileSystemException', 'parent = fs . resolveFile ( fileName . getParent ( ) ) ;', 'final int index = selected . size ( ) ;', 'objects = new ArrayList < Object > ( INITIAL LIST SIZE ) ;', 'public boolean setWritable ( final boolean readable , final boolean ownerOnly ) throws FileSystemException', 'protected RandomAccessContent doGetRandomAccessContent ( final RandomAccessMode mode ) throws Exception', 'if ( !isWriteable ( ) )', 'doAttach ( ) ;', 'super . finalize ( ) ;', 'protected abstract InputStream doGetInputStream ( ) throws Exception ;', 'return exists ( ) ? doIsReadable ( ) : false ;', 'return listFiles ( Selectors . SELECT ALL ) . iterator ( ) ;', 'throw new FileSystemException ( ""vfs . provider / delete - not - supported . error"" ) ;', 'operations = new DefaultFileOperations ( this ) ;', 'protected boolean doIsExecutable ( ) throws Exception', 'detach ( ) ;', 'public FileObject getParent ( ) throws FileSystemException', 'return 1 ;', 'protected void endOutput ( ) throws Exception', 'throw new FileSystemException ( ""vfs . provider / copy - missing - file . error"" , file ) ;', 'children = cache ;', 'final String file = files [ i ] ;', 'return attached ;', 'childrenObjects = doListChildrenResolved ( ) ;', 'fileInfo . setFile ( file ) ;', 'doCreateFolder ( ) ;', 'if ( file = = null )', 'return doGetOutputStream ( bAppend ) ;', 'final FileObject file = fileInfo . getFile ( ) ;', 'private FileObject [ ] resolveFiles ( final FileName [ ] children ) throws FileSystemException', 'public void holdObject ( final Object strongRef )', 'final List < FileObject > selected )', 'if ( file . getType ( ) . hasChildren ( ) & & selector . traverseDescendents ( fileInfo ) )', 'throw new FileSystemException ( ""vfs . provider / check - is - hidden . error"" , fileName , exc ) ;', 'protected long doGetLastModifiedTime ( ) throws Exception', 'if ( childName ! = null & & newType ! = null )', 'return AccessController . doPrivileged ( new PrivilegedExceptionAction < URL > ( )', 'return exists ( ) ? doSetWritable ( readable , ownerOnly ) : false ;', 'if ( ( destFile . getType ( ) . hasContent ( )', 'catch ( final RuntimeException re )', 'final FileObject destFile = resolveFile ( relPath , NameScope . DESCENDENT OR SELF ) ;', 'onChildrenChanged ( childName , newType ) ;', 'return fs ;', 'final boolean depthwise ,', 'protected abstract FileType doGetType ( ) throws Exception ;', 'destFile . close ( ) ;', 'protected boolean doSetWritable ( final boolean writable , final boolean ownerOnly ) throws Exception', 'exc = new FileSystemException ( ""vfs . provider / close . error"" , fileName , e ) ;', 'return fs . resolveFile ( child ) ;', 'throw new FileSystemException ( ""vfs . provider / check - is - writeable . error"" , fileName , exc ) ;', 'traverse ( info , selector , depthwise , selected ) ;', 'notifyParent ( this . getName ( ) , newType ) ;', 'return this . toString ( ) . compareToIgnoreCase ( file . toString ( ) ) ;', 'final DefaultFileSelectorInfo info = new DefaultFileSelectorInfo ( ) ;', 'protected FileContent doCreateFileContent ( ) throws FileSystemException', 'for ( final FileObject child : children )', 'throw new FileSystemException ( ""vfs . provider / get - type . error"" , exc , fileName ) ;', 'final AbstractFileObject file = FileObjectUtils . getAbstractFileObject ( files . get ( i ) ) ;', '}', 'protected abstract long doGetContentSize ( ) throws Exception ;', 'throw new FileSystemException ( ""vfs . provider / check - is - executable . error"" , fileName , exc ) ;', 'handleCreate ( FileType . FILE ) ;', 'if ( files = = null )', 'public void copyFrom ( final FileObject file , final FileSelector selector )', 'names [ iterObjects ] = objects [ iterObjects ] . getName ( ) ;', 'throws Exception', 'if ( childrenObjects ! = null )', 'return list = = null ? null : list . toArray ( new FileObject [ list . size ( ) ] ) ;', 'public void refresh ( ) throws FileSystemException', 'public OutputStream getOutputStream ( ) throws FileSystemException', 'if ( exc ! = null )', 'protected FileContentInfoFactory getFileContentInfoFactory ( )', 'public int delete ( final FileSelector selector ) throws FileSystemException', 'getName ( ) ,', 'return null ;', 'public boolean isFolder ( ) throws FileSystemException', 'return true ;', 'catch ( final IOException e )', 'throw new FileSystemException ( ""vfs . provider / create - folder - mismatched - type . error"" , fileName ) ;', 'else', 'public int compareTo ( final FileObject file )', 'objects [ iterChildren ] = resolveFile ( children [ iterChildren ] ) ;', 'list . add ( childName ) ;', 'attached = true ;', 'public void createFile ( ) throws FileSystemException', 'if ( exists ( ) )', 'cache [ i ] = fs . getFileSystemManager ( ) . resolveName ( fileName , file , NameScope . CHILD ) ;', 'for ( int i = 0 ; i < files . length ; i + + )', 'protected void doCreateFolder ( ) throws Exception', 'if ( type = = null )', 'else if ( srcFile . getType ( ) . hasChildren ( ) )', 'return false ;', 'if ( getType ( ) ! = FileType . IMAGINARY )', 'content . close ( ) ;', 'if ( operations = = null )', 'public URL run ( ) throws MalformedURLException', 'protected boolean doSetLastModifiedTime ( final long modtime ) throws Exception', 'final int count = files . size ( ) ;', 'protected Certificate [ ] doGetCertificates ( ) throws Exception', 'if ( destFile . exists ( ) & & !isSameFile ( destFile ) )', '| | destFile . getType ( ) . hasChildren ( )', 'final FileObject [ ] children = file . getChildren ( ) ;', 'final ArrayList < FileName > list = new ArrayList < FileName > ( Arrays . asList ( children ) ) ;', 'doDelete ( ) ;', 'final FileObject [ ] children = getChildren ( ) ;', 'continue ;', 'doRename ( destFile ) ;', 'final FileObject parent = getParent ( ) ;', 'fs . fireFileCreated ( this ) ;', 'return getType ( ) ! = FileType . IMAGINARY ;', 'endOutput ( ) ;', 'objects . add ( strongRef ) ;', 'protected FileObject [ ] doListChildrenResolved ( ) throws Exception', 'final FileName [ ] cache = new FileName [ files . length ] ;', 'public FileName getName ( )', 'if ( file . getType ( ) . hasChildren ( ) & & file . getChildren ( ) . length ! = 0 )', 'public boolean isFile ( ) throws FileSystemException', 'doDetach ( ) ;', 'protected void doRemoveAttribute ( final String attrName ) throws Exception', 'return parent . isWriteable ( ) ;', 'final ArrayList < FileObject > files = new ArrayList < FileObject > ( ) ;', 'final String [ ] files ;', 'injectType ( FileType . IMAGINARY ) ;', 'final FileObject [ ] objects = new FileObject [ children . length ] ;', 'throw new IllegalStateException ( e ) ;', 'final FileName child = element . getName ( ) ;', 'fileInfo . setDepth ( curDepth + 1 ) ;', 'return exists ( ) ? doIsHidden ( ) : false ;', 'return content . isOpen ( ) ;', 'if ( srcFile . getType ( ) . hasContent ( ) )', 'return FileType . FOLDER . equals ( this . getType ( ) ) ;', 'return operations ;', 'throw new FileSystemException ( ""vfs . provider / create - folder - not - supported . error"" ) ;', 'protected AFS getAbstractFileSystem ( )', 'throw new FileSystemException ( ""vfs . provider / create - file . error"" , fileName ) ;', 'deleteSelf ( ) ;', 'if ( fs . getParentLayer ( ) = = null )', 'setFileType ( null ) ;', 'throw new FileSystemException ( ""vfs . provider / write - append - not - supported . error"" , fileName ) ;', 'if ( objects = = null )', 'if ( newType . equals ( FileType . IMAGINARY ) )', 'getOutputStream ( ) . close ( ) ;', 'private FileObject resolveFile ( final FileName child ) throws FileSystemException', 'throw re ;', 'throw new FileSystemException ( ""vfs . provider / set - writeable . error"" , fileName , exc ) ;', 'throw new FileSystemException ( ""vfs . provider / random - access - not - supported . error"" ) ;', 'protected void doSetAttribute ( final String attrName , final Object value ) throws Exception', 'for ( int iterChildren = 0 ; iterChildren < children . length ; iterChildren + + )', 'return list ;', 'this . findFiles ( selector , true , list ) ;', 'public FileType getType ( ) throws FileSystemException', 'return doIsSameFile ( destFile ) ;', 'attach ( ) ;', 'if ( !fs . hasCapability ( Capability . LIST CHILDREN ) )', 'handleCreate ( FileType . FOLDER ) ;', 'throw new FileSystemException ( ""vfs . provider / set - readable . error"" , fileName , exc ) ;', 'final ArrayList < FileObject > list = new ArrayList < FileObject > ( ) ;', 'throw new FileSystemException ( ""vfs . provider / resync . error"" , fileName , e ) ;', 'public FileSystem getFileSystem ( )', 'throw new FileSystemException ( ""vfs . provider / rename . error"" , exc ,', 'return exists ( ) ? doSetReadable ( readable , ownerOnly ) : false ;', 'if ( getType ( ) = = FileType . IMAGINARY )', 'throws FileSystemException', 'public FileOperations getFileOperations ( ) throws FileSystemException', '} ) ;', 'protected void handleChanged ( ) throws Exception', 'public List < FileObject > listFiles ( final FileSelector selector ) throws FileSystemException', 'throw new FileSystemException ( ""vfs . provider / write - not - supported . error"" ) ;', 'return type ;', 'destFile . getName ( ) ) ;', 'FileUtil . copyContent ( srcFile , destFile ) ;', 'if ( content = = null )', 'return ;', 'FileSystemException exc = null ;', 'children = null ;', 'protected void injectType ( final FileType fileType )', 'list . toArray ( children ) ;', 'throw new FileSystemException ( ""vfs . provider / rename - read - only . error"" , getName ( ) ) ;', 'try', 'throw exc ;', 'catch ( final Exception e )', 'children = extractNames ( childrenObjects ) ;', 'protected void finalize ( ) throws Throwable', 'if ( bAppend & & !fs . hasCapability ( Capability . APPEND CONTENT ) )', 'final FileName [ ] names = new FileName [ objects . length ] ;', 'throw new FileSystemException ( ""vfs . provider / set - attribute - not - supported . error"" ) ;', 'return getOutputStream ( false ) ;', 'return objects ;', 'public void findFiles ( final FileSelector selector ,', 'public boolean exists ( ) throws FileSystemException', 'FileObject [ ] childrenObjects ;', 'private void removeChildrenCache ( )', 'protected void handleDelete ( ) throws Exception', 'throw new FileSystemException ( ""vfs . provider / set - last - modified - not - supported . error"" ) ;', 'catch ( final FileSystemException e )', 'FileObjectUtils . getAbstractFileObject ( destFile ) . handleCreate ( getType ( ) ) ;', 'public boolean setReadable ( final boolean readable , final boolean ownerOnly ) throws FileSystemException', 'public FileObject resolveFile ( final String name , final NameScope scope )', 'return fileName ;', 'if ( canRenameTo ( destFile ) )', 'fs . fileObjectDestroyed ( this ) ;', 'destFile . deleteAll ( ) ;', 'private void detach ( ) throws Exception', 'private FileObject parent ;', 'info . setBaseFolder ( this ) ;', 'protected void doDetach ( ) throws Exception', 'if ( destFile . exists ( ) & & destFile . getType ( ) ! = srcFile . getType ( ) )', 'attached = false ;', 'throw new FileSystemException ( ""vfs . provider / rename - not - supported . error"" ) ;', 'return exists ( ) ? doSetExecutable ( readable , ownerOnly ) : false ;', 'catch ( final Exception exc )', 'if ( this = = fs . getRoot ( ) )', 'final FileName otherName = fs . getFileSystemManager ( ) . resolveName ( fileName , path ) ;', 'destFile . getContent ( ) . setLastModifiedTime ( this . getContent ( ) . getLastModifiedTime ( ) ) ;', 'fileInfo . setFile ( child ) ;', 'fs . fireFileChanged ( this ) ;', 'public boolean setExecutable ( final boolean readable , final boolean ownerOnly ) throws FileSystemException', 'findFiles ( selector , true , files ) ;', 'if ( children ! = null )', 'if ( file . deleteSelf ( ) )', 'if ( !file . exists ( ) )', 'protected void handleCreate ( final FileType newType ) throws Exception', 'for ( final FileObject element : children )', 'public boolean canRenameTo ( final FileObject newfile )', 'return delete ( Selectors . SELECT SELF ) > 0 ;', 'throw new FileSystemException ( ""vfs . provider / rename - parent - read - only . error"" ,', 'throw new FileSystemException ( ""vfs . provider / get - url . error"" , fileName , e . getException ( ) ) ;', 'children = new FileName [ list . size ( ) ] ;', 'setFileType ( FileType . IMAGINARY ) ;', 'parent . createFolder ( ) ;', 'if ( parent ! = null )', 'parent = null ;', 'if ( attached )', 'info . setDepth ( 0 ) ;', 'return new DefaultFileContent ( this , getFileContentInfoFactory ( ) ) ;', 'protected boolean doIsWriteable ( ) throws Exception', 'throw new FileSystemException ( ""vfs . provider / copy - file . error"" , e , srcFile , destFile ) ;', 'return this . delete ( Selectors . SELECT ALL ) ;', 'throw new FileSystemException ( ""vfs . provider / check - is - readable . error"" , fileName , exc ) ;', '& & destFile . getFileSystem ( ) . hasCapability ( Capability . SET LAST MODIFIED FILE )', 'public boolean isAttached ( )', 'synchronized ( fs )', 'public void createFolder ( ) throws FileSystemException', 'public void moveTo ( final FileObject destFile ) throws FileSystemException', 'final StringBuilder buf = new StringBuilder ( ) ;', 'return fs . resolveFile ( fs . getFileSystemManager ( ) . resolveName ( this . fileName , name , scope ) ) ;', 'protected boolean doIsHidden ( ) throws Exception', 'injectType ( newType ) ;', 'return fs . resolveFile ( otherName ) ;', 'throw new FileSystemException ( ""vfs . provider / read . error"" , fileName , exc ) ;', 'nuofDeleted + + ;', 'return fs . getParentLayer ( ) . getParent ( ) ;', 'protected boolean doSetReadable ( final boolean readable , final boolean ownerOnly ) throws Exception', 'return new URL ( scheme , """" , - 1 ,', 'final String relPath = file . getName ( ) . getRelativeName ( srcFile . getName ( ) ) ;', 'protected abstract String [ ] doListChildren ( ) throws Exception ;', 'setFileType ( doGetType ( ) ) ;', 'return FileType . FILE . equals ( this . getType ( ) ) ;', 'protected Map < String , Object > doGetAttributes ( ) throws Exception', 'protected void notifyAllStreamsClosed ( )', 'return names ;', 'setFileType ( fileType ) ;', 'throw new FileNotFolderException ( fileName ) ;'}, 'removed_code': {'protected OutputStream doGetOutputStream ( final boolean bAppend ) throws Exception', 'catch ( final PrivilegedActionException e )', 'fileInfo . setDepth ( curDepth ) ;', 'if ( !getParent ( ) . isWriteable ( ) )', 'return doIsWriteable ( ) ;', '& & fs . hasCapability ( Capability . GET LAST MODIFIED ) )', 'protected boolean doSetExecutable ( final boolean writable , final boolean ownerOnly ) throws Exception', 'finally', 'return fs . getFileSystemManager ( ) . getFileContentInfoFactory ( ) ;', 'selected . add ( file ) ;', 'for ( final FileObject srcFile : files )', 'traverse ( fileInfo , selector , depthwise , selected ) ;', 'protected void doRename ( final FileObject newFile ) throws Exception', 'for ( int iterObjects = 0 ; iterObjects < objects . length ; iterObjects + + )', 'else if ( files . length = = 0 )', 'protected boolean doIsSameFile ( final FileObject destFile ) throws FileSystemException', 'if ( selector . includeFile ( fileInfo ) )', 'return childrenObjects ;', 'removeChildrenCache ( ) ;', 'public FileObject getChild ( final String name ) throws FileSystemException', 'list . remove ( childName ) ;', 'protected void onChildrenChanged ( final FileName child , final FileType newType ) throws Exception', 'protected void doAttach ( ) throws Exception', 'selected . add ( index , file ) ;', 'throw new FileSystemException ( ""vfs . provider / get - type . error"" , e , fileName ) ;', 'if ( depthwise )', 'public OutputStream getOutputStream ( final boolean bAppend ) throws FileSystemException', 'final String scheme = UriParser . extractScheme ( fileName . getURI ( ) , buf ) ;', 'throw new FileSystemException ( ""vfs . provider / get - last - modified - not - supported . error"" ) ;', 'buf . toString ( ) , new DefaultURLStreamHandler ( fs . getContext ( ) , fs . getFileSystemOptions ( ) ) ) ;', 'if ( content ! = null )', 'private static void traverse ( final DefaultFileSelectorInfo fileInfo ,', 'handleDelete ( ) ;', 'throw new FileSystemException ( ""vfs . provider / delete . error"" , exc , fileName ) ;', 'final List < FileObject > list = this . listFiles ( selector ) ;', 'if ( child . getBaseName ( ) . equals ( name ) )', '{', 'protected void childrenChanged ( final FileName childName , final FileType newType ) throws Exception', 'children = EMPTY FILE ARRAY ;', 'notifyParent ( this . getName ( ) , FileType . IMAGINARY ) ;', 'public boolean isHidden ( ) throws FileSystemException', 'final FileSelector selector ,', '& & destFile . getFileSystem ( ) . hasCapability ( Capability . SET LAST MODIFIED FOLDER ) )', 'return exists ( ) ? doIsExecutable ( ) : false ;', 'if ( children = = null )', 'info . setFile ( this ) ;', 'if ( parent = = null )', 'throw new FileSystemException ( ""vfs . provider / remove - attribute - not - supported . error"" ) ;', 'private void attach ( ) throws FileSystemException', 'destFile . createFolder ( ) ;', 'if ( exists ( ) & & !isFile ( ) )', '@ Override', 'int nuofDeleted = 0 ;', 'public boolean isExecutable ( ) throws FileSystemException', 'file . findFiles ( selector , false , files ) ;', 'exc = e ;', 'final int curDepth = fileInfo . getDepth ( ) ;', 'return fileName . getURI ( ) ;', 'final List < FileObject > selected ) throws FileSystemException', 'protected boolean doIsReadable ( ) throws Exception', 'return nuofDeleted ;', 'files = doListChildren ( ) ;', 'content = null ;', 'private FileName [ ] extractNames ( final FileObject [ ] objects )', 'public FileObject resolveFile ( final String path ) throws FileSystemException', 'public void close ( ) throws FileSystemException', 'public boolean isReadable ( ) throws FileSystemException', 'catch ( final FileSystemException exc )', 'public URL getURL ( ) throws FileSystemException', 'if ( !exists ( ) | | selector = = null )', 'public boolean isWriteable ( ) throws FileSystemException', 'fs . fireFileDeleted ( this ) ;', 'public String toString ( )', 'getParent ( ) . getName ( ) ) ;', 'return Collections . emptyMap ( ) ;', 'return resolveFiles ( children ) ;', 'return fs = = newfile . getFileSystem ( ) ;', 'onChange ( ) ;', 'protected void onChange ( ) throws Exception', 'if ( getType ( ) . hasChildren ( ) )', 'public FileObject [ ] findFiles ( final FileSelector selector ) throws FileSystemException', 'throw new FileSystemException ( ""vfs . provider / write . error"" , exc , fileName ) ;', 'throw new FileSystemException ( ""vfs . provider / find - files . error"" , fileName , e ) ;', 'for ( int i = 0 ; i < count ; i + + )', 'public FileObject [ ] getChildren ( ) throws FileSystemException', 'protected boolean isSameFile ( final FileObject destFile ) throws FileSystemException', 'private boolean deleteSelf ( ) throws FileSystemException', 'return resolveFile ( child ) ;', 'destFile . copyFrom ( this , Selectors . SELECT SELF ) ;', 'throw new FileSystemException ( ""vfs . provider / create - file . error"" , fileName , e ) ;', 'public Iterator < FileObject > iterator ( )', 'throw new FileSystemException ( ""vfs . provider / list - children . error"" , exc , fileName ) ;', 'public boolean delete ( ) throws FileSystemException', 'protected void doDelete ( ) throws Exception', 'return parent ;', 'throw new FileSystemException ( ""vfs . provider / create - folder . error"" , fileName , exc ) ;', 'public boolean isContentOpen ( )', 'throw new FileSystemException ( ""vfs . provider / set - executable . error"" , fileName , exc ) ;', 'if ( !exists ( ) )', 'public int deleteAll ( ) throws FileSystemException', 'parent = fs . resolveFile ( fileName . getParent ( ) ) ;', 'final int index = selected . size ( ) ;', 'objects = new ArrayList < Object > ( INITIAL LIST SIZE ) ;', 'public boolean setWritable ( final boolean readable , final boolean ownerOnly ) throws FileSystemException', 'protected RandomAccessContent doGetRandomAccessContent ( final RandomAccessMode mode ) throws Exception', 'if ( !isWriteable ( ) )', 'doAttach ( ) ;', 'super . finalize ( ) ;', 'protected abstract InputStream doGetInputStream ( ) throws Exception ;', 'return exists ( ) ? doIsReadable ( ) : false ;', 'return listFiles ( Selectors . SELECT ALL ) . iterator ( ) ;', 'throw new FileSystemException ( ""vfs . provider / delete - not - supported . error"" ) ;', 'operations = new DefaultFileOperations ( this ) ;', 'protected boolean doIsExecutable ( ) throws Exception', 'detach ( ) ;', 'public FileObject getParent ( ) throws FileSystemException', 'return 1 ;', 'protected void endOutput ( ) throws Exception', 'throw new FileSystemException ( ""vfs . provider / copy - missing - file . error"" , file ) ;', 'children = cache ;', 'final String file = files [ i ] ;', 'return attached ;', 'childrenObjects = doListChildrenResolved ( ) ;', 'fileInfo . setFile ( file ) ;', 'doCreateFolder ( ) ;', 'if ( file = = null )', 'return doGetOutputStream ( bAppend ) ;', 'final FileObject file = fileInfo . getFile ( ) ;', 'private FileObject [ ] resolveFiles ( final FileName [ ] children ) throws FileSystemException', 'public void holdObject ( final Object strongRef )', 'final List < FileObject > selected )', 'if ( file . getType ( ) . hasChildren ( ) & & selector . traverseDescendents ( fileInfo ) )', 'throw new FileSystemException ( ""vfs . provider / check - is - hidden . error"" , fileName , exc ) ;', 'protected long doGetLastModifiedTime ( ) throws Exception', 'if ( childName ! = null & & newType ! = null )', 'return AccessController . doPrivileged ( new PrivilegedExceptionAction < URL > ( )', 'return exists ( ) ? doSetWritable ( readable , ownerOnly ) : false ;', 'if ( ( destFile . getType ( ) . hasContent ( )', 'catch ( final RuntimeException re )', 'final FileObject destFile = resolveFile ( relPath , NameScope . DESCENDENT OR SELF ) ;', 'onChildrenChanged ( childName , newType ) ;', 'return fs ;', 'final boolean depthwise ,', 'protected abstract FileType doGetType ( ) throws Exception ;', 'destFile . close ( ) ;', 'protected boolean doSetWritable ( final boolean writable , final boolean ownerOnly ) throws Exception', 'exc = new FileSystemException ( ""vfs . provider / close . error"" , fileName , e ) ;', 'return fs . resolveFile ( child ) ;', 'throw new FileSystemException ( ""vfs . provider / check - is - writeable . error"" , fileName , exc ) ;', 'traverse ( info , selector , depthwise , selected ) ;', 'notifyParent ( this . getName ( ) , newType ) ;', 'return this . toString ( ) . compareToIgnoreCase ( file . toString ( ) ) ;', 'final DefaultFileSelectorInfo info = new DefaultFileSelectorInfo ( ) ;', 'protected FileContent doCreateFileContent ( ) throws FileSystemException', 'for ( final FileObject child : children )', 'throw new FileSystemException ( ""vfs . provider / get - type . error"" , exc , fileName ) ;', 'final AbstractFileObject file = FileObjectUtils . getAbstractFileObject ( files . get ( i ) ) ;', '}', 'protected abstract long doGetContentSize ( ) throws Exception ;', 'throw new FileSystemException ( ""vfs . provider / check - is - executable . error"" , fileName , exc ) ;', 'handleCreate ( FileType . FILE ) ;', 'if ( files = = null )', 'public void copyFrom ( final FileObject file , final FileSelector selector )', 'names [ iterObjects ] = objects [ iterObjects ] . getName ( ) ;', 'throws Exception', 'if ( childrenObjects ! = null )', 'return list = = null ? null : list . toArray ( new FileObject [ list . size ( ) ] ) ;', 'public void refresh ( ) throws FileSystemException', 'public OutputStream getOutputStream ( ) throws FileSystemException', 'if ( exc ! = null )', 'protected FileContentInfoFactory getFileContentInfoFactory ( )', 'public int delete ( final FileSelector selector ) throws FileSystemException', 'getName ( ) ,', 'return null ;', 'public boolean isFolder ( ) throws FileSystemException', 'return true ;', 'catch ( final IOException e )', 'throw new FileSystemException ( ""vfs . provider / create - folder - mismatched - type . error"" , fileName ) ;', 'else', 'public int compareTo ( final FileObject file )', 'objects [ iterChildren ] = resolveFile ( children [ iterChildren ] ) ;', 'list . add ( childName ) ;', 'attached = true ;', 'public void createFile ( ) throws FileSystemException', 'if ( exists ( ) )', 'cache [ i ] = fs . getFileSystemManager ( ) . resolveName ( fileName , file , NameScope . CHILD ) ;', 'for ( int i = 0 ; i < files . length ; i + + )', 'protected void doCreateFolder ( ) throws Exception', 'if ( type = = null )', 'else if ( srcFile . getType ( ) . hasChildren ( ) )', 'return false ;', 'if ( getType ( ) ! = FileType . IMAGINARY )', 'content . close ( ) ;', 'if ( operations = = null )', 'public URL run ( ) throws MalformedURLException', 'protected boolean doSetLastModifiedTime ( final long modtime ) throws Exception', 'final int count = files . size ( ) ;', 'protected Certificate [ ] doGetCertificates ( ) throws Exception', 'if ( destFile . exists ( ) & & !isSameFile ( destFile ) )', '| | destFile . getType ( ) . hasChildren ( )', 'final FileObject [ ] children = file . getChildren ( ) ;', 'final ArrayList < FileName > list = new ArrayList < FileName > ( Arrays . asList ( children ) ) ;', 'doDelete ( ) ;', 'final FileObject [ ] children = getChildren ( ) ;', 'continue ;', 'doRename ( destFile ) ;', 'final FileObject parent = getParent ( ) ;', 'fs . fireFileCreated ( this ) ;', 'return getType ( ) ! = FileType . IMAGINARY ;', 'endOutput ( ) ;', 'objects . add ( strongRef ) ;', 'protected FileObject [ ] doListChildrenResolved ( ) throws Exception', 'final FileName [ ] cache = new FileName [ files . length ] ;', 'public FileName getName ( )', 'if ( file . getType ( ) . hasChildren ( ) & & file . getChildren ( ) . length ! = 0 )', 'public boolean isFile ( ) throws FileSystemException', 'doDetach ( ) ;', 'protected void doRemoveAttribute ( final String attrName ) throws Exception', 'return parent . isWriteable ( ) ;', 'final ArrayList < FileObject > files = new ArrayList < FileObject > ( ) ;', 'final String [ ] files ;', 'injectType ( FileType . IMAGINARY ) ;', 'final FileObject [ ] objects = new FileObject [ children . length ] ;', 'throw new IllegalStateException ( e ) ;', 'final FileName child = element . getName ( ) ;', 'fileInfo . setDepth ( curDepth + 1 ) ;', 'return exists ( ) ? doIsHidden ( ) : false ;', 'return content . isOpen ( ) ;', 'if ( srcFile . getType ( ) . hasContent ( ) )', 'return FileType . FOLDER . equals ( this . getType ( ) ) ;', 'return operations ;', 'throw new FileSystemException ( ""vfs . provider / create - folder - not - supported . error"" ) ;', 'protected AFS getAbstractFileSystem ( )', 'throw new FileSystemException ( ""vfs . provider / create - file . error"" , fileName ) ;', 'deleteSelf ( ) ;', 'if ( fs . getParentLayer ( ) = = null )', 'setFileType ( null ) ;', 'throw new FileSystemException ( ""vfs . provider / write - append - not - supported . error"" , fileName ) ;', 'if ( objects = = null )', 'if ( newType . equals ( FileType . IMAGINARY ) )', 'getOutputStream ( ) . close ( ) ;', 'private FileObject resolveFile ( final FileName child ) throws FileSystemException', 'throw re ;', 'throw new FileSystemException ( ""vfs . provider / set - writeable . error"" , fileName , exc ) ;', 'throw new FileSystemException ( ""vfs . provider / random - access - not - supported . error"" ) ;', 'protected void doSetAttribute ( final String attrName , final Object value ) throws Exception', 'for ( int iterChildren = 0 ; iterChildren < children . length ; iterChildren + + )', 'return list ;', 'this . findFiles ( selector , true , list ) ;', 'public FileType getType ( ) throws FileSystemException', 'return doIsSameFile ( destFile ) ;', 'attach ( ) ;', 'if ( !fs . hasCapability ( Capability . LIST CHILDREN ) )', 'handleCreate ( FileType . FOLDER ) ;', 'throw new FileSystemException ( ""vfs . provider / set - readable . error"" , fileName , exc ) ;', 'final ArrayList < FileObject > list = new ArrayList < FileObject > ( ) ;', 'throw new FileSystemException ( ""vfs . provider / resync . error"" , fileName , e ) ;', 'public FileSystem getFileSystem ( )', 'throw new FileSystemException ( ""vfs . provider / rename . error"" , exc ,', 'return exists ( ) ? doSetReadable ( readable , ownerOnly ) : false ;', 'if ( getType ( ) = = FileType . IMAGINARY )', 'throws FileSystemException', 'public FileOperations getFileOperations ( ) throws FileSystemException', '} ) ;', 'protected void handleChanged ( ) throws Exception', 'public List < FileObject > listFiles ( final FileSelector selector ) throws FileSystemException', 'throw new FileSystemException ( ""vfs . provider / write - not - supported . error"" ) ;', 'return type ;', 'destFile . getName ( ) ) ;', 'FileUtil . copyContent ( srcFile , destFile ) ;', 'if ( content = = null )', 'return ;', 'FileSystemException exc = null ;', 'children = null ;', 'protected void injectType ( final FileType fileType )', 'list . toArray ( children ) ;', 'throw new FileSystemException ( ""vfs . provider / rename - read - only . error"" , getName ( ) ) ;', 'try', 'throw exc ;', 'catch ( final Exception e )', 'children = extractNames ( childrenObjects ) ;', 'protected void finalize ( ) throws Throwable', 'if ( bAppend & & !fs . hasCapability ( Capability . APPEND CONTENT ) )', 'final FileName [ ] names = new FileName [ objects . length ] ;', 'throw new FileSystemException ( ""vfs . provider / set - attribute - not - supported . error"" ) ;', 'return getOutputStream ( false ) ;', 'return objects ;', 'public void findFiles ( final FileSelector selector ,', 'public boolean exists ( ) throws FileSystemException', 'FileObject [ ] childrenObjects ;', 'private void removeChildrenCache ( )', 'protected void handleDelete ( ) throws Exception', 'throw new FileSystemException ( ""vfs . provider / set - last - modified - not - supported . error"" ) ;', 'catch ( final FileSystemException e )', 'FileObjectUtils . getAbstractFileObject ( destFile ) . handleCreate ( getType ( ) ) ;', 'public boolean setReadable ( final boolean readable , final boolean ownerOnly ) throws FileSystemException', 'public FileObject resolveFile ( final String name , final NameScope scope )', 'return fileName ;', 'if ( canRenameTo ( destFile ) )', 'fs . fileObjectDestroyed ( this ) ;', 'destFile . deleteAll ( ) ;', 'private void detach ( ) throws Exception', 'private FileObject parent ;', 'info . setBaseFolder ( this ) ;', 'protected void doDetach ( ) throws Exception', 'if ( destFile . exists ( ) & & destFile . getType ( ) ! = srcFile . getType ( ) )', 'attached = false ;', 'throw new FileSystemException ( ""vfs . provider / rename - not - supported . error"" ) ;', 'return exists ( ) ? doSetExecutable ( readable , ownerOnly ) : false ;', 'catch ( final Exception exc )', 'if ( this = = fs . getRoot ( ) )', 'final FileName otherName = fs . getFileSystemManager ( ) . resolveName ( fileName , path ) ;', 'destFile . getContent ( ) . setLastModifiedTime ( this . getContent ( ) . getLastModifiedTime ( ) ) ;', 'fileInfo . setFile ( child ) ;', 'fs . fireFileChanged ( this ) ;', 'public boolean setExecutable ( final boolean readable , final boolean ownerOnly ) throws FileSystemException', 'findFiles ( selector , true , files ) ;', 'if ( children ! = null )', 'if ( file . deleteSelf ( ) )', 'if ( !file . exists ( ) )', 'protected void handleCreate ( final FileType newType ) throws Exception', 'for ( final FileObject element : children )', 'public boolean canRenameTo ( final FileObject newfile )', 'return delete ( Selectors . SELECT SELF ) > 0 ;', 'throw new FileSystemException ( ""vfs . provider / rename - parent - read - only . error"" ,', 'throw new FileSystemException ( ""vfs . provider / get - url . error"" , fileName , e . getException ( ) ) ;', 'children = new FileName [ list . size ( ) ] ;', 'setFileType ( FileType . IMAGINARY ) ;', 'parent . createFolder ( ) ;', 'if ( parent ! = null )', 'parent = null ;', 'if ( attached )', 'info . setDepth ( 0 ) ;', 'return new DefaultFileContent ( this , getFileContentInfoFactory ( ) ) ;', 'protected boolean doIsWriteable ( ) throws Exception', 'throw new FileSystemException ( ""vfs . provider / copy - file . error"" , e , srcFile , destFile ) ;', 'return this . delete ( Selectors . SELECT ALL ) ;', 'throw new FileSystemException ( ""vfs . provider / check - is - readable . error"" , fileName , exc ) ;', '& & destFile . getFileSystem ( ) . hasCapability ( Capability . SET LAST MODIFIED FILE )', 'public boolean isAttached ( )', 'synchronized ( fs )', 'public void createFolder ( ) throws FileSystemException', 'public void moveTo ( final FileObject destFile ) throws FileSystemException', 'final StringBuilder buf = new StringBuilder ( ) ;', 'return fs . resolveFile ( fs . getFileSystemManager ( ) . resolveName ( this . fileName , name , scope ) ) ;', 'protected boolean doIsHidden ( ) throws Exception', 'injectType ( newType ) ;', 'return fs . resolveFile ( otherName ) ;', 'throw new FileSystemException ( ""vfs . provider / read . error"" , fileName , exc ) ;', 'nuofDeleted + + ;', 'return fs . getParentLayer ( ) . getParent ( ) ;', 'protected boolean doSetReadable ( final boolean readable , final boolean ownerOnly ) throws Exception', 'return new URL ( scheme , """" , - 1 ,', 'final String relPath = file . getName ( ) . getRelativeName ( srcFile . getName ( ) ) ;', 'protected abstract String [ ] doListChildren ( ) throws Exception ;', 'setFileType ( doGetType ( ) ) ;', 'return FileType . FILE . equals ( this . getType ( ) ) ;', 'protected Map < String , Object > doGetAttributes ( ) throws Exception', 'protected void notifyAllStreamsClosed ( )', 'return names ;', 'setFileType ( fileType ) ;', 'throw new FileNotFolderException ( fileName ) ;'}}"
72562004cfa5106472f61efc5d456788bbc256f9,1.0,"GIRAPH - 1086 : Use pool of byte arrays with InMemoryDataAccessor Summary : Have a pool of byte arrays with InMemoryDataAccessor , to save on byte array creation and initialization . Test Plan : Improved performance of a job using InMemoryDataAccessor Differential Revision : https : / / reviews . facebook . net / D60621","{'added_code': {'protected ExtendedDataOutput currentDataOutput ;', 'currentDataOutput = createOutput ( initialSize ) ;', 'private ExtendedDataOutput getDataOutputToWriteTo ( int additionalSize ) {', 'getDataOutputToWriteTo ( len + SIZE DELTA ) . write ( b , off , len ) ;', 'protected List < ExtendedDataOutput > dataOutputs ;', 'return conf . createExtendedDataOutput ( size ) ;', 'return MAX SIZE ;', 'protected int getMaxSize ( ) {', 'return currentDataOutput ;', '}', 'getDataOutputToWriteTo ( b . length + SIZE DELTA ) . write ( b ) ;', 'if ( currentDataOutput . getPos ( ) + additionalSize > = getMaxSize ( ) ) {', 'currentDataOutput = createOutput ( getMaxSize ( ) ) ;', 'protected final ImmutableClassesGiraphConfiguration conf ;', 'protected ExtendedDataOutput createOutput ( int size ) {', 'return getDataOutputToWriteTo ( SIZE DELTA ) ;', 'dataOutputs = new ArrayList < > ( 1 ) ;'}, 'removed_code': {'private final ImmutableClassesGiraphConfiguration conf ;', 'private List < ExtendedDataOutput > dataOutputs ;', 'currentDataOutput = conf . createExtendedDataOutput ( MAX SIZE ) ;', '} else {', 'currentDataOutput = conf . createExtendedDataOutput ( initialSize ) ;', 'if ( currentDataOutput . getPos ( ) + SIZE DELTA < MAX SIZE ) {', 'return currentDataOutput ;', 'dataOutputs = new ArrayList < ExtendedDataOutput > ( 1 ) ;', 'getDataOutputToWriteTo ( ) . write ( b ) ;', 'private ExtendedDataOutput currentDataOutput ;', 'getDataOutputToWriteTo ( ) . write ( b , off , len ) ;'}}"
dc4d9a2a7f5d2e40fc1e28c3b8da011306d7dccc,1.0,GIRAPH - 975 In - proc ZooKeeper server with Master process https : / / reviews . facebook . net / D30693,"{'added_code': {'ServerConfig serverConfig = new ServerConfig ( ) ;', 'LOG . warn ( ""Neither quorum nor server is set"" ) ;', 'quorumPeer . shutdown ( ) ;', 'quorumRunner . start ( configFilePath ) ;', '} catch ( IOException e ) {', 'QuorumPeerConfig quorumPeerConfig = new QuorumPeerConfig ( ) ;', '. getDataDir ( ) , quorumPeerConfig . getDataLogDir ( ) , quorumPeerConfig', 'quorumRunner . stop ( ) ;', 'private static class QuorumRunner extends QuorumPeerMain {', '} else {', 'private static class ZooKeeperServerRunner extends ZooKeeperServerMain {', 'implements ZooKeeperRunner {', 'if ( quorumPeer ! = null ) {', 'runFromConfig ( serverConfig ) ;', '}', 'ManagedUtil . registerLog4jMBeans ( ) ;', 'zkThread . start ( ) ;', 'Thread zkThread = new Thread ( new Runnable ( ) {', 'import org . apache . zookeeper . server . quorum . QuorumPeerMain ;', 'QuorumPeerConfig . ConfigException , IOException {', '} catch ( QuorumPeerConfig . ConfigException e ) {', '} catch ( InterruptedException e ) {', 'public void start ( String configFilePath ) throws IOException ,', 'Logger . getLogger ( InProcessZooKeeperRunner . class ) ;', 'LOG . info ( ""Initialization ended"" ) ;', 'public void cleanup ( ) {', 'public void run ( ) {', 'import java . io . IOException ;', 'serverConfig . parse ( configFilePath ) ;', 'public class InProcessZooKeeperRunner', 'QuorumPeerConfig . ConfigException {', 'serverRunner . start ( configFilePath ) ;', 'import org . apache . zookeeper . server . DatadirCleanupManager ;', '"" in standalone mode"" ) ;', 'LOG . error ( ""Invalid config , zookeeper failed"" , e ) ;', 'shutdown ( ) ;', 'import org . apache . zookeeper . server . ZooKeeperServerMain ;', 'DatadirCleanupManager purgeMgr = new DatadirCleanupManager (', 'import org . apache . giraph . conf . DefaultImmutableClassesGiraphConfigurable ;', 'try {', 'public void start ( String zkDir , final String configFilePath ) {', 'private static final Logger LOG =', 'serverRunner = new ZooKeeperServerRunner ( ) ;', 'runFromConfig ( quorumPeerConfig ) ;', 'LOG . error ( ""Unable to cleanly shutdown zookeeper"" , e ) ;', 'import org . apache . zookeeper . server . quorum . QuorumPeerConfig ;', 'quorumPeerConfig', 'private ZooKeeperServerRunner serverRunner ;', 'public void start ( String configFilePath ) throws', 'if ( quorumPeerConfig . getServers ( ) . size ( ) > 0 ) {', 'LOG . warn ( ""Either no config or no quorum defined in config , running "" +', '@ Override', 'package org . apache . giraph . zk ;', 'import javax . management . JMException ;', '} ) ;', 'private QuorumRunner quorumRunner = new QuorumRunner ( ) ;', '} else if ( serverRunner ! = null ) {', '. getSnapRetainCount ( ) , quorumPeerConfig . getPurgeInterval ( ) ) ;', 'LOG . warn ( ""Unable to register log4j JMX control"" , e ) ;', 'public void stop ( ) {', 'serverRunner . stop ( ) ;', 'import org . apache . zookeeper . jmx . ManagedUtil ;', 'zkThread . setDaemon ( true ) ;', 'extends DefaultImmutableClassesGiraphConfigurable', 'purgeMgr . start ( ) ;', 'public void stop ( ) throws InterruptedException {', 'import org . apache . zookeeper . server . ServerConfig ;', 'quorumPeer . join ( ) ;', 'quorumPeerConfig . parse ( configFilePath ) ;', 'LOG . error ( ""Unable to start zookeeper"" , e ) ;', '} catch ( JMException e ) {', 'import org . apache . log4j . Logger ;'}, 'removed_code': set()}"
1c9c43c1d4bb76d7e47cdfc9c6681a38305a95e4,1.0,MATH - 1274 : representation of Kolmogorov - Smirnov statistic as integral value,"{'added_code': {'final double tol = 1e - 12 ;', 'else {', 'long tail = 0 ;', 'if ( curD > = d ) {', 'else if ( - curD > supD ) {', '} else {', '}', 'Iterator < int [ ] > combinationsIterator = CombinatoricsUtils . combinationsIterator ( n + m , n ) ;', 'final long d = integralKolmogorovSmirnovStatistic ( x , y ) ;', 'mSet [ k + + ] = universe [ i ] ;', 'final double [ ] mSet = new double [ m ] ;', 'System . arraycopy ( x , 0 , universe , 0 , n ) ;', 'final int [ ] nSetI = combinationsIterator . next ( ) ;', 'System . arraycopy ( y , 0 , universe , n , m ) ;', 'return upperBound + 1l ;', 'private double integralExactP ( long d , int n , int m ) {', 'curD + = m ;', 'return integralExactP ( calculateIntegralD ( d , n , m , strict ) , n , m ) ;', 'if ( curD < = - d ) {', 'public double exactP ( double [ ] x , double [ ] y , boolean strict ) {', 'if ( j < n & & nSetI [ j ] = = i ) {', 'final double [ ] universe = new double [ n + m ] ;', 'long curD = 0l ;', 'return integralMonteCarloP ( integralKolmogorovSmirnovStatistic ( x , y ) + ( ( strict ) ? 1l : 0l ) , x . length , y . length , MONTE CARLO ITERATIONS ) ;', 'final int n = x . length ;', 'break ;', 'long nm = n * ( long ) m ;', 'final double [ ] nSet = new double [ n ] ;', 'long upperBound = ( long ) FastMath . ceil ( ( d - tol ) * nm ) ;', 'final long curD = integralKolmogorovSmirnovStatistic ( nSet , mSet ) ;', 'return integralKolmogorovSmirnovStatistic ( x , y ) / ( ( double ) ( x . length * ( long ) y . length ) ) ;', 'if ( b [ j ] ) {', 'curD - = nn ;', 'private double integralMonteCarloP ( final long d , final int n , final int m , final int iterations ) {', 'final int m = y . length ;', 'supD = - curD ;', 'curD - = n ;', 'return ( double ) tail / ( double ) CombinatoricsUtils . binomialCoefficient ( n + m , n ) ;', 'while ( combinationsIterator . hasNext ( ) ) {', 'curD + = mm ;', 'return integralMonteCarloP ( calculateIntegralD ( d , n , m , strict ) , n , m , iterations ) ;', 'for ( int i = 0 ; i < n + m ; i + + ) {', 'private static long calculateIntegralD ( double d , int n , int m , boolean strict ) {', 'tail + + ;', 'int k = 0 ;', 'long supD = 0l ;', 'return upperBound ;', 'private long integralKolmogorovSmirnovStatistic ( double [ ] x , double [ ] y ) {', 'if ( strict & & lowerBound = = upperBound ) {', 'if ( curD > d | | ( curD = = d & & !strict ) ) {', 'return integralExactP ( integralKolmogorovSmirnovStatistic ( x , y ) + ( ( strict ) ? 1l : 0l ) , x . length , y . length ) ;', 'nSet [ j + + ] = universe [ i ] ;', 'int j = 0 ;', 'long lowerBound = ( long ) FastMath . floor ( ( d + tol ) * nm ) ;', 'for ( int j = 0 ; j < b . length ; + + j ) {'}, 'removed_code': {'final double curD = kolmogorovSmirnovStatistic ( nSet , mSet ) ;', 'final double tol = 1e - 12 ;', 'final double cdf m = rankM / ( double ) mm ;', 'previous = b [ j ] ;', '}', 'final int order = Precision . compareTo ( curD , d , tol ) ;', 'final double cdf x = rankX / ( double ) n ;', 'for ( int j = 1 ; j < b . length ; + + j ) {', 'return monteCarloP ( kolmogorovSmirnovStatistic ( x , y ) , x . length , y . length , strict , MONTE CARLO ITERATIONS ) ;', 'final double cdf n = rankN / ( double ) nn ;', 'int rankN = b [ 0 ] ? 1 : 0 ;', 'int rankM = b [ 0 ] ? 0 : 1 ;', 'final double curD = FastMath . abs ( cdf x - cdf y ) ;', 'final double curD = FastMath . abs ( cdf n - cdf m ) ;', 'if ( b [ j ] ) {', 'if ( order > 0 | | ( order = = 0 & & !strict ) ) {', 'import org . apache . commons . math3 . util . Precision ;', 'final double cdf y = rankY / ( double ) m ;', 'rankN + + ;', 'rankM + + ;', 'return exactP ( kolmogorovSmirnovStatistic ( x , y ) , x . length , y . length , strict ) ;', 'if ( b [ j ] ! = previous ) {', 'boolean previous = b [ 0 ] ;', 'double supD = 0d ;'}}"
0637e2fbcd401f47bb062d5c2d1cceddabf372b7,1.0,PARQUET - 360 : Handle all map key types with cat tool's json dump When dumping a parquet map with `parquet - cat - - json` it throws a class cast exception as it doesn't properly handle all map key types . ``` java . lang . ClassCastException : [ B cannot be cast to java . lang . String at org . apache . parquet . tools . read . SimpleMapRecord . toJsonObject ( SimpleMapRecord . java : 34 ) at org . apache . parquet . tools . read . SimpleRecord . toJsonValue ( SimpleRecord . java : 119 ) at org . apache . parquet . tools . read . SimpleRecord . toJsonObject ( SimpleRecord . java : 112 ) at org . apache . parquet . tools . read . SimpleRecord . prettyPrintJson ( SimpleRecord . java : 106 ) at org . apache . parquet . tools . command . CatCommand . execute ( CatCommand . java : 76 ) at org . apache . parquet . tools . Main . main ( Main . java : 222 ) [ B cannot be cast to java . lang . String ``` Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #259 from nezihyigitbasi / parquet - cat - json and squashes the following commits : d047502 [ Nezih Yigitbasi ] Add unit test e4cd545 [ Nezih Yigitbasi ] Get rid of deprecated methods bdc8fdf [ Nezih Yigitbasi ] Handle all map key types with cat tool's json dump,"{'added_code': {'import static org . apache . parquet . format . converter . ParquetMetadataConverter . NO FILTER ;', 'import org . apache . parquet . format . converter . ParquetMetadataConverter ;', 'ParquetMetadata metaData = ParquetFileReader . readFooter ( conf , inpath , NO FILTER ) ;'}, 'removed_code': {'ParquetMetadata metaData = ParquetFileReader . readFooter ( conf , inpath ) ;'}}"
1f8cfe7d2b2306384243cae9a45de523f4e0a8f8,1.0,Ensure all conditional statements use blocks ( no code change ),"{'added_code': {'if ( input ! = null ) {', 'if ( listener ! = null ) {', 'if ( lastBlock = = ( block = = 0 ? 65535 : ( block - 1 ) ) ) {', 'if ( mode = = TFTP . ASCII MODE ) {', 'if ( numTimeouts < 1 ) {', 'if ( output ! = null ) {', '} else if ( isType = = MEMBER LIST TYPE ) {', 'if ( isType = = FILE LIST TYPE ) {', 'if ( file = = null ) {', '} else {', '}', 'if ( !isParsed ) {', 'if ( message . length < 1 ) {'}, 'removed_code': {'if ( lastBlock = = ( block = = 0 ? 65535 : ( block - 1 ) ) )', 'if ( message . length < 1 )', 'if ( input ! = null )', 'if ( isType = = FILE LIST TYPE )', 'if ( mode = = TFTP . ASCII MODE )', 'if ( !isParsed )', 'if ( file = = null )', 'if ( listener ! = null )', 'else', 'if ( numTimeouts < 1 )', 'else if ( isType = = MEMBER LIST TYPE ) {', 'if ( output ! = null )'}}"
06c38617a3b7e708688fdcf2f001c82f5d1a2f2a,1.0,enhanced [ DIGESTER - 153 ] by appliyng the patch kindly provided by Matt Benson,"{'added_code': {'reportError ( ""createObject ( ) . usingDefaultConstructorArguments ( Object [ ] ) "" , ""NULL defaultConstructorArguments not allowed"" ) ;', 'paramTypes [ i ] = classLoader . loadClass ( paramTypeNames [ i ] ) ;', 'objectCreateRule . setDefaultConstructorArguments ( defaultConstructorArguments ) ;', 'if ( defaultConstructorArguments ! = null )', 'this . reportError ( format ( ""createObject ( ) . usingConstructor ( % s ) "" ,', '}', 'import java . util . Collections ;', 'primitiveTypes . put ( ""double"" , double . class ) ;', 'primitiveTypes . put ( ""long"" , long . class ) ;', 'public ObjectCreateBuilder usingDefaultConstructorArguments ( Object . . . defaultConstructorArguments )', 'HashMap < String , Class < ? > > primitiveTypes = new HashMap < String , Class < ? > > ( ) ;', 'continue ;', 'primitiveTypes . put ( ""byte"" , byte . class ) ;', 'return this ;', 'primitiveTypes . put ( ""boolean"" , boolean . class ) ;', 'format ( ""class \' % s\' cannot be loaded"" , paramTypeNames [ i ] ) ) ;', 'if ( PRIMITIVE TYPES . containsKey ( paramTypeNames [ i ] ) )', 'catch ( ClassNotFoundException e )', 'for ( int i = 0 ; i < paramTypeNames . length ; i + + )', 'Class < ? > [ ] paramTypes = new Class < ? > [ paramTypeNames . length ] ;', 'primitiveTypes . put ( ""char"" , char . class ) ;', 'if ( constructorArgumentTypes = = null )', 'try', 'import java . util . Map ;', 'import java . util . HashMap ;', 'PRIMITIVE TYPES = Collections . unmodifiableMap ( primitiveTypes ) ;', 'static', 'public ObjectCreateBuilder usingConstructor ( Class < ? > . . . constructorArgumentTypes )', 'private static final Map < String , Class < ? > > PRIMITIVE TYPES ;', 'this . constructorArgumentsType = constructorArgumentTypes ;', 'this . defaultConstructorArguments = defaultConstructorArguments ;', 'Arrays . toString ( paramTypeNames ) ) ,', 'objectCreateRule . setConstructorArgumentTypes ( constructorArgumentsType ) ;', 'primitiveTypes . put ( ""int"" , int . class ) ;', 'reportError ( ""createObject ( ) . usingConstructor ( Class < ? > [ ] ) "" , ""NULL constructorArgumentTypes not allowed"" ) ;', 'paramTypes [ i ] = PRIMITIVE TYPES . get ( paramTypeNames [ i ] ) ;', '{', 'primitiveTypes . put ( ""short"" , short . class ) ;', 'private Object [ ] defaultConstructorArguments ;', 'if ( defaultConstructorArguments = = null )', 'primitiveTypes . put ( ""float"" , float . class ) ;'}, 'removed_code': {'Arrays . toString ( paramTypeNames ) ) ,', 'paramTypes [ i ] = classLoader . loadClass ( paramTypeNames [ i ] ) ;', 'public ObjectCreateBuilder usingConstructor ( Class < ? > . . . constructorArgumentsType )', 'try', 'if ( constructorArgumentsType = = null )', 'reportError ( ""createObject ( ) . usingConstructor ( Class < ? > [ ] ) "" , ""NULL parametersTypes not allowed"" ) ;', 'format ( ""class \' % s\' cannot be load"" , paramTypeNames [ i ] ) ) ;', 'this . reportError ( format ( ""createObject ( ) . usingConstructor ( % s ) "" ,', 'Class < ? > [ ] paramTypes = null ;', '{', 'if ( paramTypeNames ! = null )', '}', 'paramTypes = new Class < ? > [ paramTypeNames . length ] ;', 'this . constructorArgumentsType = constructorArgumentsType ;', 'objectCreateRule . setConstructorArguments ( constructorArgumentsType ) ;', 'catch ( ClassNotFoundException e )', 'for ( int i = 0 ; i < paramTypeNames . length ; i + + )'}}"
96c30e248d6d27a1df8e26be14aa10c633168cdb,1.0,Use final consistently .,"{'added_code': {'for ( final CharSequence cs : css ) {', 'private static Type [ ] extractTypeArgumentsFrom ( final Map < TypeVariable < ? > , Type > mappings , final TypeVariable < ? > [ ] variables ) {', 'public boolean equals ( final Object obj ) {', 'private WildcardTypeImpl ( final Type [ ] upperBounds , final Type [ ] lowerBounds ) {', 'private GenericArrayTypeImpl ( final Type componentType ) {', 'final char queryChar = queryLowerCase . charAt ( queryIndex ) ;', 'final WildcardType wild = ( WildcardType ) type ;', 'private static String genericArrayTypeToString ( final GenericArrayType g ) {', 'private static String parameterizedTypeToString ( final ParameterizedType p ) {', 'private ParameterizedTypeImpl ( final Class < ? > raw , final Type useOwner , final Type [ ] typeArguments ) {', 'private static int commonPrefixLength ( final CharSequence first , final CharSequence second ) {', 'public WildcardTypeBuilder withUpperBounds ( final Type . . . bounds ) {', 'public static boolean isAnyEmpty ( final CharSequence . . . css ) {', 'public static boolean isNoneBlank ( final CharSequence . . . css ) {', 'public static String wrap ( final String str , final char wrapWith ) {', 'public static boolean equals ( final Type t1 , final Type t2 ) {', 'public static String toLongString ( final TypeVariable < ? > var ) {', 'for ( final Type arg : ( ( ParameterizedType ) type ) . getActualTypeArguments ( ) ) {', 'private static boolean equals ( final ParameterizedType p , final Type t ) {', 'public static boolean isNoneEmpty ( final CharSequence . . . css ) {', 'final', 'private static String typeVariableToString ( final TypeVariable < ? > v ) {', 'private static int transpositions ( final CharSequence first , final CharSequence second ) {', 'public static String toEncodedString ( final byte [ ] bytes , final Charset charset ) {', 'public WildcardTypeBuilder withLowerBounds ( final Type . . . bounds ) {', 'private static boolean equals ( final GenericArrayType a , final Type t ) {', 'private static boolean equals ( final Type [ ] t1 , final Type [ ] t2 ) {', 'private static boolean equals ( final WildcardType w , final Type t ) {', 'final char firstChar = str . charAt ( 0 ) ;', 'final char termChar = termLowerCase . charAt ( termIndex ) ;', 'private static String wildcardTypeToString ( final WildcardType w ) {', 'public static boolean containsTypeVariables ( final Type type ) {', 'public static String wrap ( final String str , final String wrapWith ) {', 'private static String classToString ( final Class < ? > c ) {', 'public static boolean isAnyBlank ( final CharSequence . . . css ) {', 'public static String toString ( final Type type ) {', 'private static StringBuilder appendAllTo ( final StringBuilder buf , final String sep , final Type . . . types ) {', 'for ( final TypeVariable < ? > var : variables ) {'}, 'removed_code': {'public WildcardTypeBuilder withUpperBounds ( Type . . . bounds ) {', 'public static String wrap ( String str , String wrapWith ) {', 'public static String toEncodedString ( byte [ ] bytes , Charset charset ) {', 'public static boolean containsTypeVariables ( Type type ) {', 'char termChar = termLowerCase . charAt ( termIndex ) ;', 'private static boolean equals ( ParameterizedType p , Type t ) {', 'private static boolean equals ( Type [ ] t1 , Type [ ] t2 ) {', 'WildcardType wild = ( WildcardType ) type ;', 'public WildcardTypeBuilder withLowerBounds ( Type . . . bounds ) {', 'for ( TypeVariable < ? > var : variables ) {', 'public static String wrap ( String str , char wrapWith ) {', 'public static boolean isNoneEmpty ( CharSequence . . . css ) {', 'private WildcardTypeImpl ( Type [ ] upperBounds , Type [ ] lowerBounds ) {', 'private static String classToString ( Class < ? > c ) {', 'char firstChar = str . charAt ( 0 ) ;', 'public static boolean equals ( Type t1 , Type t2 ) {', 'for ( CharSequence cs : css ) {', 'public static String toString ( Type type ) {', 'private static Type [ ] extractTypeArgumentsFrom ( Map < TypeVariable < ? > , Type > mappings , TypeVariable < ? > [ ] variables ) {', 'private static String typeVariableToString ( TypeVariable < ? > v ) {', 'public static boolean isNoneBlank ( CharSequence . . . css ) {', 'private static int transpositions ( CharSequence first , CharSequence second ) {', 'private static String wildcardTypeToString ( WildcardType w ) {', 'public static String toLongString ( TypeVariable < ? > var ) {', 'private static int commonPrefixLength ( CharSequence first , CharSequence second ) {', 'private static StringBuilder appendAllTo ( StringBuilder buf , String sep , Type . . . types ) {', 'private static boolean equals ( WildcardType w , Type t ) {', 'private static String parameterizedTypeToString ( ParameterizedType p ) {', 'private static String genericArrayTypeToString ( GenericArrayType g ) {', 'for ( Type arg : ( ( ParameterizedType ) type ) . getActualTypeArguments ( ) ) {', 'public static boolean isAnyEmpty ( CharSequence . . . css ) {', 'private ParameterizedTypeImpl ( Class < ? > raw , Type useOwner , Type [ ] typeArguments ) {', 'private static boolean equals ( GenericArrayType a , Type t ) {', 'private GenericArrayTypeImpl ( Type componentType ) {', 'char queryChar = queryLowerCase . charAt ( queryIndex ) ;', 'public boolean equals ( Object obj ) {', 'public static boolean isAnyBlank ( CharSequence . . . css ) {'}}"
9720cbf8b2b6595f79e08f2964c53e47c96324f4,1.0,"[ CONFIGURATION - 644 ] Fix for a duplicated header comment . Under certain circumstances , the header comment managed by PropertiesConfigurationLayout gets duplicated . This commit fixes this problem . Thanks to Andrew DeMaria for the patch .","{'added_code': {'{', 'setHeaderComment ( extractComment ( commentLines , 0 , index - 1 ) ) ;', '}', 'if ( loadCounter = = 1 & & layoutData . isEmpty ( ) )', 'if ( getHeaderComment ( ) = = null )'}, 'removed_code': {'& & layoutData . isEmpty ( ) )', 'setHeaderComment ( extractComment ( commentLines , 0 , index - 1 ) ) ;', 'if ( loadCounter = = 1 & & getHeaderComment ( ) = = null'}}"
3c92830ec51fb6b6e9a7ca2fb8fda324cd33e48a,1.0,LANG - 1219 : FastDateFormat doesn't respect summer daylight in some localized strings,"{'added_code': {'TimeZone zone ;', 'dstOffset = useDst ? tz . getDSTSavings ( ) : 0 ;', 'final Set < String > sorted = new TreeSet < String > ( LONGER FIRST LOWERCASE ) ;', 'TimeZone tz = TimeZone . getTimeZone ( ""GMT"" + value ) ;', '}', 'switch ( i ) {', 'TzInfo standard = new TzInfo ( tz , false ) ;', 'int dstOffset ;', 'for ( Map . Entry < String , Integer > displayName : displayNames . entrySet ( ) ) {', 'lKeyValues = appendDisplayNames ( definingCalendar , locale , field , regex ) ;', 'private final Map < String , TzInfo > tzNames = new HashMap < String , TzInfo > ( ) ;', 'TzInfo tzInfo = tzNames . get ( value . toLowerCase ( locale ) ) ;', 'TimeZone tz = TimeZone . getTimeZone ( value . toUpperCase ( ) ) ;', 'private static class TzInfo {', 'break ;', 'for ( String symbol : sorted ) {', 'zone = tz ;', 'sb . append ( "" ( ( ? iu ) "" + RFC 822 TIME ZONE + "" | "" + GMT OPTION ) ;', 'TzInfo ( TimeZone tz , boolean useDst ) {', 'tzInfo = new TzInfo ( tz , true ) ;', 'Map < String , Integer > displayNames = cal . getDisplayNames ( field , Calendar . ALL STYLES , locale ) ;', ""simpleQuote ( sb . append ( ' | ' ) , zoneName ) ;"", '} ;', 'Map < String , Integer > values = new HashMap < String , Integer > ( ) ;', 'case 3 :', 'case 5 :', 'String key = zoneNames [ i ] . toLowerCase ( locale ) ;', 'return right . compareTo ( left ) ;', 'tzInfo = standard ;', 'TreeSet < String > sorted = new TreeSet < String > ( LONGER FIRST LOWERCASE ) ;', 'cal . set ( Calendar . DST OFFSET , tzInfo . dstOffset ) ;', 'TzInfo tzInfo = standard ;', '@ Override', 'cal . set ( Calendar . ZONE OFFSET , tzInfo . zone . getRawOffset ( ) ) ;', 'if ( sorted . add ( key ) ) {', 'private static final Comparator < String > LONGER FIRST LOWERCASE = new Comparator < String > ( ) {', 'cal . setTimeZone ( tz ) ;', 'public int compare ( String left , String right ) {', 'for ( String zoneName : sorted ) {', 'for ( int i = 1 ; i < zoneNames . length ; + + i ) {', 'String key = displayName . getKey ( ) . toLowerCase ( locale ) ;', ""simpleQuote ( regex , symbol ) . append ( ' | ' ) ;"", 'private static Map < String , Integer > appendDisplayNames ( Calendar cal , Locale locale , int field , StringBuilder regex ) {', 'tzNames . put ( key , tzInfo ) ;', 'return values ;', 'values . put ( key , displayName . getValue ( ) ) ;', 'private final Map < String , Integer > lKeyValues ;'}, 'removed_code': {'return v ;', 'TimeZone tz ;', 'appendDisplayNames ( definingCalendar , locale , field , regex , lKeyValues ) ;', 'return right . getKey ( ) . compareToIgnoreCase ( left . getKey ( ) ) ;', 'if ( values . put ( symbol . toLowerCase ( locale ) , entry . getValue ( ) ) = = null ) {', 'sb . append ( \' ( \' + RFC 822 TIME ZONE + "" | ( ? iu ) "" + GMT OPTION ) ;', '}', 'tz = TimeZone . getTimeZone ( value . toUpperCase ( ) ) ;', 'String symbol = entry . getKey ( ) ;', 'int v = left . getValue ( ) - right . getValue ( ) ;', 'sort . addAll ( displayNames ) ;', 'tz = tzNames . get ( value . toLowerCase ( locale ) ) ;', 'import java . util . Map . Entry ;', 'private static final Comparator < Map . Entry < String , Integer > > ALTERNATIVES ORDERING = new Comparator < Map . Entry < String , Integer > > ( ) {', 'TreeSet < Map . Entry < String , Integer > > sort = new TreeSet < Map . Entry < String , Integer > > ( ALTERNATIVES ORDERING ) ;', ""simpleQuote ( sb . append ( ' | ' ) , zoneName ) ;"", '} ;', 'public int compare ( Map . Entry < String , Integer > left , Map . Entry < String , Integer > right ) {', 'if ( tzNames . put ( zoneName . toLowerCase ( locale ) , tz ) = = null ) {', 'private static void appendDisplayNames ( Calendar cal , Locale locale , int field ,', 'if ( v ! = 0 ) {', 'for ( Map . Entry < String , Integer > entry : sort ) {', 'Set < Entry < String , Integer > > displayNames = cal . getDisplayNames ( field , Calendar . ALL STYLES , locale ) . entrySet ( ) ;', '@ Override', 'private final Map < String , TimeZone > tzNames = new HashMap < String , TimeZone > ( ) ;', 'if ( zoneName = = null ) {', 'cal . setTimeZone ( tz ) ;', 'private final Map < String , Integer > lKeyValues = new HashMap < String , Integer > ( ) ;', 'if ( symbol . length ( ) > 0 ) {', 'for ( int i = 1 ; i < zoneNames . length ; + + i ) {', 'String zoneName = zoneNames [ i ] ;', 'StringBuilder regex , Map < String , Integer > values ) {', ""simpleQuote ( regex , symbol ) . append ( ' | ' ) ;"", 'tz = TimeZone . getTimeZone ( ""GMT"" + value ) ;'}}"
5b7d3f5f4a40ad6e0ccf8ddde120219ba53cb3e6,1.0,"Reworked XMLConfiguration to operate on immutable nodes . The major part of the functionality for loading and saving XML documents is working , but there is still a bunch of tests failing .","{'added_code': {'private ImmutableNode createChildNodeWithValue (', 'String txt =', 'else', 'import javax . xml . transform . Source ;', 'private final Map < Node , Node > elementMapping ;', 'public XMLConfiguration ( HierarchicalConfiguration < ImmutableNode > c )', 'childTrim . booleanValue ( ) , attrmap ) ;', 'builder . processDocument ( handler ) ;', 'new XMLBuilderVisitor ( newHelper , getListDelimiterHandler ( ) ) ;', 'import javax . xml . transform . stream . StreamResult ;', 'private static Map < String , String > processAttributes ( Element element )', 'import javax . xml . transform . dom . DOMSource ;', 'Text txtNode = findTextNodeForUpdate ( element ) ;', 'document . getDocumentElement ( ) , elemRefMap , true , 0 ) ;', 'if ( newNode . getValue ( ) ! = null )', 'hasChildren = true ;', 'newNode . getValue ( ) ,', 'values = getListDelimiterHandler ( ) . split ( value , trim ) ;', 'private Document createDocument ( ) throws ConfigurationException', 'return ( XMLDocumentHelper ) handler . getReference ( handler . getRootNode ( ) ) ;', 'Node element ;', 'createChildNodeWithValue ( node , childNode ,', 'ReferenceNodeHandler handler = getReferenceHandler ( ) ;', 'parent . addChild ( addedChildNode ) ;', 'private static void updateAttributes ( ImmutableNode node , Element elem )', 'protected void insert ( ImmutableNode newNode , ImmutableNode parent ,', 'import org . apache . commons . configuration . tree . ImmutableNode ;', 'ImmutableNode sibling1 , ImmutableNode sibling2 ,', 'parentElem . removeChild ( element ) ;', 'finally', 'private final ListDelimiterHandler listDelimiterHandler ;', 'String text = determineValue ( buffer . toString ( ) , childrenFlag , trimFlag ) ;', 'try', 'Element element = getElement ( node , refHandler ) ;', 'protected void update ( ImmutableNode node , Object reference ,', 'document = docHelper . getDocument ( ) ;', 'newElements . put ( newNode , elem ) ;', 'Result result = new StreamResult ( writer ) ;', 'child . value ( values . iterator ( ) . next ( ) ) ;', 'element . insertBefore ( txtNode , element . getFirstChild ( ) ) ;', 'for ( int i = 0 ; i < children . getLength ( ) ; i + + )', 'Element elementNew = newElements . get ( node ) ;', 'updateAttributes ( node , element ) ;', 'if ( nd instanceof Text )', 'import javax . xml . parsers . DocumentBuilder ;', 'constructHierarchy ( rootBuilder , rootValue ,', 'boolean childrenFlag = hasChildren | | attributes . size ( ) > 1 ;', 'private Map < String , String > constructHierarchy ( ImmutableNode . Builder node ,', 'ImmutableNode . Builder rootBuilder = new ImmutableNode . Builder ( ) ;', 'private static Text findTextNodeForUpdate ( Element elem )', 'if ( result = = null )', 'elem . removeChild ( tn ) ;', 'return doc . getDocumentElement ( ) . getNodeName ( ) ;', 'return result ;', 'this . getLogger ( ) . debug ( ""Unable to load the configuration"" , e ) ;', 'refChildValue . getValue ( ) ,', 'elem . setAttribute ( e . getKey ( ) , e . getValue ( ) . toString ( ) ) ;', 'boolean hasChildren = false ;', 'XMLDocumentHelper docHelper =', 'element =', 'XMLDocumentHelper . transform ( transformer , source , result ) ;', 'import org . apache . commons . lang3 . mutable . MutableObject ;', 'private static String determineValue ( String content , boolean hasChildren ,', 'ReferenceNodeHandler refHandler )', 'for ( int i = 0 ; i < attributes . getLength ( ) ; i + + )', 'public void handleRemovedNodes ( ReferenceNodeHandler refHandler )', 'else if ( sibling1 ! = null )', 'if ( elementNew ! = null )', 'private ReferenceNodeHandler getReferenceHandler ( )', 'child . value ( it . next ( ) ) ;', 'String value , boolean trim , Map < String , String > attrmap )', 'parent . addChild ( c . create ( ) ) ;', '""The name of the root element ""', '. forNewDocument ( getRootElementName ( ) ) : docHelper', ': document . getDocumentElement ( ) ;', 'for ( Map . Entry < String , Object > e : node . getAttributes ( )', 'if ( sibling2 = = null )', 'if ( reference instanceof XMLDocumentHelper )', 'Map < String , String > attributes = processAttributes ( element ) ;', 'endRead ( ) ;', 'MutableObject < String > refChildValue =', 'if ( value ! = null )', 'refValue . setValue ( text ) ;', 'import javax . xml . parsers . ParserConfigurationException ;', 'Collection < org . w3c . dom . Node > textNodes =', 'private void updateElement ( Element element , Object value )', 'return ( element ! = null ) ? ( Element ) elementMapping . get ( element )', 'rootElementName = getRootNode ( ) . getNodeName ( ) ;', 'updateAttributes ( newNode , elem ) ;', 'ImmutableNode . Builder childNode = new ImmutableNode . Builder ( ) ;', 'Map < ImmutableNode , Object > elemRefMap =', 'textNodes . add ( result ) ;', 'childNode . addAttributes ( attrmap ) ;', 'XMLDocumentHelper docHelper = getDocumentHelper ( ) ;', 'private Element getElement ( ImmutableNode node ,', 'static class XMLBuilderVisitor extends BuilderVisitor', 'elem . removeAttribute ( attributes . item ( i ) . getNodeName ( ) ) ;', 'Iterator < String > it = values . iterator ( ) ;', 'clearAttributes ( elem ) ;', 'while ( it . hasNext ( ) )', 'elem . appendChild ( document . createTextNode ( txt ) ) ;', 'Document doc = getDocument ( ) ;', 'public void processDocument ( ReferenceNodeHandler refHandler )', 'addedChildNode = child . create ( ) ;', 'private void removeReference ( Element element )', 'getSubConfigurationParentModel ( ) . addReferences ( elemRefMap ) ;', 'return getSubConfigurationParentModel ( ) . getReferenceNodeHandler ( ) ;', 'getElement ( parent , refHandler ) . appendChild ( elem ) ;', 'Text result = null ;', 'ListDelimiterHandler handler )', 'elementMapping = docHelper . getElementMapping ( ) ;', '+ ""cannot be changed when loaded from an XML document!"" ) ;', '. entrySet ( ) )', '{', 'org . w3c . dom . Node parentElem = element . getParentNode ( ) ;', 'element . appendChild ( txtNode ) ;', 'private static boolean shouldTrim ( Element element , boolean currentTrim )', '. getDocumentElement ( ) ;', 'XMLBuilderVisitor builder =', 'Document oldDocument = getDocument ( ) ;', 'refHandler ) ;', 'c . addAttributes ( attrmap ) ;', 'import javax . xml . transform . Transformer ;', 'updateElement ( element , refHandler . getValue ( node ) ) ;', 'return addedChildNode ;', 'builder . handleRemovedNodes ( handler ) ;', 'import java . util . Collections ;', 'if ( doc = = null )', '( docHelper = = null ) ? XMLDocumentHelper', 'listDelimiterHandler = handler ;', 'removeReference ( ( Element ) elementMapping . get ( removedElem ) ) ;', 'Map < ImmutableNode , Object > elemRefs , boolean trim , int level )', 'if ( parentElem ! = null )', 'if ( e . getValue ( ) ! = null )', 'textNodes . add ( nd ) ;', 'NodeList children = elem . getChildNodes ( ) ;', 'if ( element . getFirstChild ( ) ! = null )', 'boolean trimFlag )', 'Document document = docHelper . getDocument ( ) ;', 'MutableObject < String > refValue , Element element ,', 'ListDelimiterHandler . NOOP TRANSFORMER ) ) ;', 'for ( Object ref : refHandler . removedReferences ( ) )', 'return ( docHelper ! = null ) ? docHelper . getDocument ( ) : null ;', 'ImmutableNode . Builder c = new ImmutableNode . Builder ( ) ;', 'else if ( values . size ( ) = = 1 )', 'import org . w3c . dom . Node ;', 'constructHierarchy ( childNode , refChildValue , child ,', 'initRootElementText ( newHelper . getDocument ( ) , getRootNode ( ) . getValue ( ) ) ;', 'import org . apache . commons . configuration . tree . ReferenceNodeHandler ;', 'if ( getDocument ( ) ! = null )', 'new MutableObject < String > ( ) ;', 'NamedNodeMap attributes = elem . getAttributes ( ) ;', '@ Override', 'NodeTreeWalker . INSTANCE . walkDFS ( refHandler . getRootNode ( ) , this ,', 'elemRefs . put ( newChild , child ) ;', 'if ( text . length ( ) > 0 | | ( !childrenFlag & & level ! = 0 ) )', 'ImmutableNode newChild =', 'c . value ( it . next ( ) ) ;', 'getElement ( parent , refHandler ) . getFirstChild ( ) ) ;', 'elemRefs , trimFlag , level + 1 ) ;', '( ( XMLDocumentHelper ) reference ) . getDocument ( )', 'return newHelper . getDocument ( ) ;', 'values = Collections . emptyList ( ) ;', 'getElement ( parent , refHandler ) . insertBefore ( elem ,', 'c . name ( addedChildNode . getNodeName ( ) ) ;', 'new ArrayList < org . w3c . dom . Node > ( ) ;', 'elemRefs ? new HashMap < ImmutableNode , Object > ( ) : null ;', 'childNode . name ( child . getTagName ( ) ) ;', 'element . removeChild ( txtNode ) ;', 'getElement ( sibling1 , refHandler ) . getNextSibling ( ) ) ;', 'import org . apache . commons . configuration . tree . NodeTreeWalker ;', 'MutableObject < String > rootValue = new MutableObject < String > ( ) ;', 'beginRead ( true ) ;', 'result = ( Text ) nd ;', 'org . w3c . dom . Node nd = children . item ( i ) ;', '}', 'String . valueOf ( listDelimiterHandler . escape (', 'import javax . xml . transform . Result ;', 'Node removedElem = ( Node ) ref ;', 'Source source = new DOMSource ( createDocument ( ) ) ;', 'if ( result instanceof CDATASection )', 'for ( org . w3c . dom . Node tn : textNodes )', 'Collection < String > values ;', 'ImmutableNode top = rootBuilder . value ( rootValue . getValue ( ) ) . create ( ) ;', 'private XMLDocumentHelper getDocumentHelper ( )', 'private final Document document ;', 'newElements = new HashMap < ImmutableNode , Element > ( ) ;', 'private void initProperties ( XMLDocumentHelper docHelper , boolean elemRefs )', 'return elementNew ;', 'Element elem = document . createElement ( newNode . getNodeName ( ) ) ;', 'XMLDocumentHelper newHelper =', 'getModel ( ) . addNodes ( null , top . getChildren ( ) , this ) ;', 'public XMLBuilderVisitor ( XMLDocumentHelper docHelper ,', 'elemRefMap . put ( getRootNode ( ) , docHelper ) ;', 'Transformer transformer = XMLDocumentHelper . createTransformer ( ) ;', 'rootElementName = name ;', 'trimFlag | | ( StringUtils . isBlank ( content ) & & hasChildren ) ;', 'private static void clearAttributes ( Element elem )', 'element = ( Node ) reference ;', 'ImmutableNode addedChildNode ;', 'private final Map < ImmutableNode , Element > newElements ;', 'oldDocument = = null ) ;', 'ImmutableNode . Builder parent , ImmutableNode . Builder child ,', 'result = null ;', 'if ( elemRefs ! = null )', 'if ( values . size ( ) > 1 )', 'Object reference = refHandler . getReference ( node ) ;', 'String . valueOf ( listDelimiterHandler . escape ( value ,', '. createCopy ( ) ;', 'initProperties ( XMLDocumentHelper . forSourceDocument ( newDocument ) ,', '( XMLDocumentHelper ) handler . getReference ( handler . getRootNode ( ) ) ;', 'import javax . xml . parsers . DocumentBuilderFactory ;', 'throw new UnsupportedOperationException ('}, 'removed_code': {'protected void removeReference ( )', 'ConfigurationNode parent , ConfigurationNode sibling1 ,', 'String txt =', 'private static List < ConfigurationNode > fetchDefinedAttributes (', 'public void setValue ( Object value )', 'Element elem = document . createElement ( newNode . getName ( ) ) ;', 'else', 'for ( Map . Entry < String , String > e : attrmap . entrySet ( ) )', 'private Map < String , String > processAttributes ( ConfigurationNode node ,', 'transformer . transform ( source , result ) ;', 'import javax . xml . transform . Source ;', 'parent . addChild ( c ) ;', 'Document newDocument = builder . newDocument ( ) ;', 'newDocument . appendChild ( rootElem ) ;', 'nd . setValue ( node . getValue ( ) ) ;', 'import javax . xml . transform . stream . StreamResult ;', 'import javax . xml . transform . dom . DOMSource ;', 'newNode . getValue ( ) ,', 'transformer . setOutputProperty ( OutputKeys . INDENT , ""yes"" ) ;', 'throw new ConfigurationException ( ""Unable to save the configuration"" , e ) ;', 'protected ConfigurationNode createNode ( String name )', 'if ( newNode . getValue ( ) ! = null )', 'throw new ConfigurationException ( domEx ) ;', 'ConfigurationNode c = createNode ( child . getName ( ) ) ;', 'return new XMLNode ( name , null ) ;', 'public void initProperties ( Document document , boolean elemRefs )', 'public XMLBuilderVisitor ( Document doc , ListDelimiterHandler handler )', 'import org . apache . commons . configuration . tree . DefaultConfigurationNode ;', 'clearReferences ( copy . getRootNode ( ) ) ;', 'private void updateElement ( Object value )', 'private boolean shouldTrim ( Element element , boolean currentTrim )', 'import org . w3c . dom . DOMException ;', 'definedAttrs . add ( attr ) ;', 'throw new UnsupportedOperationException ( ""The name of the root element ""', '""Multiple values for attribute \'"" + name', 'updateAttribute ( parent , getElement ( parent ) , newNode . getName ( ) ) ;', 'String . valueOf ( getListDelimiterHandler ( ) . escape ( value ,', 'builder . processDocument ( getRootNode ( ) ) ;', 'return ( node . getName ( ) ! = null & & node . getReference ( ) ! = null ) ? ( Element ) node', 'elem . setAttribute ( name , attr . getValue ( ) . toString ( ) ) ;', 'elem . removeAttribute ( name ) ;', 'parentElem . removeChild ( element ) ;', 'finally', 'private final ListDelimiterHandler listDelimiterHandler ;', 'try', 'getElement ( parent ) . insertBefore ( elem , getElement ( parent ) . getFirstChild ( ) ) ;', '( ( Element ) getReference ( ) ) . getFirstChild ( ) ) ;', 'systemID ) ;', 'DocumentBuilder builder = DocumentBuilderFactory . newInstance ( ) . newDocumentBuilder ( ) ;', 'getRootNode ( ) . setName ( name ) ;', 'child . getValue ( ) . toString ( ) , trim ) ;', 'return document ;', 'getRootNode ( ) . setName ( document . getDocumentElement ( ) . getNodeName ( ) ) ;', 'Result result = new StreamResult ( writer ) ;', 'clearReferences ( getRootNode ( ) ) ;', '| | ( StringUtils . isBlank ( content ) & & node', 'elemRefs ? child : null ) ;', 'for ( int i = 0 ; i < children . getLength ( ) ; i + + )', 'if ( nd instanceof Text )', 'import javax . xml . parsers . DocumentBuilder ;', 'new ArrayList < ConfigurationNode > ( attrs . size ( ) ) ;', 'for ( ConfigurationNode ndAttr : child . getAttributes ( ) )', 'private Text findTextNodeForUpdate ( )', 'if ( result = = null )', 'import javax . xml . transform . TransformerFactory ;', 'elem . removeChild ( tn ) ;', 'return result ;', 'xmlNodes = new ArrayList < XMLNode > ( nodes . size ( ) ) ;', 'super ( name ) ;', 'nd . addChild ( convertToXMLNode ( child ) ) ;', 'parent . removeChild ( child ) ;', 'rootNode . visit ( this ) ;', 'class XMLNode extends DefaultConfigurationNode', 'for ( ConfigurationNode node : nodes )', 'else if ( sibling1 ! = null )', 'if ( attr . getValue ( ) ! = null )', 'String text = determineValue ( node , buffer . toString ( ) , trimFlag ) ;', ': document . getDocumentElement ( ) ;', 'private Element getElement ( ConfigurationNode node )', 'XMLNode nd = ( XMLNode ) createNode ( node . getName ( ) ) ;', 'if ( sibling2 = = null )', 'endRead ( ) ;', 'ConfigurationNode sibling2 )', 'xmlNodes . add ( convertToXMLNode ( node ) ) ;', 'Collection < org . w3c . dom . Node > textNodes = new ArrayList < org . w3c . dom . Node > ( ) ;', 'XMLConfiguration copy = ( XMLConfiguration ) super . clone ( ) ;', 'import javax . xml . parsers . ParserConfigurationException ;', 'copy . document = null ;', '. getReference ( )', 'e . getValue ( ) ) ;', 'String content , boolean trimFlag )', 'updateAttribute ( ) ;', 'for ( ConfigurationNode attr : node . getAttributes ( ) )', 'getElement ( parent ) . appendChild ( elem ) ;', 'textNodes . add ( result ) ;', 'if ( text . length ( ) > 0 | | ( !hasChildren ( node ) & & node ! = getRootNode ( ) ) )', 'static class XMLBuilderVisitor extends BuilderVisitor', 'return copy ;', 'Iterator < String > it = values . iterator ( ) ;', 'Transformer transformer = TransformerFactory . newInstance ( )', 'while ( it . hasNext ( ) )', 'document = null ;', 'elem . appendChild ( document . createTextNode ( txt ) ) ;', 'ndAttr . setReference ( null ) ;', 'child . setValue ( values . iterator ( ) . next ( ) ) ;', 'fetchDefinedAttributes ( node . getAttributes ( name ) ) ;', 'Map < String , String > attributes =', 'protected Object insert ( ConfigurationNode newNode ,', 'getListDelimiterHandler ( ) . split (', 'if ( systemID ! = null )', 'import org . apache . commons . configuration . ex . ConfigurationRuntimeException ;', 'if ( document = = null )', 'document = doc ;', 'Text result = null ;', '( ( Element ) getReference ( ) ) . insertBefore ( txtNode ,', 'c = createNode ( child . getName ( ) ) ;', '+ ""cannot be changed when loaded from an XML document!"" ) ;', 'if ( node ! = null )', '{', 'org . w3c . dom . Node parentElem = element . getParentNode ( ) ;', 'if ( getReference ( ) ! = null & & document ! = null )', 'return definedAttrs ;', 'if ( child . getValue ( ) ! = null )', 'if ( attrs . isEmpty ( ) )', 'catch ( TransformerException e )', 'super . clearInternal ( ) ;', 'super . setValue ( value ) ;', 'node . addAttribute ( child ) ;', 'return elem ;', 'updateAttribute ( node , ( Element ) node . getReference ( ) , name ) ;', 'import javax . xml . transform . Transformer ;', 'Element element = ( Element ) getReference ( ) ;', 'if ( !definedAttrs . isEmpty ( ) )', 'return transformer ;', 'return node . getChildrenCount ( ) > 0 | | node . getAttributeCount ( ) > 0 ;', 'import java . util . List ;', 'private Map < String , String > constructHierarchy ( ConfigurationNode node ,', 'nd . setAttribute ( node . isAttribute ( ) ) ;', '+ ""\' are not supported!"" ) ;', 'public XMLNode ( String name , Element elem )', 'return document . getDocumentElement ( ) . getNodeName ( ) ;', 'Element elem = ( Element ) getReference ( ) ;', 'catch ( TransformerFactoryConfigurationError e )', 'appendAttribute ( c , null , false , e . getKey ( ) ,', 'listDelimiterHandler = handler ;', 'Text txtNode = findTextNodeForUpdate ( ) ;', 'throw new ConfigurationException ( pex ) ;', 'if ( parentElem ! = null )', 'c . addAttribute ( ndAttr ) ;', 'textNodes . add ( nd ) ;', 'NodeList children = elem . getChildNodes ( ) ;', 'Collection < XMLNode > xmlNodes ;', 'Collection < String > values =', 'private void appendAttribute ( ConfigurationNode node , Element element , boolean elemRefs ,', 'if ( getReference ( ) ! = null )', 'document = ( oldDocument = = null ) ? newDocument : oldDocument ;', 'this . getLogger ( ) . debug ( ""Unable to load the configuraton"" , e ) ;', 'node . setValue ( text ) ;', 'ListDelimiterHandler . NOOP TRANSFORMER ) ) ;', 'super . addNodesInternal ( key , xmlNodes ) ;', 'for ( ConfigurationNode attr : attrs )', 'else if ( values . size ( ) = = 1 )', 'constructHierarchy ( getRootNode ( ) , document . getDocumentElement ( ) , elemRefs , true ) ;', 'ConfigurationNode attr = definedAttrs . get ( 0 ) ;', 'return attrs ;', 'if ( getDocument ( ) ! = null )', 'protected void clearInternal ( )', 'if ( isAttribute ( ) )', 'return nd ;', '@ Override', 'setRootElementName ( getRootNode ( ) . getName ( ) ) ;', 'catch ( DOMException domEx )', 'if ( newNode . isAttribute ( ) )', 'super . addNodesInternal ( key , nodes ) ;', 'updateElement ( value ) ;', 'XMLBuilderVisitor . updateAttribute ( getParentNode ( ) , getName ( ) ) ;', 'Document oldDocument = document ;', 'import javax . xml . transform . TransformerException ;', 'public Object clone ( )', 'child . setValue ( value ) ;', 'import javax . xml . transform . TransformerFactoryConfigurationError ;', 'private static void updateAttribute ( ConfigurationNode node , Element elem , String name )', 'if ( node instanceof XMLNode )', 'throw new ConfigurationException ( ""Validation failed"" , e ) ;', 'private void handleDelimiters ( ConfigurationNode parent , ConfigurationNode child , boolean trim ,', 'private static final long serialVersionUID = - 4133988932174596562L ;', 'static void updateAttribute ( ConfigurationNode node , String name )', '. newTransformer ( ) ;', 'if ( definedAttrs . size ( ) > 1 )', 'protected Transformer createTransformer ( ) throws TransformerException', 'String attr , String value )', 'result = ( Text ) nd ;', 'org . w3c . dom . Node nd = children . item ( i ) ;', 'if ( ( ( Element ) getReference ( ) ) . getFirstChild ( ) ! = null )', '}', 'if ( publicID ! = null )', 'String . valueOf ( listDelimiterHandler . escape (', 'getElement ( parent ) . insertBefore ( elem , getElement ( sibling1 ) . getNextSibling ( ) ) ;', 'import javax . xml . transform . Result ;', 'Element rootElem = newDocument . createElement ( getRootElementName ( ) ) ;', 'List < ConfigurationNode > attrs )', 'XMLBuilderVisitor builder = new XMLBuilderVisitor ( document , getListDelimiterHandler ( ) ) ;', 'Map < String , String > attrmap )', '. getChildrenCount ( ) > 0 ) ;', 'public XMLConfiguration ( HierarchicalConfiguration c )', 'Source source = new DOMSource ( createDocument ( ) ) ;', 'if ( result instanceof CDATASection )', 'private Document document ;', 'handleDelimiters ( node , childNode , childTrim . booleanValue ( ) , attrmap ) ;', 'protected Document createDocument ( ) throws ConfigurationException', 'for ( org . w3c . dom . Node tn : textNodes )', 'import javax . xml . transform . OutputKeys ;', 'if ( nodes ! = null & & !nodes . isEmpty ( ) )', 'node . addChild ( childNode ) ;', 'initProperties ( newDocument , oldDocument = = null ) ;', 'trimFlag', 'appendAttribute ( node , element , elemRefs , attr . getName ( ) , attr . getValue ( ) ) ;', 'private void updateAttribute ( )', 'if ( locator . getEncoding ( ) ! = null )', 'for ( ConfigurationNode child : node . getChildren ( ) )', 'private final Document document ;', 'getRootNode ( ) . setReference ( document . getDocumentElement ( ) ) ;', 'public void processDocument ( ConfigurationNode rootNode )', 'private XMLNode convertToXMLNode ( ConfigurationNode node )', '( ( Element ) getReference ( ) ) . appendChild ( txtNode ) ;', 'private static boolean hasChildren ( ConfigurationNode node )', 'nd . addAttribute ( convertToXMLNode ( attr ) ) ;', 'ConfigurationNode childNode = new XMLNode ( child . getTagName ( ) ,', 'protected void addNodesInternal ( String key , Collection < ? extends ConfigurationNode > nodes )', 'transformer . setOutputProperty ( OutputKeys . ENCODING , locator . getEncoding ( ) ) ;', 'c . setValue ( it . next ( ) ) ;', 'publicID ) ;', 'rootElementName = name ;', '( ( Element ) getReference ( ) ) . removeChild ( txtNode ) ;', 'transformer . setOutputProperty ( OutputKeys . DOCTYPE SYSTEM ,', 'List < ConfigurationNode > definedAttrs =', 'getRootNode ( ) . setReference ( null ) ;', 'processAttributes ( node , element , elemRefs ) ;', 'result = null ;', 'document = newDocument ;', 'return null ;', 'if ( values . size ( ) > 1 )', 'Element element , boolean elemRefs )', 'constructHierarchy ( childNode , child , elemRefs , trimFlag ) ;', 'setReference ( elem ) ;', 'return ( XMLNode ) node ;', 'beginRead ( false ) ;', 'import org . apache . commons . configuration . tree . ConfigurationNode ;', 'private static String determineValue ( ConfigurationNode node ,', 'catch ( ParserConfigurationException pex )', 'Element element , boolean elemRefs , boolean trim )', 'ConfigurationNode child = new XMLNode ( attr , elemRefs ? element : null ) ;', 'Transformer transformer = createTransformer ( ) ;', 'import javax . xml . parsers . DocumentBuilderFactory ;', 'initRootElementText ( document , getRootNode ( ) . getValue ( ) ) ;', 'transformer . setOutputProperty ( OutputKeys . DOCTYPE PUBLIC ,', 'throw new ConfigurationRuntimeException ('}}"
eee7e7c4b278274240ad7458da9d9073b7374415,1.0,JCS - 130 : Simplify RemoteHttpCacheFactory & friends . Get rid of criss - cross static calls . Remote RemoteHttpCacheManager,"{'added_code': {'{', '}', '( ( RemoteCache < K , V > ) rcnw . getRemoteCache ( ) ) . setFacade ( this ) ;', 'for ( RemoteCacheNoWait < K , V > rcnw : this . noWaits )', 'this . noWaits . add ( rcnw ) ;'}, 'removed_code': set()}"
3eb4be60cf00c20e46b75fb72366dd0649700c2f,1.0,Reuse code already available in StringUtils,"{'added_code': {'final int result = getCommonPrefix ( first . toString ( ) , second . toString ( ) ) . length ( ) ;'}, 'removed_code': {'for ( int i = 0 ; i < shorter . length ( ) ; i + + ) {', 'String longer ;', 'int result = 0 ;', 'result + + ;', 'if ( first . length ( ) > second . length ( ) ) {', 'shorter = second . toString ( ) . toLowerCase ( ) ;', '} else {', 'break ;', 'String shorter ;', 'if ( shorter . charAt ( i ) ! = longer . charAt ( i ) ) {', 'shorter = first . toString ( ) . toLowerCase ( ) ;', '}', 'longer = first . toString ( ) . toLowerCase ( ) ;', 'longer = second . toString ( ) . toLowerCase ( ) ;'}}"
0ff845a477db67a485e7a8c1cd8265e520bc8c05,1.0,JCS - 78 Fix : RemoteCacheStartupServlet can't start with config outside classpath,"{'added_code': {'private void loadInitParams ( )', 'import java . io . OutputStream ;', 'String registryHost = config . getInitParameter ( ""registryHost"" ) ;', 'os . write ( stats . getBytes ( characterEncoding ) ) ;', 'String propsFileName = config . getInitParameter ( ""propsFileName"" ) ;', 'String portS = props . getProperty ( ""registry . port"" , String . valueOf ( registryPort ) ) ;', 'import org . apache . commons . jcs . auxiliary . remote . RemoteUtils ;', 'else', 'log . error ( ""Problem loading props . "" , e ) ;', 'private String propsFileName = DEFAULT PROPS FILE NAME ;', 'log . info ( ""Shutting down remote cache "" ) ;', 'log . error ( ""Problem converting port to an int . "" , e ) ;', 'setRegistryPort ( portS ) ;', 'private static final String DEFAULT PROPS FILE NAME = "" / cache . ccf"" ;', 'if ( null ! = propsFileName )', '}', 'private Properties loadPropertiesFromFile ( )', 'registryHost = HostNameUtil . getLocalHostAddress ( ) ;', 'log . error ( ""Problem starting remote cache server . "" , e ) ;', 'import javax . servlet . ServletConfig ;', 'this . registryHost = registryHost ;', 'log . error ( ""Problem shutting down . "" , e ) ;', 'log . warn ( ""The local address [ "" + registryHost', 'import org . apache . commons . jcs . utils . net . HostNameUtil ;', 'private static final Log log = LogFactory . getLog ( RemoteCacheStartupServlet . class ) ;', 'import org . apache . commons . jcs . access . exception . CacheException ;', 'registryHost = props . getProperty ( ""registry . host"" , registryHost ) ;', 'loadInitParams ( ) ;', 'if ( null ! = registryHost )', 'RemoteCacheServerFactory . startup ( registryHost , registryPort , propsFileName ) ;', 'this . propsFileName = propsFileName ;', 'if ( log . isDebugEnabled ( ) )', 'Properties props = loadPropertiesFromFile ( ) ;', 'RemoteCacheServerFactory . startup ( registryHost , registryPort , props , propsFileName ) ;', 'extends HttpServlet', 'RemoteCacheServerFactory . shutdownImpl ( registryHost , registryPort ) ;', 'import java . io . IOException ;', 'private int registryPort = DEFAULT REGISTRY PORT ;', 'if ( props ! = null )', 'private String registryHost = null ;', 'log . error ( ""Problem writing response . "" , e ) ;', 'props = RemoteUtils . loadProps ( propsFileName ) ;', 'if ( null ! = regPortString )', 'protected void service ( HttpServletRequest request , HttpServletResponse response )', 'log . info ( ""Remote JCS Server started with properties from "" + propsFileName ) ;', 'ServletConfig config = getServletConfig ( ) ;', 'if ( log . isInfoEnabled ( ) )', 'Properties props = null ;', 'this . registryPort = Integer . parseInt ( portS ) ;', 'try', 'return props ;', 'log . error ( ""Could not get local address to use for the registry!"" , e ) ;', 'catch ( NumberFormatException e )', 'catch ( IOException e )', 'import java . util . Properties ;', 'private void setRegistryPort ( String portS )', 'import java . net . UnknownHostException ;', 'import org . apache . commons . jcs . engine . control . CompositeCacheManager ;', 'String regPortString = config . getInitParameter ( ""registryPort"" ) ;', '+ "" ] is INVALID . Other machines must be able to use the address to reach this server . "" ) ;', 'if ( ""localhost"" . equals ( registryHost ) | | ""127 . 0 . 0 . 1"" . equals ( registryHost ) )', 'log . debug ( ""registryHost = [ "" + registryHost + "" ] "" ) ;', 'import org . apache . commons . logging . LogFactory ;', 'throws ServletException , IOException', 'catch ( UnknownHostException e )', 'if ( registryHost = = null )', 'import org . apache . commons . logging . Log ;', 'log . info ( stats ) ;', '{', 'if ( props = = null )', 'setRegistryPort ( regPortString ) ;', 'throws ServletException', 'this . registryPort = DEFAULT REGISTRY PORT ;'}, 'removed_code': {'import java . io . OutputStream ;', 'os . write ( stats . getBytes ( characterEncoding ) ) ;', 'log . info ( ""Shutting down remote cache "" ) ;', 'log . error ( ""Problem converting port to an int . "" , e ) ;', '}', 'registryHost = HostNameUtil . getLocalHostAddress ( ) ;', 'log . error ( ""Problem starting remote cache server . "" , e ) ;', 'import org . apache . commons . jcs . utils . net . HostNameUtil ;', 'private static final Log log = LogFactory . getLog ( RemoteCacheStartupServlet . class ) ;', 'log . warn ( ""The local address [ "" + registryHost', 'import org . apache . commons . jcs . access . exception . CacheException ;', 'import org . apache . commons . jcs . utils . props . PropertyLoader ;', 'private static final String DEFAULT PROPS FILE NAME = ""cache"" ;', 'if ( log . isDebugEnabled ( ) )', 'extends HttpServlet', 'private final String propsFileName = DEFAULT PROPS FILE NAME ;', 'import java . io . IOException ;', 'if ( props ! = null )', 'int registryPort = DEFAULT REGISTRY PORT ;', 'log . error ( ""Problem writing response . "" , e ) ;', 'RemoteCacheServerFactory . startup ( registryHost , registryPort , "" / "" + fullPropsFileName ) ;', 'String portS = props . getProperty ( ""registry . port"" , String . valueOf ( DEFAULT REGISTRY PORT ) ) ;', 'protected void service ( HttpServletRequest request , HttpServletResponse response )', 'registryPort = Integer . parseInt ( portS ) ;', 'log . error ( ""Could not get local address to use for the registry!"" , e ) ;', 'if ( log . isInfoEnabled ( ) )', 'String registryHost ;', 'try', 'catch ( IOException e )', 'catch ( NumberFormatException e )', 'import java . util . Properties ;', 'import java . net . UnknownHostException ;', 'import org . apache . commons . jcs . engine . control . CompositeCacheManager ;', 'private final String fullPropsFileName = DEFAULT PROPS FILE NAME + "" . "" + DEFAULT PROPS FILE SUFFIX ;', 'log . info ( ""Remote JCS Server started with properties from "" + fullPropsFileName ) ;', '+ "" ] is INVALID . Other machines must be able to use the address to reach this server . "" ) ;', 'if ( ""localhost"" . equals ( registryHost ) | | ""127 . 0 . 0 . 1"" . equals ( registryHost ) )', 'log . debug ( ""registryHost = [ "" + registryHost + "" ] "" ) ;', 'import org . apache . commons . logging . LogFactory ;', 'throws ServletException , IOException', 'catch ( UnknownHostException e )', 'import org . apache . commons . logging . Log ;', 'log . info ( stats ) ;', '{', 'Properties props = PropertyLoader . loadProperties ( propsFileName ) ;', 'throws ServletException', 'private static final String DEFAULT PROPS FILE SUFFIX = ""ccf"" ;'}}"
ae1e4c3704cb315c241e4512f101fd101e64069f,1.0,[ VFS - 449 ] HDFS Provider is not removing cached files .,"{'added_code': {'file . refresh ( ) ;', 'FileObject file ;', 'if ( useCache )', 'if ( getFileSystemManager ( ) . getCacheStrategy ( ) . equals ( CacheStrategy . ON RESOLVE ) )', 'else', 'import org . apache . commons . vfs2 . CacheStrategy ;', 'boolean useCache = ( null ! = getContext ( ) . getFileSystemManager ( ) . getFilesCache ( ) ) ;', '{', '}', 'this . putFileToCache ( file ) ;', 'file = null ;', 'return file ;', 'file = this . getFileFromCache ( name ) ;'}, 'removed_code': {'else', 'this . putFileToCache ( file ) ;', '{', '}', 'FileObject file = this . getFileFromCache ( name ) ;', 'return file ;'}}"
cbbeae7719943308494825574a0002ea649b3de3,1.0,"Modified ZipOutputStream to be able to avoid seeking and rewriting headers when operating through addRaw . The basic idea is that an entry added through addRaw is fully known at the time we call add , so we do not need to go back in the file to rewrite fields . Adding this third mode increases the pain of multiple code paths , and we should probably consider a ground - up rewrite at some point .","{'added_code': {'private void closeEntry ( boolean actuallyNeedsZip64 , boolean phased ) throws IOException {', '} else if ( zipMethod = = DEFLATED | | raf ! = null ) {', 'putLong ( ze . getCompressedSize ( ) , buf , LFH COMPRESSED SIZE OFFSET ) ;', 'private boolean isTooLageForZip32 ( ZipArchiveEntry zipArchiveEntry ) {', 'return requestedMode = = Zip64Mode . Always | | isTooLageForZip32 ( entry1 ) ;', 'putLong ( ze . getSize ( ) , buf , LFH ORIGINAL SIZE OFFSET ) ;', '} else {', '}', 'putLong ( ze . getSize ( ) , buf , LFH COMPRESSED SIZE OFFSET ) ;', 'final Zip64Mode effectiveMode = getEffectiveZip64Mode ( entry . entry ) ;', 'final boolean actuallyNeedsZip64 = isZip64Required ( entry . entry , effectiveMode ) ;', 'return zipArchiveEntry . getSize ( ) > = ZIP64 MAGIC | | zipArchiveEntry . getCompressedSize ( ) > = ZIP64 MAGIC ;', 'putArchiveEntry ( archiveEntry , false ) ;', 'if ( hasZip64Extra ( entry . entry ) ) {', 'if ( hasZip64Extra ( ae ) ) {', 'if ( phased ) {', 'closeEntry ( actuallyNeedsZip64 , false ) ;', 'putLong ( ze . getCrc ( ) , buf , LFH CRC OFFSET ) ;', 'System . arraycopy ( LZERO , 0 , buf , LFH ORIGINAL SIZE OFFSET , WORD ) ;', 'private void writeLocalFileHeader ( ZipArchiveEntry ze , boolean phased ) throws IOException {', 'compressedSize = size ;', 'boolean phased ) {', 'size = new ZipEightByteInteger ( entry . entry . getSize ( ) ) ;', '} else if ( phased ) {', '} else if ( entry . entry . getMethod ( ) = = STORED', 'ZipLong . ZIP64 MAGIC . putLong ( buf , LFH COMPRESSED SIZE OFFSET ) ;', 'writeLocalFileHeader ( ( ZipArchiveEntry ) archiveEntry , phased ) ;', '& & ae . getSize ( ) ! = ArchiveEntry . SIZE UNKNOWN', 'final boolean actuallyNeedsZip64 = handleSizesAndCrc ( bytesWritten , realCrc , effectiveMode ) ;', 'ae . removeExtraField ( Zip64ExtendedInformationExtraField . HEADER ID ) ;', 'System . arraycopy ( LZERO , 0 , buf , LFH COMPRESSED SIZE OFFSET , WORD ) ;', 'final byte [ ] localHeader = createLocalFileHeader ( ze , name , encodable , phased ) ;', 'private void closeCopiedEntry ( boolean phased ) throws IOException {', 'writeLocalFileHeader ( ze , false ) ;', 'private void putArchiveEntry ( ArchiveEntry archiveEntry , boolean phased ) throws IOException {', 'private boolean isZip64Required ( ZipArchiveEntry entry1 , Zip64Mode requestedMode ) {', 'if ( phased & & !isZip64Required ( entry . entry , zip64Mode ) ) {', 'compressedSize = new ZipEightByteInteger ( entry . entry . getCompressedSize ( ) ) ;', 'ZipEightByteInteger compressedSize = ZipEightByteInteger . ZERO ;', 'if ( !phased & & raf ! = null ) {', 'boolean is2PhaseSource = ae . getCrc ( ) ! = - 1', 'ZipLong . ZIP64 MAGIC . putLong ( buf , LFH ORIGINAL SIZE OFFSET ) ;', 'closeCopiedEntry ( is2PhaseSource ) ;', '& & entry . entry . getSize ( ) ! = ArchiveEntry . SIZE UNKNOWN ) {', 'z64 . setCompressedSize ( compressedSize ) ;', 'putArchiveEntry ( ae , is2PhaseSource ) ;', 'putShort ( versionNeededToExtract ( zipMethod , hasZip64Extra ( ze ) ) , buf , LFH VERSION NEEDED OFFSET ) ;', '& & ae . getCompressedSize ( ) ! = - 1 ;', 'closeEntry ( actuallyNeedsZip64 , phased ) ;', 'private byte [ ] createLocalFileHeader ( ZipArchiveEntry ze , ByteBuffer name , boolean encodable ,', 'putShort ( INITIAL VERSION , buf , LFH VERSION NEEDED OFFSET ) ;'}, 'removed_code': {'private void doCloseCopiedEntry ( ) throws IOException {', 'putLong ( ze . getSize ( ) , buf , LFH ORIGINAL SIZE OFFSET ) ;', '} else {', '}', 'putLong ( ze . getSize ( ) , buf , LFH COMPRESSED SIZE OFFSET ) ;', 'private void closeCopiedEntry ( ) throws IOException {', 'final Zip64Mode effectiveMode = getEffectiveZip64Mode ( entry . entry ) ;', 'final byte [ ] localHeader = createLocalFileHeader ( ze , name , encodable ) ;', 'if ( hasZip64Extra ( entry . entry ) ) {', 'System . arraycopy ( LZERO , 0 , buf , LFH ORIGINAL SIZE OFFSET , WORD ) ;', 'private void doCloseEntry ( long realCrc , long bytesWritten ) throws IOException {', 'private void closeEntry ( boolean actuallyNeedsZip64 ) throws IOException {', 'z64 . setCompressedSize ( size ) ;', 'if ( raf ! = null ) {', 'if ( !hasZip64Extra ( ze ) ) {', '| | entry . entry . getCompressedSize ( ) > = ZIP64 MAGIC ;', 'ZipLong . ZIP64 MAGIC . putLong ( buf , LFH COMPRESSED SIZE OFFSET ) ;', 'closeEntry ( actuallyNeedsZip64 ) ;', 'final boolean actuallyNeedsZip64 = handleSizesAndCrc ( bytesWritten , realCrc , effectiveMode ) ;', '| | entry . entry . getSize ( ) > = ZIP64 MAGIC', 'System . arraycopy ( LZERO , 0 , buf , LFH COMPRESSED SIZE OFFSET , WORD ) ;', 'final boolean actuallyNeedsZip64 = effectiveMode = = Zip64Mode . Always', 'doCloseCopiedEntry ( ) ;', 'if ( zipMethod = = DEFLATED | | raf ! = null ) {', 'putArchiveEntry ( ae ) ;', 'ZipLong . ZIP64 MAGIC . putLong ( buf , LFH ORIGINAL SIZE OFFSET ) ;', 'doCloseEntry ( realCrc , bytesWritten ) ;', 'private byte [ ] createLocalFileHeader ( ZipArchiveEntry ze , ByteBuffer name , boolean encodable ) {', '& & entry . entry . getSize ( ) ! = ArchiveEntry . SIZE UNKNOWN ) {', 'if ( entry . entry . getMethod ( ) = = STORED', 'putShort ( versionNeededToExtract ( zipMethod , hasZip64Extra ( ze ) ) , buf , LFH VERSION NEEDED OFFSET ) ;', 'writeLocalFileHeader ( ( ZipArchiveEntry ) archiveEntry ) ;', 'closeCopiedEntry ( ) ;'}}"
42662f8750a2c33ee169f17f4b4e4586db98d869,1.0,"PARQUET - 389 : Support predicate push down on missing columns . Predicate push - down will complain when predicates reference columns that aren't in a file's schema . This makes it difficult to implement predicate push - down in engines where schemas evolve because each task needs to process the predicates and prune references to columns not in that task's file . This PR implements predicate evaluation for missing columns , where the values are all null . This allows engines to pass predicates as they are written . A future commit should rewrite the predicates to avoid the extra work currently done in record - level filtering , but that isn't included here because it is an optimization . Author : Ryan Blue < blue @ apache . org > Closes #354 from rdblue / PARQUET - 389 - predicate - push - down - on - missing - columns and squashes the following commits : b4d809a [ Ryan Blue ] PARQUET - 389 : Support record - level filtering with missing columns . 91b841c [ Ryan Blue ] PARQUET - 389 : Add missing column support to StatisticsFilter . 275f950 [ Ryan Blue ] PARQUET - 389 : Add missing column support to DictionaryFilter .","{'added_code': {'if ( value ! = null ) {', 'if ( meta = = null ) {', '}', 'if ( hasNulls ( meta ) ) {', 'private static final boolean BLOCK CANNOT MATCH = true ;', 'ColumnChunkMetaData meta = getColumnChunk ( filterColumn . getColumnPath ( ) ) ;', 'T value = gtEq . getValue ( ) ;', 'if ( value = = null ) {', 'Statistics < T > stats = meta . getStatistics ( ) ;', 'return BLOCK MIGHT MATCH ;', 'return isAllNulls ( meta ) ;', 'T value = gt . getValue ( ) ;', 'T value = ltEq . getValue ( ) ;', 'T value = lt . getValue ( ) ;', 'return !hasNulls ( meta ) ;', 'return BLOCK CANNOT MATCH ;', 'if ( isAllNulls ( meta ) ) {', 'private static final boolean BLOCK MIGHT MATCH = false ;', 'return columns . get ( columnPath ) ;', '@ SuppressWarnings ( ""unchecked"" )'}, 'removed_code': {'ColumnChunkMetaData columnChunk = getColumnChunk ( filterColumn . getColumnPath ( ) ) ;', 'return c ;', 'if ( isAllNulls ( columnChunk ) ) {', 'return !hasNulls ( columnChunk ) ;', 'ColumnChunkMetaData c = columns . get ( columnPath ) ;', 'T value = lt . getValue ( ) ;', 'return true ;', 'return isAllNulls ( columnChunk ) ;', 'return false ;', 'if ( hasNulls ( columnChunk ) ) {', 'Statistics < T > stats = columnChunk . getStatistics ( ) ;', 'T value = gt . getValue ( ) ;', 'T value = gtEq . getValue ( ) ;', 'checkArgument ( c ! = null , ""Column "" + columnPath . toDotString ( ) + "" not found in schema!"" ) ;', 'T value = ltEq . getValue ( ) ;'}}"
33c95771c804abc02223f24a0234343b93ffde56,1.0,"COMPRESS - 290 Fixed error message with large groupid This is a bit of a simple solution to the issue , since there are obviously lots of other options that could have similar updates . The reality is that most recent macs that are initialized to run in corporate networks tend to get large GID's for the users . So I just fixed the one we actually have complaints about","{'added_code': {'private void failForBigNumber ( String field , long value , long maxValue , String additionalMsg ) {', '+ ""\' is too big ( > ""', 'failForBigNumberWithPosixMessage ( ""group id"" , entry . getGroupId ( ) , TarConstants . MAXID ) ;', 'failForBigNumber ( field , value , maxValue , "" Use STAR or POSIX extensions to overcome this limit"" ) ;', '}', 'private void failForBigNumberWithPosixMessage ( String field , long value , long maxValue ) {', '+ maxValue + "" ) . "" + additionalMsg ) ;', 'failForBigNumber ( field , value , maxValue , """" ) ;'}, 'removed_code': {'failForBigNumber ( ""group id"" , entry . getGroupId ( ) , TarConstants . MAXID ) ;', '+ ""\' is too big ( > ""', '+ maxValue + "" ) "" ) ;'}}"
c5ae09d77e8756ab73e1c39f77f1b303aa4ba384,1.0,"Improved brackting utility for univariate solvers . Bracketing utility for univariate root solvers now returns a tighter interval than before . It also allows choosing the search interval expansion rate , supporting both linear and asymptotically exponential rates .","{'added_code': {'public static double [ ] bracket ( final UnivariateFunction function , final double initial ,', 'if ( fa * previousFa < = 0 ) {', '} else {', 'throw new NotStrictlyPositiveException ( q ) ;', 'return bracket ( function , initial , lowerBound , upperBound , 1 . 0 , 1 . 0 , Integer . MAX VALUE ) ;', '}', 'final double previousFa = fa ;', 'double fa = Double . NaN ;', 'final double previousB = b ;', 'return new double [ ] { a , b } ;', 'fb = function . value ( b ) ;', 'throw new NoBracketingException ( a , b , fa , fb ) ;', 'return bracket ( function , initial , lowerBound , upperBound , 1 . 0 , 1 . 0 , maximumIterations ) ;', 'if ( fa * fb < = 0 ) {', 'final double previousA = a ;', 'double fb = Double . NaN ;', 'final double q , final double r , final int maximumIterations )', 'return new double [ ] { a , previousA } ;', 'double b = initial ;', '+ + numIterations ) {', 'final double previousFb = fb ;', 'a = FastMath . max ( initial - delta , lowerBound ) ;', 'if ( numIterations = = 0 ) {', 'fa = function . value ( a ) ;', 'return new double [ ] { previousB , b } ;', '} else if ( fb * previousFb < = 0 ) {', 'double a = initial ;', 'final double lowerBound , final double upperBound ,', 'for ( int numIterations = 0 ;', 'throws NoBracketingException {', 'b = FastMath . min ( initial + delta , upperBound ) ;', 'double delta = 0 ;', 'if ( q < = 0 ) {', '( numIterations < maximumIterations ) & & ( a > lowerBound | | b > upperBound ) ;', 'delta = r * delta + q ;'}, 'removed_code': {'lowerBound , upperBound ) ;', 'do {', 'return new double [ ] { a , b } ;', 'fb = function . value ( b ) ;', 'double fb ;', 'return bracket ( function , initial , lowerBound , upperBound , Integer . MAX VALUE ) ;', 'double b = initial ;', 'b = FastMath . min ( b + 1 . 0 , upperBound ) ;', 'throw new NoBracketingException ( LocalizedFormats . FAILED BRACKETING ,', 'fa = function . value ( a ) ;', 'int numIterations = 0 ;', 'a , b , fa , fb ,', '+ + numIterations ;', 'double a = initial ;', 'numIterations , maximumIterations , initial ,', 'double fa ;', '} while ( ( fa * fb > 0 . 0 ) & & ( numIterations < maximumIterations ) & &', 'if ( fa * fb > 0 . 0 ) {', '( ( a > lowerBound ) | | ( b < upperBound ) ) ) ;', 'a = FastMath . max ( a - 1 . 0 , lowerBound ) ;'}}"
5ec70549ae7e7d2eb97d3d56e696dbf0cef7ca35,1.0,Clean up API Use LinkedBlockingQueue instead of home - grown implementation,"{'added_code': {'log . info ( ""Destroying queue , stats = "" + getStatistics ( ) ) ;', 'AbstractCacheEvent event = null ;', 'else', 'log . info ( ""Destroy was called after queue was destroyed . Doing nothing . Stats = "" + getStatistics ( ) ) ;', '}', 'if ( processorThread ! = null )', 'QProcessor ( )', 'if ( isWorking ( ) )', 'stopProcessing ( ) ;', 'log . debug ( ""QProcessor exiting for "" + getCacheName ( ) ) ;', 'while ( isAlive ( ) )', 'protected void stopProcessing ( )', 'private LinkedBlockingQueue < AbstractCacheEvent > queue = new LinkedBlockingQueue < AbstractCacheEvent > ( ) ;', 'log . debug ( ""Event entering Queue for "" + getCacheName ( ) + "" : "" + event ) ;', 'processorThread = new QProcessor ( ) ;', 'if ( event ! = null & & isWorking ( ) & & isAlive ( ) )', 'if ( !isAlive ( ) )', 'log . info ( ""Cache event queue created : "" + this ) ;', 'processorThread . start ( ) ;', 'if ( log . isInfoEnabled ( ) )', 'queue . offer ( event ) ;', 'try', 'processorThread = null ;', 'import java . util . ArrayList ;', 'setAlive ( false ) ;', 'catch ( InterruptedException e )', 'return queue . size ( ) ;', 'import java . util . concurrent . LinkedBlockingQueue ;', 'log . info ( ""Cache event queue destroyed : "" + this ) ;', 'initialize ( listener , listenerId , cacheName , maxFailure , waitBeforeRetry ) ;', 'elems . add ( new StatElement < Integer > ( ""Size"" , Integer . valueOf ( this . size ( ) ) ) ) ;', 'protected class QProcessor', 'processorThread . interrupt ( ) ;', '{', 'elems . add ( new StatElement < Boolean > ( ""Working"" , Boolean . valueOf ( this . isWorking ( ) ) ) ) ;', 'import java . util . concurrent . TimeUnit ;', 'event = queue . poll ( getWaitToDieMillis ( ) , TimeUnit . MILLISECONDS ) ;', 'return queue . isEmpty ( ) ;', 'if ( isAlive ( ) )', 'super ( ""CacheEventQueue . QProcessor - "" + getCacheName ( ) ) ;', 'setAlive ( true ) ;'}, 'removed_code': {'else', 'private final Object queueLock = new Object ( ) ;', 'this . maxFailure = maxFailure < = 0 ? 3 : maxFailure ;', 'if ( isWorking ( ) )', 'return ;', 'event = queue . take ( ) ;', 'n = n . next ;', 'size - - ;', 'CacheEventQueue < K , V > queue ;', 'try', 'if ( head = = tail )', 'int sz = 0 ;', 'this . listenerId = listenerId ;', 'log . debug ( ""node . event = "" + node . event ) ;', 'return tail = = head ;', 'sz = 0 ;', '@ SuppressWarnings ( ""synthetic - access"" )', 'initialize ( listener , listenerId , cacheName , maxFailure , waitBeforeRetry , null ) ;', 'AbstractCacheEvent value = ( AbstractCacheEvent ) node . event ;', '@ SuppressWarnings ( ""unchecked"" )', 'private Node head = new Node ( ) ;', 'super ( ""CacheEventQueue . QProcessor - "" + aQueue . cacheName ) ;', 'log . info ( ""Destroy was called after queue was destroyed . Doing nothing . Stats = "" + getStatistics ( ) ) ;', 'public void initialize ( ICacheListener < K , V > listener , long listenerId , String cacheName , int maxFailure ,', 'public void stopProcessing ( )', 'tail = newNode ;', 'this . listener = listener ;', 'synchronized ( queueLock )', 'head = node ;', 'private Node tail = head ;', 'return value ;', 'queueLock . wait ( queue . getWaitToDieMillis ( ) ) ;', 'destroyed = true ;', 'log . debug ( ""Event entering Queue for "" + cacheName + "" : "" + event ) ;', 'import java . util . ArrayList ;', 'catch ( InterruptedException e )', 'log . info ( ""Cache event queue destroyed : "" + this ) ;', 'elems . add ( new StatElement < Integer > ( ""Size"" , Integer . valueOf ( sz ) ) ) ;', 'if ( queue . isWorking ( ) & & queue . isAlive ( ) & & event ! = null )', 'processorThread . interrupt ( ) ;', 'if ( listener = = null )', '{', 'Node newNode = new Node ( ) ;', 'destroyed = false ;', 'log . warn ( ""Interrupted while waiting for another event to come in before we die . "" ) ;', 'if ( processorThread ! = null )', 'log . debug ( ""Event from queue after sleep = "" + event ) ;', 'newNode . event = event ;', 'if ( log . isDebugEnabled ( ) )', 'if ( event = = null )', 'processorThread . start ( ) ;', 'int waitBeforeRetry , String threadPoolName )', 'if ( !destroyed )', 'private int size = 0 ;', '@ Override', 'size + + ;', 'sz + + ;', 'Node node = head . next ;', 'elems . add ( new StatElement < Boolean > ( ""Working"" , Boolean . valueOf ( super . isWorking ( ) ) ) ) ;', 'log . info ( ""Destroying queue , stats = "" + getStatistics ( ) ) ;', 'AbstractCacheEvent event = null ;', '}', 'while ( n ! = null )', 'private class QProcessor', 'protected AbstractCacheEvent take ( )', 'queue = aQueue ;', 'log . debug ( ""head . event = "" + head . event ) ;', 'if ( !isAlive ( ) )', 'log . info ( ""Cache event queue created : "" + this ) ;', 'return size ;', 'this . cacheName = cacheName ;', 'if ( log . isInfoEnabled ( ) )', 'processorThread = null ;', 'log . debug ( ""QProcessor exiting for "" + queue ) ;', 'log . debug ( ""Constructed : "" + this ) ;', 'throw new IllegalArgumentException ( ""listener must not be null"" ) ;', 'processorThread = new QProcessor ( this ) ;', 'QProcessor ( CacheEventQueue < K , V > aQueue )', 'Node n = head ;', 'tail . next = newNode ;', 'return null ;', 'node . event = null ;', 'queueLock . notify ( ) ;', 'while ( queue . isAlive ( ) )', 'this . waitBeforeRetry = waitBeforeRetry < = 0 ? 500 : waitBeforeRetry ;', 'queue . stopProcessing ( ) ;'}}"
a2ba6d54852aceda5e3bf9285730da743ef04e77,1.0,Bugfix for COMPRESS - 343,"{'added_code': {'public void close ( ) throws IOException {', 'inflater ) ;', 'deflaterOutputStream . close ( ) ;', 'inflater . end ( ) ;', 'deflaterOutputStream . write ( b ) ;', 'public int read ( ) throws IOException {', 'final DeflaterOutputStream deflaterOutputStream = new DeflaterOutputStream ( out , deflater ) ;', '}', 'return inflaterInputStream . read ( b , off , len ) ;', 'final Deflater deflater = new Deflater ( level , true ) ;', 'public void write ( int b ) throws IOException {', 'return inflaterInputStream . read ( ) ;', '} ;', 'return new OutputStream ( ) {', 'return inflaterInputStream . read ( b ) ;', 'deflater . end ( ) ;', 'public void write ( byte [ ] b , int off , int len ) throws IOException {', 'public void write ( byte [ ] b ) throws IOException {', '@ Override', 'public int read ( byte [ ] b , int off , int len ) throws IOException {', 'return new InputStream ( ) {', 'final InflaterInputStream inflaterInputStream = new InflaterInputStream ( new DummyByteAddingInputStream ( in ) ,', 'final Inflater inflater = new Inflater ( true ) ;', 'deflaterOutputStream . write ( b , off , len ) ;', 'inflaterInputStream . close ( ) ;', 'public int read ( byte [ ] b ) throws IOException {'}, 'removed_code': {'return new DeflaterOutputStream ( out , new Deflater ( level , true ) ) ;', 'return new InflaterInputStream ( new DummyByteAddingInputStream ( in ) ,', 'new Inflater ( true ) ) ;'}}"
96531689d341eb26103356410280447e94529b5a,1.0,Backport CONFIGURATION - 500 from r1382310 .,"{'added_code': {'String attr , Collection < String > values )', 'node . addAttribute ( child ) ;', 'else', 'attrmap = new HashMap < String , Collection < String > > ( ) ;', '}', 'private void handleDelimiters ( Node parent , Node child , boolean trim ,', 'private void appendAttributes ( Node node , Element element , boolean elemRefs ,', 'Map < String , Collection < String > > attrmap ;', 'private Map < String , Collection < String > > constructHierarchy ( Node node ,', 'attrmap = Collections . emptyMap ( ) ;', 'return attributes ;', 'appendAttributes ( node , element , elemRefs , attr . getName ( ) , values ) ;', 'handleDelimiters ( node , childNode , trimFlag , attrmap ) ;', 'attrmap . put ( attr . getName ( ) , values ) ;', 'e . getValue ( ) ) ;', 'Map < String , Collection < String > > attrmap =', 'return attrmap ;', 'appendAttributes ( c , null , false , e . getKey ( ) ,', 'for ( String value : values )', 'Map < String , Collection < String > > attributes =', 'if ( attributes . getLength ( ) > 0 )', 'processAttributes ( node , element , elemRefs ) ;', 'constructHierarchy ( childNode , child , elemRefs , trimFlag ) ;', '. entrySet ( ) )', 'child . setValue ( value ) ;', '{', 'Element element , boolean elemRefs , boolean trim )', 'private Map < String , Collection < String > > processAttributes ( Node node ,', 'for ( Map . Entry < String , Collection < String > > e : attrmap', 'Map < String , Collection < String > > attrmap )', 'Node child = new XMLNode ( attr , elemRefs ? element : null ) ;', 'Element element , boolean elemRefs )'}, 'removed_code': {'handleDelimiters ( node , childNode , trimFlag ) ;', 'node . addAttribute ( child ) ;', 'constructHierarchy ( childNode , child , elemRefs , trimFlag ) ;', ': null ) ;', 'private void constructHierarchy ( Node node , Element element , boolean elemRefs , boolean trim )', 'private void handleDelimiters ( Node parent , Node child , boolean trim )', '{', 'Node child = new XMLNode ( attr . getName ( ) , elemRefs ? element', '}', 'for ( String value : values )', 'private void processAttributes ( Node node , Element element , boolean elemRefs )', 'child . setValue ( value ) ;', 'processAttributes ( node , element , elemRefs ) ;'}}"
be2aa80bc371d600ab2230c545051ea6454577f5,1.0,FIX : PomModuleDescriptorBuilder does not resolve ejb type dependencies to jar extension ( IVY - 1058 ) ( thanks to Andrey Lomakin ),"{'added_code': {'String ext = type ;', 'type , ext , null , extraAtt ) ;', '}', 'ext = ""jar"" ;', 'if ( JAR PACKAGINGS . contains ( type ) ) {'}, 'removed_code': {'type , type , null , extraAtt ) ;'}}"
9c881675d214b95fcf861b69b4204bcd7932f66b,1.0,[ CODEC - 199 ] Bug in HW rule in Soundex . Applying 2nd version of the patch .,"{'added_code': {'out [ count + + ] = mapped ;', 'public static final String US ENGLISH MAPPING STRING = ""0123012#02245501262301#202"" ;', 'last = this . map ( str . charAt ( 0 ) ) ;', ""if ( mapped = = '0' ) {"", ""} else if ( mapped ! = '#' & & mapped ! = last ) {"", 'last = mapped ;', 'mapped = this . map ( str . charAt ( incount + + ) ) ;'}, 'removed_code': {'out [ count + + ] = mapped ;', 'final char prevChar = str . charAt ( i ) ;', 'final char mappedChar = this . map ( str . charAt ( index ) ) ;', 'if ( this . map ( prevChar ) = = mappedChar ) {', 'mapped = getMappingCode ( str , incount + + ) ;', 'public static final String US ENGLISH MAPPING STRING = ""01230120022455012623010202"" ;', 'last = getMappingCode ( str , 0 ) ;', 'break ;', 'return mappedChar ;', ""if ( mapped ! = '0' & & mapped ! = last ) {"", '}', ""if ( index > 1 & & mappedChar ! = '0' ) {"", 'if ( mapped ! = 0 ) {', 'return 0 ;', 'private char getMappingCode ( final String str , final int index ) {', 'for ( int i = index - 1 ; i > = 0 ; i - - ) {', ""if ( 'H'! = prevChar & & 'W'! = prevChar ) {""}}"
348e020e1df6c0b3a5b8c38b220746617320fb43,1.0,GORA - 477 Add support for Solr 5 . x,"{'added_code': {'fieldValue = data ;', 'return new SolrResult < > ( this , query , server , resultsSize ) ;', 'if ( batch . size ( ) > 0 ) {', '( DefaultHttpClient ) ( ( HttpSolrClient ) server ) . getHttpClient ( ) ,', 'private int batchSize = DEFAULT BATCH SIZE ;', 'if ( fieldSchema . getTypes ( ) . size ( ) = = 2 & & isNullable ( fieldSchema ) ) {', 'import org . apache . avro . specific . SpecificDatumReader ;', 'public T get ( K key , String [ ] fields ) {', 'protected static final String SOLR SERVER USERNAME = ""solr . solrjserver . username"" ;', 'import java . io . IOException ;', 'throw new IOException ( ex ) ;', 'fieldValue = solrValue ;', 'solrJServerImpl = DataStoreFactory . findProperty ( properties , this ,', 'public void put ( K key , T persistent ) {', 'protected static final String SOLR SCHEMA PROPERTY = ""solr . schema"" ;', 'if ( autoCreateSchema ) {', 'SpecificDatumReader < ? > reader = readerMap . get ( fieldSchema ) ;', 'if ( serverUserAuth ) {', 'String mappingFile = DataStoreFactory . getMappingFile ( properties , this ,', 'import org . apache . gora . query . impl . PartitionQueryImpl ;', 'fieldValue = serilazeData ;', 'else if ( pValue instanceof Map & & schemaType . equals ( Type . MAP ) )', 'if ( ( localReader = readerMap . putIfAbsent ( fieldSchema , reader ) ) ! = null ) {', 'protected static final String SOLR SERVER USER AUTH = ""solr . solrjserver . user auth"" ;', 'public Result < K , T > execute ( Query < K , T > query ) {', 'protected static final String SOLR SERVER PASSWORD = ""solr . solrjserver . password"" ;', 'import org . apache . gora . solr . query . SolrResult ;', 'v = serializeFieldValue ( fieldSchema , v ) ;', '@ SuppressWarnings ( ""rawtypes"" )', 'Object o = rsp . getResponse ( ) . get ( ""doc"" ) ;', 'for ( String f : fields ) {', 'return partitions ;', 'String solrJServerType = ( ( solrJServerImpl = = null | | solrJServerImpl . equals ( """" ) ) ? ""http"" : solrJServerImpl ) ;', 'else if ( pValue instanceof Long & & schemaType . equals ( Type . LONG ) )', 'else if ( pValue instanceof Boolean & & schemaType . equals ( Type . BOOLEAN ) )', 'public static String escapeQueryKey ( String key ) {', 'import org . apache . avro . Schema . Type ;', 'SOLR SERVER PASSWORD , null ) ;', 'import java . util . ArrayList ;', 'Schema schema = persistent . getSchema ( ) ;', '( DefaultHttpClient ) ( ( LBHttpSolrClient ) adminServer ) . getHttpClient ( ) ,', 'return new SolrQuery < > ( this ) ;', 'doc . addField ( mapping . getPrimaryKey ( ) , key ) ;', 'return unionSchemaPos ;', 'SolrClientUrl = DataStoreFactory . findProperty ( properties , this ,', 'import org . apache . gora . util . IOUtils ;', 'protected static final String SOLR BATCH SIZE PROPERTY = ""solr . batch size"" ;', 'protected static final String SOLR URL PROPERTY = ""solr . url"" ;', 'private String SolrClientUrl , solrConfig , solrSchema , solrJServerImpl ;', 'protected static final String SOLR COMMIT WITHIN PROPERTY = ""solr . commit within"" ;', 'import org . apache . gora . query . Query ;', 'byte [ ] data = null ;', 'import org . apache . solr . common . params . ModifiableSolrParams ;', 'unionSchemaPos + + ;', 'import org . apache . solr . common . SolrInputDocument ;', 'Field field = fieldMap . get ( f ) ;', 'private boolean isNullable ( Schema unionSchema ) {', '} else if ( solrJServerType . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""loadbalance"" ) ) {', 'import org . apache . avro . Schema . Field ;', 'import org . apache . gora . store . DataStoreFactory ;', 'int unionSchemaPos = 0 ;', 'flush ( ) ;', 'this . adminServer = new HttpSolrClient ( SolrClientUrl ) ;', '@ Override', 'LOG . info ( ""Using ConcurrentUpdateSolrClient Solrj implementation . "" ) ;', 'sb . append ( "" \\ \\ "" ) . append ( c ) ;', 'import java . util . Locale ;', 'fieldSchema = fieldSchema . getTypes ( ) . get ( 1 ) ;', 'List < Field > fields = schema . getFields ( ) ;', 'case BYTES :', 'import org . jdom . input . SAXBuilder ;', ""case ' * ' :"", 'SpecificDatumReader reader = getDatumReader ( fieldSchema ) ;', 'persistent . put ( field . pos ( ) , v ) ;', 'Object solrValue , T persistent ) throws IOException {', 'public class SolrStore < K , T extends PersistentBase > extends DataStoreBase < K , T > {', 'if ( classElement . getAttributeValue ( ""keyClass"" ) . equals (', 'for ( Element classElement : classes ) {', 'import org . apache . solr . common . params . CommonParams ;', 'persistent ) ;', 'public void deleteSchema ( ) {', 'Schema unionSchema = fieldSchema . getTypes ( ) . get ( schemaPos ) ;', 'public void close ( ) {', 'exists = rsp . getUptime ( mapping . getCoreName ( ) ) ! = null ;', 'import java . util . Properties ;', 'private int resultsSize = DEFAULT RESULTS SIZE ;', 'sf = f ;', 'fieldValue = IOUtils . deserialize ( ( byte [ ] ) solrValue , reader ,', 'ArrayList < PartitionQuery < K , T > > partitions = new ArrayList < > ( ) ;', 'batch . add ( doc ) ;', 'public static final int DEFAULT UNION SCHEMA = 0 ;', 'resultsSize = Integer . parseInt ( resultsSizeString ) ;', 'case STRING :', 'fields = fieldMap . keySet ( ) . toArray ( new String [ fieldMap . size ( ) ] ) ;', 'add ( batch , commitWithin ) ;', 'import org . slf4j . LoggerFactory ;', 'LOG . info ( ""Using Solr server at "" + SolrClientUrl ) ;', 'private Object deserializeFieldValue ( Field field , Schema fieldSchema ,', 'SolrMapping map = new SolrMapping ( ) ;', 'case UNION :', 'pqi . setConf ( getConf ( ) ) ;', 'SolrInputDocument doc = new SolrInputDocument ( ) ;', 'if ( o = = null ) {', 'if ( i > 0 )', 'writerMap . put ( fieldSchema , writer ) ;', 'CoreAdminRequest . createCore ( mapping . getCoreName ( ) ,', 'return exists ;', 'SOLR BATCH SIZE PROPERTY , null ) ;', 'if ( e . getMessage ( ) . contains ( ""No such core"" ) ) {', '} catch ( Exception e ) {', '} catch ( Exception ex ) {', 'fieldValue = ( ( ByteBuffer ) fieldValue ) . array ( ) ;', 'case ENUM :', 'import java . util . Map ;', 'private int getUnionSchema ( Object pValue , Schema pUnionSchema ) {', 'if ( key = = null ) {', 'import org . apache . solr . client . solrj . response . UpdateResponse ;', 'public static final ConcurrentHashMap < Schema , SpecificDatumWriter < ? > > writerMap = new ConcurrentHashMap < > ( ) ;', 'String tableName = getSchemaName (', '@ SuppressWarnings ( ""unchecked"" )', 'serverUsername , serverPassword ) ;', 'Type type0 = fieldSchema . getTypes ( ) . get ( 0 ) . getType ( ) ;', 'params . set ( CommonParams . QT , "" / get"" ) ;', '( DefaultHttpClient ) ( ( CloudSolrClient ) server ) . getLbClient ( ) . getHttpClient ( ) ,', 'params . set ( ""id"" , key . toString ( ) ) ;', 'String pk = mapping . getPrimaryKey ( ) ;', 'public T newInstance ( SolrDocument doc , String [ ] fields ) throws IOException {', 'case RECORD :', 'import org . apache . solr . client . solrj . impl . ConcurrentUpdateSolrClient ;', 'this . adminServer = new ConcurrentUpdateSolrClient ( SolrClientUrl , 1000 , 10 ) ;', 'import org . apache . solr . client . solrj . impl . HttpSolrClient ;', 'SOLR SCHEMA PROPERTY , null ) ;', 'reader = new SpecificDatumReader ( fieldSchema ) ;', 'if ( writer = = null ) {', 'fieldValue = deserializeFieldValue ( field , fieldSchema , solrValue ,', 'QueryResponse rsp = server . query ( params ) ;', 'SpecificDatumReader unionReader = getDatumReader ( fieldSchema ) ;', 'else if ( pValue instanceof Integer & & schemaType . equals ( Type . INT ) )', 'LOG . info ( rsp . toString ( ) ) ;', 'else if ( pValue instanceof Persistent & & schemaType . equals ( Type . RECORD ) )', 'Properties properties ) {', 'import java . util . List ;', 'import org . apache . solr . common . SolrDocument ;', 'this . server = new CloudSolrClient ( SolrClientUrl + "" / "" + mapping . getCoreName ( ) ) ;', 'persistent . setDirty ( field . pos ( ) ) ;', 'import org . apache . solr . client . solrj . impl . CloudSolrClient ;', 'CoreAdminResponse rsp = CoreAdminRequest . getStatus ( mapping . getCoreName ( ) ,', 'SOLR SERVER USERNAME , null ) ;', 'import org . apache . solr . client . solrj . response . CoreAdminResponse ;', 'byte [ ] serilazeData = null ;', 'LOG . warn ( ""Invalid commit within \' { } \' , using default { } "" , commitWithinString , DEFAULT COMMIT WITHIN ) ;', 'public void createSchema ( ) {', 'doc . addField ( sf , v ) ;', 'persistent . get ( field . pos ( ) ) ) ;', 'batchSize = Integer . parseInt ( batchSizeString ) ;', 'String batchSizeString = DataStoreFactory . findProperty ( properties , this ,', 'try {', 'char c = key . charAt ( i ) ;', 'String sf = mapping . getSolrField ( field . name ( ) ) ;', 'map . setPrimaryKey ( primaryKeyEl . getAttributeValue ( ""column"" ) ) ;', 'for ( Element field : fields ) {', 'protected static final String SOLR RESULTS SIZE PROPERTY = ""solr . results size"" ;', 'import org . apache . hadoop . util . StringUtils ;', '( DefaultHttpClient ) ( ( CloudSolrClient ) adminServer ) . getLbClient ( ) . getHttpClient ( ) ,', 'import org . jdom . Element ;', '+ escapeQueryKey ( key . toString ( ) ) ) ;', '}', 'Document doc = builder . build ( getClass ( ) . getClassLoader ( )', 'mapping = readMapping ( mappingFile ) ;', 'break ;', 'private SpecificDatumWriter getDatumWriter ( Schema fieldSchema ) {', 'import org . apache . gora . query . Result ;', 'default :', 'String sf = null ;', 'else if ( pValue instanceof ByteBuffer & & schemaType . equals ( Type . BYTES ) )', 'return null ;', 'SOLR CONFIG PROPERTY , null ) ;', 'fieldValue = fieldValue . toString ( ) ;', 'LOG . info ( ""Using HttpSolrClient Solrj implementation . "" ) ;', 'return true ;', 'return newInstance ( ( SolrDocument ) o , fields ) ;', 'Schema fieldSchema = field . schema ( ) ;', 'switch ( c ) {', 'String columnName = field . getAttributeValue ( ""column"" ) ;', 'return mapping . getCoreName ( ) ;', 'server . commit ( false , true , true ) ;', '} catch ( MalformedURLException e ) {', 'protected static final int DEFAULT BATCH SIZE = 100 ;', 'else', 'sb . append ( c ) ;', 'List < Element > fields = classElement . getChildren ( ""field"" ) ;', 'case MAP :', 'adminServer ) ;', 'LOG . error ( e . getMessage ( ) , e ) ;', 'T persistent = newPersistent ( ) ;', 'private ArrayList < SolrInputDocument > batch ;', 'PartitionQueryImpl < K , T > pqi = new PartitionQueryImpl < > ( query ) ;', 'solrConfig = DataStoreFactory . findProperty ( properties , this ,', 'return false ;', 'String q = ( ( SolrQuery < K , T > ) query ) . toSolrQuery ( ) ;', 'List < Element > classes = doc . getRootElement ( ) . getChildren ( ""class"" ) ;', 'public List < PartitionQuery < K , T > > getPartitions ( Query < K , T > query )', 'protected static final String SOLR SOLRJSERVER IMPL = ""solr . solrjserver"" ;', 'SpecificDatumReader localReader = null ;', 'classElement . getAttributeValue ( ""table"" ) , persistentClass ) ;', 'writer = new SpecificDatumWriter ( fieldSchema ) ;', 'public void truncateSchema ( ) {', 'protected static final String SOLR CONFIG PROPERTY = ""solr . config"" ;', 'return 0 ;', 'LOG . warn ( ""Invalid results size \' { } \' , using default { } "" , resultsSizeString , DEFAULT RESULTS SIZE ) ;', 'if ( batch . size ( ) > = batchSize ) {', 'if ( sv = = null ) {', 'CoreAdminRequest . unloadCore ( mapping . getCoreName ( ) , adminServer ) ;', 'if ( !persistent . isDirty ( ) ) {', 'if ( fields = = null ) {', 'LOG . error ( e . getMessage ( ) ) ;', 'package org . apache . gora . solr . store ;', 'fieldValue = serializeFieldValue ( unionSchema , fieldValue ) ;', 'String commitWithinString = DataStoreFactory . findProperty ( properties , this ,', 'params . set ( CommonParams . FL , toDelimitedString ( fields , "" , "" ) ) ;', 'solrSchema = DataStoreFactory . findProperty ( properties , this ,', 'import org . apache . gora . store . impl . DataStoreBase ;', 'import org . apache . gora . util . AvroUtils ;', 'if ( resultsSizeString ! = null ) {', 'import java . net . MalformedURLException ;', 'import org . apache . solr . client . solrj . SolrServerException ;', 'continue ;', 'DEFAULT MAPPING FILE ) ;', 'Type schemaType = currentSchema . getType ( ) ;', 'serverPassword = DataStoreFactory . findProperty ( properties , this ,', 'return reader ;', 'if ( type0 . equals ( Schema . Type . NULL ) )', 'import org . apache . avro . Schema ;', 'server . commit ( ) ;', 'String resultsSizeString = DataStoreFactory . findProperty ( properties , this ,', 'Object fieldValue = null ;', '& & classElement . getAttributeValue ( ""name"" ) . equals (', 'private SolrClient server , adminServer ;', 'import org . apache . solr . client . solrj . impl . HttpClientUtil ;', 'import org . apache . gora . solr . query . SolrQuery ;', 'int schemaPos = getUnionSchema ( fieldValue , fieldSchema ) ;', 'SOLR SERVER USER AUTH , ""false"" ) ;', 'if ( !type0 . equals ( type1 ) ) {', 'private String serverPassword ;', 'Element primaryKeyEl = classElement . getChild ( ""primarykey"" ) ;', '. getResourceAsStream ( filename ) ) ;', 'switch ( fieldSchema . getType ( ) ) {', 'return sb . toString ( ) ;', 'if ( !schemaExists ( ) )', '+ ""match with intended values . A mapping mismatch has been found therefore ""', 'fieldSchema = fieldSchema . getTypes ( ) . get ( 0 ) ;', '} else if ( solrJServerType . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""cloud"" ) ) {', 'public static final ConcurrentHashMap < Schema , SpecificDatumReader < ? > > readerMap = new ConcurrentHashMap < > ( ) ;', 'return DEFAULT UNION SCHEMA ;', 'import org . apache . solr . client . solrj . response . QueryResponse ;', 'LOG . info ( ""Using CloudSolrClient Solrj implementation . "" ) ;', 'if ( pk . equals ( f ) ) {', 'UpdateResponse rsp = server . deleteByQuery ( keyField + "" : ""', 'super . initialize ( keyClass , persistentClass , properties ) ;', 'private static final String toDelimitedString ( String [ ] arr , String sep ) {', 'public String getSchemaName ( ) {', 'StringBuilder sb = new StringBuilder ( ) ;', 'SOLR URL PROPERTY , null ) ;', 'SpecificDatumWriter writer = writerMap . get ( fieldSchema ) ;', 'public boolean delete ( K key ) {', 'serverUsername = DataStoreFactory . findProperty ( properties , this ,', 'if ( sf = = null ) {', 'LOG . warn ( ""Check that \'keyClass\' and \'name\' parameters in gora - solr - mapping . xml ""', 'public Query < K , T > newQuery ( ) {', 'SOLR RESULTS SIZE PROPERTY , null ) ;', 'if ( commitWithin = = 0 ) {', '} catch ( NumberFormatException nfe ) {', 'String keyField = mapping . getPrimaryKey ( ) ;', 'sb . append ( arr [ i ] ) ;', 'this . server = new HttpSolrClient ( SolrClientUrl + "" / "" + mapping . getCoreName ( ) ) ;', 'persistentClass . getCanonicalName ( ) ) ) {', 'if ( reader = = null ) {', 'createSchema ( ) ;', 'Object v = deserializeFieldValue ( field , fieldSchema , sv , persistent ) ;', 'batch = new ArrayList < > ( batchSize ) ;', 'import org . apache . solr . client . solrj . impl . LBHttpSolrClient ;', 'fieldValue = ByteBuffer . wrap ( ( byte [ ] ) solrValue ) ;', 'if ( batchSizeString ! = null ) {', 'public boolean schemaExists ( ) {', 'private void add ( ArrayList < SolrInputDocument > batch , int commitWithin )', '( DefaultHttpClient ) ( ( LBHttpSolrClient ) server ) . getHttpClient ( ) ,', 'public SolrMapping getMapping ( ) {', 'if ( arr = = null | | arr . length = = 0 ) {', 'private boolean serverUserAuth ;', 'protected static final int DEFAULT COMMIT WITHIN = 1000 ;', 'SOLR SOLRJSERVER IMPL , ""http"" ) ;', 'for ( Field field : fields ) {', 'Object sv = doc . get ( sf ) ;', '} else if ( solrJServerType . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""concurrent"" ) ) {', 'mapping . getCoreName ( ) , adminServer , solrConfig , solrSchema ) ;', 'serilazeData = IOUtils . serialize ( writer , fieldValue ) ;', 'return ;', 'fieldValue = AvroUtils . getEnumValue ( fieldSchema , ( String ) solrValue ) ;', 'throw new RuntimeException ( e ) ;', '+ ""no mapping has been initialized for class mapping at position ""', 'return mapping ;', 'LOG . info ( ""Putting DOCUMENT : "" + doc ) ;', 'sf = mapping . getSolrField ( f ) ;', 'protected static final String DEFAULT MAPPING FILE = ""gora - solr - mapping . xml"" ;', 'Object v = persistent . get ( field . pos ( ) ) ;', 'map . setCoreName ( tableName ) ;', 'if ( v = = null ) {', 'HttpClientUtil . setBasicAuth (', 'server . add ( batch ) ;', 'serverUserAuth = DataStoreFactory . findBooleanProperty ( properties , this ,', 'import org . slf4j . Logger ;', 'if ( innerSchema . getType ( ) . equals ( Schema . Type . NULL ) ) {', 'case FIXED :', 'this . server = new LBHttpSolrClient ( solrUrlElements + "" / "" + mapping . getCoreName ( ) ) ;', 'return persistent ;', '} catch ( IOException e ) {', 'return map ;', 'private int commitWithin = DEFAULT COMMIT WITHIN ;', 'case ARRAY :', 'data = IOUtils . serialize ( writer , fieldValue ) ;', 'for ( int i = 0 ; i < arr . length ; i + + ) {', 'import org . apache . gora . query . PartitionQuery ;', 'import org . apache . solr . client . solrj . SolrClient ;', 'SpecificDatumWriter writer = getDatumWriter ( fieldSchema ) ;', '+ "" { } in mapping file . "" , classes . indexOf ( classElement ) ) ;', 'import org . apache . avro . specific . SpecificDatumWriter ;', 'map . addField ( fieldName , columnName ) ;', 'public void flush ( ) {', 'LOG . info ( ""Using LBHttpSolrClient Solrj implementation . "" ) ;', 'private String serverUsername ;', 'import org . apache . avro . util . Utf8 ;', '} else {', 'for ( Schema currentSchema : pUnionSchema . getTypes ( ) ) {', 'this . adminServer = new LBHttpSolrClient ( solrUrlElements ) ;', 'this . adminServer = new CloudSolrClient ( SolrClientUrl ) ;', 'return fieldValue ;', 'protected static final int DEFAULT RESULTS SIZE = 100 ;', 'private Object serializeFieldValue ( Schema fieldSchema , Object fieldValue ) {', 'throw new IOException ( "" ? ? ? "" ) ;', 'if ( solrJServerType . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""http"" ) ) {', 'import java . util . concurrent . ConcurrentHashMap ;', 'private SolrMapping mapping ;', 'batch . clear ( ) ;', 'SAXBuilder builder = new SAXBuilder ( ) ;', 'import org . apache . gora . persistency . Persistent ;', 'public void initialize ( Class < K > keyClass , Class < T > persistentClass ,', 'import java . nio . ByteBuffer ;', 'public long deleteByQuery ( Query < K , T > query ) {', 'commitWithin = Integer . parseInt ( commitWithinString ) ;', 'private SpecificDatumReader getDatumReader ( Schema fieldSchema ) {', 'UpdateResponse rsp = server . deleteByQuery ( q ) ;', 'fieldValue = IOUtils . deserialize ( ( byte [ ] ) solrValue , unionReader ,', 'String [ ] solrUrlElements = StringUtils . split ( SolrClientUrl ) ;', 'import org . apache . gora . persistency . impl . PersistentBase ;', 'return """" ;', 'import org . apache . solr . client . solrj . request . CoreAdminRequest ;', 'fieldValue = new Utf8 ( solrValue . toString ( ) ) ;', 'keyClass . getCanonicalName ( ) )', 'import org . jdom . Document ;', 'server . add ( batch , commitWithin ) ;', 'if ( pValue instanceof Utf8 & & schemaType . equals ( Type . STRING ) )', '( DefaultHttpClient ) ( ( HttpSolrClient ) adminServer ) . getHttpClient ( ) ,', 'private SolrMapping readMapping ( String filename ) throws IOException {', 'for ( Schema innerSchema : unionSchema . getTypes ( ) ) {', 'String fieldName = field . getAttributeValue ( ""name"" ) ;', 'if ( commitWithinString ! = null ) {', 'persistent . clearDirty ( ) ;', 'throws SolrServerException , IOException {', 'sb . append ( sep ) ;', 'boolean exists = false ;', 'server . deleteByQuery ( "" * : * "" ) ;', 'import org . apache . http . impl . client . DefaultHttpClient ;', 'return writer ;', 'partitions . add ( pqi ) ;', 'else if ( pValue instanceof List & & schemaType . equals ( Type . ARRAY ) )', 'ModifiableSolrParams params = new ModifiableSolrParams ( ) ;', 'for ( int i = 0 ; i < key . length ( ) ; i + + ) {', 'else if ( pValue instanceof Double & & schemaType . equals ( Type . DOUBLE ) )', 'private static final Logger LOG = LoggerFactory . getLogger ( SolrStore . class ) ;', ""case ' : ' :"", 'else if ( pValue instanceof Float & & schemaType . equals ( Type . FLOAT ) )', 'SOLR COMMIT WITHIN PROPERTY , null ) ;', 'LOG . warn ( ""Invalid batch size \' { } \' , using default { } "" , batchSizeString , DEFAULT BATCH SIZE ) ;', 'throws IOException {', 'Type type1 = fieldSchema . getTypes ( ) . get ( 1 ) . getType ( ) ;', 'this . server = new ConcurrentUpdateSolrClient ( SolrClientUrl + "" / "" + mapping . getCoreName ( ) , 1000 , 10 ) ;', 'reader = localReader ;'}, 'removed_code': set()}"
dfc6dfa3ed711d08678fabf98fb70bdf1170820c,1.0,Made DatabaseConfiguration compatible with the builder approach . There are now set methods for the properties defining the database structures the configuration operates on . The values of these properties can also be queried which was requested by [ CONFIGURATION - 535 ] .,"{'added_code': {'if ( nameCol & & configurationNameColumn ! = null )', 'public void setConfigurationNameColumn ( String configurationNameColumn )', 'return table ;', 'public String getConfigurationNameColumn ( )', 'public String getTable ( )', 'addErrorLogListener ( ) ;', '}', 'public String getValueColumn ( )', 'if ( configurationNameColumn ! = null )', 'public DatabaseConfiguration ( )', 'public String getConfigurationName ( )', 'private String table ;', 'ps . setString ( idx , configurationName ) ;', 'return valueColumn ;', 'return dataSource ;', 'this . autoCommit = autoCommit ;', 'public void setAutoCommit ( boolean autoCommit )', 'public boolean isAutoCommit ( )', 'public void setValueColumn ( String valueColumn )', 'this . dataSource = dataSource ;', 'return configurationNameColumn ;', 'setLogger ( LogFactory . getLog ( getClass ( ) ) ) ;', 'public void setTable ( String table )', 'private boolean autoCommit ;', 'private String valueColumn ;', 'protected void close ( Connection conn , Statement stmt , ResultSet rs )', 'buf . append ( "" AND "" ) . append ( configurationNameColumn ) . append ( "" = ? "" ) ;', 'private DataSource dataSource ;', 'return keyColumn ;', 'private String configurationNameColumn ;', 'public DataSource getDataSource ( )', 'this . configurationNameColumn = configurationNameColumn ;', 'this . configurationName = configurationName ;', 'private String configurationName ;', 'return configurationName ;', 'return autoCommit ;', 'public void setKeyColumn ( String keyColumn )', '{', 'public String getKeyColumn ( )', 'public void setConfigurationName ( String configurationName )', 'private String keyColumn ;', 'query . append ( "" , "" ) . append ( configurationNameColumn ) ;', 'public void setDataSource ( DataSource dataSource )', 'if ( isAutoCommit ( ) )', 'pstmt . setString ( 3 , configurationName ) ;'}, 'removed_code': {'query . append ( "" , "" ) . append ( nameColumn ) ;', 'private final boolean doCommits ;', 'private final String keyColumn ;', 'private void close ( Connection conn , Statement stmt , ResultSet rs )', 'String nameColumn , String keyColumn , String valueColumn ,', 'addErrorLogListener ( ) ;', 'private final String name ;', 'this ( datasource , table , null , keyColumn , valueColumn , null , commits ) ;', 'this . name = name ;', 'ps . setString ( idx , name ) ;', 'String keyColumn , String valueColumn , boolean commits )', 'doCommits = commits ;', 'private final DataSource datasource ;', 'this ( datasource , table , nameColumn , keyColumn , valueColumn , name , false ) ;', 'public boolean isDoCommits ( )', 'if ( isDoCommits ( ) )', 'setLogger ( LogFactory . getLog ( getClass ( ) ) ) ;', 'private final String nameColumn ;', 'return datasource ;', 'public DatabaseConfiguration ( DataSource datasource , String table ,', 'private final String valueColumn ;', 'String name , boolean commits )', 'public DatabaseConfiguration ( DataSource datasource , String table , String nameColumn ,', 'public DatabaseConfiguration ( DataSource datasource , String table , String keyColumn , String valueColumn )', 'String keyColumn , String valueColumn , String name )', 'pstmt . setString ( 3 , name ) ;', 'this ( datasource , table , null , keyColumn , valueColumn , null ) ;', 'buf . append ( "" AND "" ) . append ( nameColumn ) . append ( "" = ? "" ) ;', 'private final String table ;', 'this . nameColumn = nameColumn ;', 'return doCommits ;', 'if ( nameColumn ! = null )', 'if ( nameCol & & nameColumn ! = null )', 'this . datasource = datasource ;'}}"
2280cbd563332a1b9f3ada9de77af40efc6c97b0,1.0,Partial fix for DBCP - 404 Make mutable fields private,"{'added_code': {'private volatile String password = null ;', 'private boolean testOnBorrow = true ;', 'private PrintWriter logWriter = new PrintWriter ( new OutputStreamWriter (', 'private int maxTotal = GenericObjectPoolConfig . DEFAULT MAX TOTAL ;', 'private volatile boolean defaultAutoCommit = true ;', '}', 'protected DataSource createDataSourceInstance ( ) throws SQLException {', 'private ClassLoader driverClassLoader = null ;', 'private volatile int defaultTransactionIsolation =', 'private volatile String defaultCatalog = null ;', 'private Properties connectionProperties = new Properties ( ) ;', 'private int maxIdle = GenericObjectPoolConfig . DEFAULT MAX IDLE ;', 'private String driverClassName = null ;', 'public List < String > getConnectionInitSqls ( ) {', 'List < String > result = connectionInitSqls ;', 'private boolean testOnReturn = false ;', 'Properties getConnectionProperties ( ) {', 'private volatile GenericObjectPool < PoolableConnection > connectionPool = null ;', 'return connectionProperties ;', 'return pds ;', 'private String url = null ;', 'private transient Boolean defaultReadOnly = null ;', 'dataSource = createDataSourceInstance ( ) ;', 'private volatile int validationQueryTimeout = - 1 ;', 'protected GenericObjectPool < PoolableConnection > getConnectionPool ( ) {', 'private int numTestsPerEvictionRun =', 'private volatile List < String > connectionInitSqls ;', 'return defaultReadOnly ;', 'private boolean closed ;', 'private String username = null ;', 'private int initialSize = 0 ;', 'private long maxWaitMillis =', 'private long minEvictableIdleTimeMillis =', 'private long timeBetweenEvictionRunsMillis =', 'private volatile String validationQuery = null ;', 'private int minIdle = GenericObjectPoolConfig . DEFAULT MIN IDLE ;', 'return connectionPool ;', 'private boolean testWhileIdle = false ;', 'protected Boolean getDefaultReadOnlyBoolean ( ) {', 'private volatile DataSource dataSource = null ;'}, 'removed_code': {'protected volatile String password = null ;', 'protected int maxIdle = GenericObjectPoolConfig . DEFAULT MAX IDLE ;', 'protected volatile DataSource dataSource = null ;', 'protected boolean testOnReturn = false ;', 'protected long timeBetweenEvictionRunsMillis =', 'protected int minIdle = GenericObjectPoolConfig . DEFAULT MIN IDLE ;', 'protected int initialSize = 0 ;', 'protected ClassLoader driverClassLoader = null ;', 'protected long minEvictableIdleTimeMillis =', 'protected Properties connectionProperties = new Properties ( ) ;', 'protected boolean closed ;', 'protected void createDataSourceInstance ( ) throws SQLException {', 'dataSource = pds ;', 'protected volatile String defaultCatalog = null ;', 'Collection < String > result = connectionInitSqls ;', 'protected volatile GenericObjectPool < PoolableConnection > connectionPool = null ;', 'protected volatile int validationQueryTimeout = - 1 ;', 'createDataSourceInstance ( ) ;', 'protected volatile List < String > connectionInitSqls ;', 'protected String url = null ;', 'protected boolean testOnBorrow = true ;', 'protected int maxTotal = GenericObjectPoolConfig . DEFAULT MAX TOTAL ;', 'protected volatile boolean defaultAutoCommit = true ;', 'protected transient Boolean defaultReadOnly = null ;', 'protected PrintWriter logWriter = new PrintWriter ( new OutputStreamWriter (', 'protected String driverClassName = null ;', 'protected boolean testWhileIdle = false ;', 'protected long maxWaitMillis =', 'protected volatile String validationQuery = null ;', 'protected String username = null ;', 'public Collection < String > getConnectionInitSqls ( ) {', 'protected volatile int defaultTransactionIsolation =', 'protected int numTestsPerEvictionRun ='}}"
f36294048060163b60cb5e4cf8a7bc09667353e0,1.0,IVY - 309 refactor all those split - trim - join and unwrap some logic,"{'added_code': {'for ( String tok : splitToArray ( extend ) ) {', '""Cannot exclude a configuration which is extended . "" ) ;', '@ Deprecated', 'for ( int i = 0 ; i < parts . length ; i + + ) {', '}', 'if ( ! ( objs [ i ] instanceof String ) ) {', 'return joinArray ( ( String [ ] ) objs , sep ) ;', 'if ( isNullOrEmpty ( value ) ) {', 'String [ ] parts = list . split ( "" , "" ) ;', 'return parts ;', 'public static String join ( Object [ ] objs , String sep ) {', 'throw new IllegalArgumentException ( errorMessage ) ;', 'objs [ i ] = objs [ i ] . toString ( ) ;', 'newList . append ( sep ) . append ( current ) ;', 'for ( String obj : objs ) {', 'for ( String current : splitToArray ( list ) ) {', 'for ( String lh : splitToArray ( ops [ 0 ] ) ) {', 'newMapping . append ( "" - > "" ) . append ( joinArray ( splitToArray ( ops [ 1 ] ) , sep ) ) ;', 'import static org . apache . ivy . util . StringUtils . isNullOrEmpty ;', 'if ( list = = null ) {', 'throw new IllegalArgumentException (', 'String sep = """" ;', 'public static void assertNotNullNotEmpty ( final String value , final String errorMessage ) {', 'String listSep = groups . contains ( "" "" ) ? "" , "" : "" , "" ;', 'for ( String groups : mapping . split ( "" ; "" ) ) {', 'buffer . setDefaultPrint ( isNullOrEmpty ( attributes . getValue ( ""conf"" ) ) ) ;', 'if ( !isNullOrEmpty ( newBranch ) ) {', 'if ( !confs . contains ( lh ) ) {', 'public static String joinArray ( String [ ] objs , String sep ) {', 'String result = ( ivy = = null ) ? value : ivy . substitute ( value ) ;', 'for ( int i = 0 ; i < objs . length ; i + + ) {', 'import static org . apache . ivy . util . StringUtils . splitToArray ;', 'assertNotNullNorEmpty ( value , errorMessage ) ;', 'if ( !confsToRemove . contains ( current ) ) {', 'public static boolean isNullOrEmpty ( String s ) {', 'if ( org = = null ) {', 'return joinArray ( context . toArray ( new String [ context . size ( ) ] ) , "" / "" ) ;', 'return s = = null | | s . trim ( ) . isEmpty ( ) ;', 'String listSep = list . contains ( "" "" ) ? "" , "" : "" , "" ;', 'return null ;', 'import static org . apache . ivy . util . StringUtils . joinArray ;', 'public static void assertNotNullNorEmpty ( final String value , final String errorMessage ) {', 'sep = listSep ;', 'parts [ i ] = parts [ i ] . trim ( ) ;', 'if ( confs . contains ( tok ) ) {', 'org = organisation ;', 'public static String [ ] splitToArray ( String list ) {', 'write ( "" branch = \\ """" + newBranch + "" \\ """" ) ;', 'String [ ] ops = groups . split ( "" - > "" ) ;'}, 'removed_code': {'if ( !newBranch . trim ( ) . equals ( """" ) ) {', 'while ( tokenizer . hasMoreTokens ( ) ) {', 'String listSep = """" ;', 'if ( confs . contains ( tok . nextToken ( ) ) ) {', 'import java . util . StringTokenizer ;', 'StringTokenizer tokenizer = new StringTokenizer ( list , "" , "" ) ;', 'newMapping . append ( "" - > "" ) . append ( ops [ 1 ] ) ;', 'for ( String lh : ops [ 0 ] . split ( "" , "" ) ) {', '}', 'if ( buf . length ( ) > 0 ) {', 'buf . setLength ( buf . length ( ) - 1 ) ;', 'StringTokenizer tok = new StringTokenizer ( extend , "" , "" ) ;', 'buffer . setDefaultPrint ( attributes . getValue ( ""conf"" ) = = null', 'String [ ] ops = tokenizer . nextToken ( ) . split ( "" - > "" ) ;', 'listSep = "" , "" ;', 'if ( newBranch ! = null ) {', 'String current = tokenizer . nextToken ( ) ;', 'sep = "" , "" ;', 'public static String join ( Object [ ] objs , String sep ) {', 'throw new IllegalArgumentException ( errorMessage ) ;', 'org = org = = null ? organisation : org ;', '+ ""configuration which is extended . "" ) ;', 'return buf . toString ( ) ;', 'for ( Object obj : objs ) {', 'public static void assertNotNullNotEmpty ( final String value , final String errorMessage ) {', 'StringBuilder buf = new StringBuilder ( ) ;', 'throw new IllegalArgumentException ( ""Cannot exclude a ""', 'newList . append ( listSep ) . append ( current ) ;', 'if ( value = = null | | value . trim ( ) . isEmpty ( ) ) {', 'for ( String ctx : context ) {', 'String result = ivy = = null ? value : ivy . substitute ( value ) ;', 'if ( !confsToRemove . contains ( current . trim ( ) ) ) {', 'if ( !confs . contains ( lh . trim ( ) ) ) {', 'while ( tok . hasMoreTokens ( ) ) {', '| | attributes . getValue ( ""conf"" ) . trim ( ) . length ( ) = = 0 ) ;', 'StringTokenizer tokenizer = new StringTokenizer ( mapping , "" ; "" ) ;', 'buf . append ( ctx ) . append ( "" / "" ) ;', 'write ( "" branch = \\ """" + newBranch + "" \\ """" ) ;'}}"
6ffdfbb8c97d7f70e5cb57be566f1c90e35e03ba,1.0,OPENNLP - 946 : GISTrainer should extend AbstractEventTrainer This closes #104,"{'added_code': {'indexingParameters . put ( GISTrainer . CUTOFF PARAM , Integer . toString ( cutoff ) ) ;', 'int threads = trainingParameters . getIntParameter ( TrainingParameters . THREADS PARAM , 1 ) ;', '}', 'AbstractModel model ;', 'protected void display ( String s ) {', 'private static final double SMOOTHING OBSERVATION = 0 . 1 ;', 'indexingParameters . put ( GISTrainer . ITERATIONS PARAM , Integer . toString ( iterations ) ) ;', 'return trainModel ( iterations , di , new UniformPrior ( ) , threads ) ;', 'this . setSmoothing ( smoothing ) ;', 'return trainModel ( eventStream , 100 , 0 ) ;', 'public class GISTrainer extends AbstractEventTrainer {', 'import opennlp . tools . ml . model . MaxentModel ;', 'public GISModel trainModel ( int iterations , DataIndexer di , int threads ) {', 'import opennlp . tools . ml . AbstractEventTrainer ;', 'public MaxentModel doTrain ( DataIndexer indexer ) throws IOException {', 'boolean smoothing = trainingParameters . getBooleanParameter ( SMOOTHING PARAM , SMOOTHING DEFAULT ) ;', 'private static final boolean SMOOTHING DEFAULT = false ;', '@ Override', 'return model ;', 'public static final String MAXENT VALUE = ""MAXENT"" ;', 'public boolean isSortAndMerge ( ) {', 'int iterations = getIterations ( ) ;', 'public GISTrainer ( ) {', 'private static final String SMOOTHING PARAM = ""smoothing"" ;', 'return true ;', 'model = trainModel ( iterations , indexer , threads ) ;', 'public GISModel trainModel ( ObjectStream < Event > eventStream ) throws IOException {', 'import opennlp . tools . ml . model . AbstractModel ;'}, 'removed_code': {'indexingParameters . put ( GIS . CUTOFF PARAM , Integer . toString ( cutoff ) ) ;', 'public class GISTrainer {', 'indexingParameters . put ( GIS . ITERATIONS PARAM , Integer . toString ( iterations ) ) ;', 'GISTrainer ( ) {', 'private void display ( String s ) {'}}"
372c35ebccedf64266a38a35e365d3810642fef2,1.0,GIRAPH - 842 : option to dump histogram of memory usage when heap is low on memory ( pavanka ),"{'added_code': {'import org . apache . giraph . worker . WorkerObserver ;', 'joinSupervisorThread ( ) ;', 'import org . apache . giraph . conf . ImmutableClassesGiraphConfiguration ;', 'thread . setName ( ""ReactiveJMapHistoDumperSupervisorThread"" ) ;', '}', 'MasterObserver , WorkerObserver {', 'public void preSuperstep ( long superstep ) { }', 'if ( potentialMemory / MB < minFreeMemory ) {', 'private Thread thread ;', 'long potentialMemory = ( runtime . maxMemory ( ) -', 'sleepMillis = GiraphConstants . JMAP SLEEP MILLIS . get ( configuration ) ;', 'startSupervisorThread ( ) ;', 'Thread . sleep ( sleepMillis ) ;', 'private int minFreeMemory ;', 'public void preApplication ( ) {', '} catch ( InterruptedException e ) {', 'JMap . heapHistogramDump ( linesToPrint ) ;', 'private static final Logger LOG = Logger . getLogger (', 'public void run ( ) {', 'thread = new Thread ( new Runnable ( ) {', 'public class ReactiveJMapHistoDumper extends', 'public void setConf ( ImmutableClassesGiraphConfiguration configuration ) {', 'thread . start ( ) ;', 'LOG . error ( ""Failed to join jmap thread"" ) ;', 'thread . join ( sleepMillis + 5000 ) ;', 'import org . apache . giraph . conf . GiraphConstants ;', 'stop = true ;', 'public void applicationFailed ( Exception e ) { }', 'minFreeMemory = GiraphConstants . MIN FREE MBS ON HEAP . get ( configuration ) ;', 'private static final int MB = 1024 * 1024 ;', 'public void postApplication ( ) {', 'linesToPrint = GiraphConstants . JMAP PRINT LINES . get ( configuration ) ;', 'stop = false ;', 'while ( !stop ) {', 'public void postSuperstep ( long superstep ) { }', 'private volatile boolean stop = false ;', 'try {', 'import org . apache . giraph . conf . DefaultImmutableClassesGiraphConfigurable ;', 'DefaultImmutableClassesGiraphConfigurable implements', 'package org . apache . giraph . utils ;', 'private int sleepMillis ;', '@ Override', 'public void startSupervisorThread ( ) {', '} ) ;', 'final Runtime runtime = Runtime . getRuntime ( ) ;', 'ReactiveJMapHistoDumper . class ) ;', 'import org . apache . giraph . master . MasterObserver ;', 'runtime . totalMemory ( ) ) + runtime . freeMemory ( ) ;', 'import org . apache . log4j . Logger ;', 'private void joinSupervisorThread ( ) {', 'LOG . warn ( ""JMap histogram sleep interrupted"" , e ) ;', 'private int linesToPrint ;'}, 'removed_code': set()}"
294b73583fc0dcd548ae95a841829f9ad2ab3ed0,1.0,Rest of GIRAPH - 701 .,"{'added_code': {'CentralizedServiceWorker < I , ? , ? > serviceWorker =', 'public SendWorkerOneToAllMessagesRequest ( ) { }', 'idMsgs . add ( vertexId , msg ) ;', 'int idCount = 0 ;', 'Int2ObjectOpenHashMap < ByteArrayVertexIdMessages >', 'import org . apache . giraph . utils . ExtendedDataInput ;', 'idMsgs . getKey ( ) , idMsgs . getValue ( ) ) ;', 'import java . io . IOException ;', 'implements WorkerRequest < I , Writable , Writable > {', 'package org . apache . giraph . comm . requests ;', 'PartitionOwner owner =', 'int initialSize = oneToAllMsgs . getSize ( ) /', 'if ( !idMsgs . getValue ( ) . isEmpty ( ) ) {', 'import java . io . DataInput ;', 'for ( int i = 0 ; i < idCount ; i + + ) {', 'ExtendedDataInput reader = oneToAllMsgs . getOneToAllMessagesReader ( ) ;', 'new Int2ObjectOpenHashMap < ByteArrayVertexIdMessages > ( ) ;', 'ByteArrayOneToAllMessages < I , M > oneToAllMsgs ,', 'partitionIdMsgs . entrySet ( ) ) {', 'serviceWorker . getVertexPartitionOwner ( vertexId ) ;', 'import java . io . DataOutput ;', '@ SuppressWarnings ( ""unchecked"" )', 'import org . apache . hadoop . io . Writable ;', 'partitionIdMsgs . get ( partitionId ) ;', 'if ( idMsgs = = null ) {', '} catch ( IOException e ) {', 'throw new RuntimeException ( ""doRequest : Got IOException "" , e ) ;', 'this . oneToAllMsgs . write ( output ) ;', 'for ( Entry < Integer , ByteArrayVertexIdMessages > idMsgs :', 'public int getSerializedSize ( ) {', 'getConf ( ) . < M > getOutgoingMessageValueFactory ( ) ) ;', 'import org . apache . giraph . utils . ByteArrayOneToAllMessages ;', 'import it . unimi . dsi . fastutil . ints . Int2ObjectOpenHashMap ;', 'partitionIdMsgs . put ( partitionId , idMsgs ) ;', 'ByteArrayVertexIdMessages < I , M > idMsgs =', 'public class SendWorkerOneToAllMessagesRequest < I extends WritableComparable ,', 'oneToAllMsgs . setConf ( getConf ( ) ) ;', 'import org . apache . giraph . conf . ImmutableClassesGiraphConfiguration ;', 'serverData . getPartitionStore ( ) . getNumPartitions ( ) * 2 ;', 'serverData . getIncomingMessageStore ( ) . addPartitionMessages (', 'public RequestType getType ( ) {', 'setConf ( conf ) ;', 'throw new RuntimeException ( ""doRequest : Got IOException . "" , e ) ;', 'M msg = oneToAllMsgs . createMessage ( ) ;', 'return super . getSerializedSize ( ) + this . oneToAllMsgs . getSerializedSize ( ) ;', 'idCount = reader . readInt ( ) ;', 'import org . apache . giraph . partition . PartitionOwner ;', 'serverData . getServiceWorker ( ) ;', 'public SendWorkerOneToAllMessagesRequest (', 'try {', '@ Override', 'public void doRequest ( ServerData serverData ) {', 'this . oneToAllMsgs = oneToAllMsgs ;', 'return RequestType . SEND WORKER ONETOALL MESSAGES REQUEST ;', 'idMsgs = new ByteArrayVertexIdMessages < I , M > (', 'oneToAllMsgs = new ByteArrayOneToAllMessages < I , M > (', 'partitionIdMsgs =', 'partitionId = owner . getPartitionId ( ) ;', 'import org . apache . hadoop . io . WritableComparable ;', 'idMsgs . initialize ( initialSize ) ;', 'M extends Writable > extends WritableRequest < I , Writable , Writable >', 'ImmutableClassesGiraphConfiguration conf ) {', 'vertexId . readFields ( reader ) ;', '}', 'while ( reader . available ( ) ! = 0 ) {', 'import org . apache . giraph . utils . ByteArrayVertexIdMessages ;', 'private ByteArrayOneToAllMessages < I , M > oneToAllMsgs ;', 'import java . util . Map . Entry ;', 'int partitionId = 0 ;', 'msg . readFields ( reader ) ;', 'oneToAllMsgs . readFields ( input ) ;', 'public void readFieldsRequest ( DataInput input ) throws IOException {', 'idMsgs . setConf ( getConf ( ) ) ;', 'I vertexId = getConf ( ) . createVertexId ( ) ;', 'import org . apache . giraph . bsp . CentralizedServiceWorker ;', 'import org . apache . giraph . comm . ServerData ;', 'public void writeRequest ( DataOutput output ) throws IOException {'}, 'removed_code': set()}"
3b81f3a94da9e26ec0458f4b5bd3a0469d8a93f7,1.0,COMPRESS - 271 add LZ4 frame to CompressorStreamFactory,"{'added_code': {'if ( LZ4 FRAMED . equalsIgnoreCase ( name ) ) {', 'if ( FramedLZ4CompressorInputStream . matches ( signature , signatureLength ) ) {', 'return new FramedLZ4CompressorInputStream ( in ) ;', 'import org . apache . commons . compress . compressors . lz4 . FramedLZ4CompressorInputStream ;', 'return Sets . newHashSet ( GZIP , BZIP2 , XZ , LZMA , PACK200 , DEFLATE , SNAPPY RAW , SNAPPY FRAMED , Z , LZ4 BLOCK ,', 'return LZ4 BLOCK ;', '}', 'LZ4 FRAMED ) ;', 'return LZ4 FRAMED ;', 'public static final String LZ4 FRAMED = ""lz4 - framed"" ;', 'public static String getLZ4Block ( ) {', 'public static String getLZ4Framed ( ) {', 'return Sets . newHashSet ( GZIP , BZIP2 , XZ , LZMA , PACK200 , DEFLATE , SNAPPY RAW , SNAPPY FRAMED , LZ4 BLOCK ) ;'}, 'removed_code': {'return Sets . newHashSet ( GZIP , BZIP2 , XZ , LZMA , PACK200 , SNAPPY RAW , SNAPPY FRAMED , Z , DEFLATE , LZ4 BLOCK ) ;', 'return Sets . newHashSet ( GZIP , BZIP2 , XZ , LZMA , PACK200 , DEFLATE , SNAPPY FRAMED , LZ4 BLOCK ) ;'}}"
80ed7676093c6ee19c271fd9414d360b6a8d1712,1.0,BCEL - 195 addition of hashCode ( ) to generic / Instruction . java breaks Targeters . Never make distinct BranchInstructions compare equal,"{'added_code': {'if ( i1 = = i2 ) {', 'return true ;', '}', 'if ( i1 instanceof BranchInstruction ) {', 'return false ;'}, 'removed_code': {'if ( t1 . length = = t2 . length ) {', 'return ( ( BranchInstruction ) i1 ) . getTarget ( ) = = ( ( BranchInstruction ) i2 ) . getTarget ( ) ;', 'InstructionHandle [ ] t1 = ( ( Select ) i1 ) . getTargets ( ) ;', 'if ( t1 [ i ] ! = t2 [ i ] ) {', 'InstructionHandle [ ] t2 = ( ( Select ) i2 ) . getTargets ( ) ;', '} else if ( i1 instanceof BranchInstruction ) {', 'return true ;', '}', 'return false ;', 'if ( i1 instanceof Select ) {', 'for ( int i = 0 ; i < t1 . length ; i + + ) {'}}"
8d340a008767c5d954b7539e825b4c90eb15ab9b,1.0,FIX : Fixed name snapshots are not updated even if they are marked as changing and the publication date is changed in repo ( IVY - 938 ),"{'added_code': {'long repoLastModified = mdRef . getLastModified ( ) ;', '} else {', '}', 'Artifact originalMetadataArtifact = getOriginalMetadataArtifact ( moduleArtifact ) ;', 'if ( rmr ! = null ) {', 'Artifact transformedArtifact = NameSpaceHelper . transform (', 'long cacheLastModified = rmr . getDescriptor ( ) . getLastModified ( ) ;', 'File artFile = getArchiveFileInCache ( transformedArtifact , origin , false ) ;', 'if ( !moduleArtifact . isMetadata ( ) ) {', 'Message . error ( ""Couldn\'t delete outdated artifact from cache : "" + artFile ) ;', 'rmr . getDescriptor ( ) . getResolvedPublicationDate ( ) ;', '+ "" ) : but it\'s a default one , maybe we can find a better one"" ) ;', 'return rmr ;', 'if ( !isCheckmodified ( dd , mrid , options ) & & !isChanging ( dd , mrid , options ) ) {', 'removeSavedArtifactOrigin ( transformedArtifact ) ;', 'if ( isChanging ( dd , mrid , options ) ) {', '+ "" ( resolved by "" + rmr . getResolver ( ) . getName ( )', 'if ( rmr . getDescriptor ( ) . isDefault ( ) & & rmr . getResolver ( ) ! = resolver ) {', '+ mrid ) ;', 'try {', 'Message . verbose ( """" + getName ( ) + "" : revision in cache ( not updated ) : ""', 'ArtifactOrigin origin = getSavedArtifactOrigin ( transformedArtifact ) ;', 'if ( !artFile . delete ( ) ) {', 'cachedPublicationDate =', 'return null ;', 'if ( artFile . exists ( ) & & repoLastModified > artFile . lastModified ( ) ) {', 'ResolvedModuleRevision rmr = doFindModuleInCache ( mrid , options , null ) ;', 'rmr . getReport ( ) . setSearched ( true ) ;', 'Message . verbose ( """" + getName ( ) + "" : revision in cache is not up to date : ""', 'BackupResourceDownloader backupDownloader = new BackupResourceDownloader ( downloader ) ;', 'Message . debug ( ""deleting "" + artFile ) ;', '. getInstance ( ) . getParser ( mdRef . getResource ( ) ) ;', 'Message . verbose ( """" + getName ( ) + "" : found revision in cache : "" + mrid', 'ModuleDescriptorParser parser = ModuleDescriptorParserRegistry', 'Message . verbose ( """" + getName ( ) + "" : revision in cache : "" + mrid ) ;', 'Message . verbose ( mrid + "" has changed : deleting old artifacts"" ) ;', 'moduleArtifact , options . getNamespace ( ) . getToSystemTransformer ( ) ) ;', 'long repLastModified = mdRef . getLastModified ( ) ;', 'if ( !rmr . getDescriptor ( ) . isDefault ( ) & & repLastModified < = cacheLastModified ) {'}, 'removed_code': {'} else {', '}', 'Artifact originalMetadataArtifact = getOriginalMetadataArtifact ( moduleArtifact ) ;', 'if ( rmr ! = null ) {', 'long cacheLastModified = rmr . getDescriptor ( ) . getLastModified ( ) ;', 'return rmr ;', 'rmr . getDescriptor ( ) . getResolvedPublicationDate ( ) ;', '+ "" ) : but it\'s a default one , maybe we can find a better one"" ) ;', 'if ( !isCheckmodified ( dd , mrid , options ) & & !isChanging ( dd , mrid , options ) ) {', 'if ( isChanging ( dd , mrid , options ) ) {', '+ "" ( resolved by "" + rmr . getResolver ( ) . getName ( )', 'if ( rmr . getDescriptor ( ) . isDefault ( ) & & rmr . getResolver ( ) ! = resolver ) {', '+ mrid ) ;', 'try {', 'Message . verbose ( """" + getName ( ) + "" : revision in cache ( not updated ) : ""', 'cachedPublicationDate =', 'ResolvedModuleRevision rmr = doFindModuleInCache ( mrid , options , null ) ;', 'rmr . getReport ( ) . setSearched ( true ) ;', 'Message . verbose ( """" + getName ( ) + "" : revision in cache is not up to date : ""', 'BackupResourceDownloader backupDownloader = new BackupResourceDownloader ( downloader ) ;', '. getInstance ( ) . getParser ( mdRef . getResource ( ) ) ;', 'Message . verbose ( """" + getName ( ) + "" : found revision in cache : "" + mrid', 'ModuleDescriptorParser parser = ModuleDescriptorParserRegistry', 'Message . verbose ( """" + getName ( ) + "" : revision in cache : "" + mrid ) ;', 'long repLastModified = mdRef . getLastModified ( ) ;', 'if ( !rmr . getDescriptor ( ) . isDefault ( ) & & repLastModified < = cacheLastModified ) {'}}"
5b2806103d5e6d4a7a6df1ebc8d88005ad7731be,1.0,[ CODEC - 192 ] Add DaitchMokotoff Soundex .,"{'added_code': {'final Branch branch = new Branch ( ) ;', 'final boolean branchingRequired = replacements . length > 1 & & branching ;', 'if ( leftCharacter . length ( ) ! = 1 | | rightCharacter . length ( ) ! = 1 ) {', 'scanner . close ( ) ;', 'private final String pattern ;', 'if ( + + index < branches . length ) {', 'currentLine + + ;', 'this ( true ) ;', 'final String [ ] branches = soundex ( source , true ) ;', 'if ( source = = null ) {', 'import org . apache . commons . codec . EncoderException ;', 'cachedString = null ;', 'for ( final Map . Entry < Character , List < Rule > > rule : RULES . entrySet ( ) ) {', 'String line = rawLine ;', 'private final boolean folding ;', 'nextBranches . add ( nextBranch ) ;', ""final String [ ] replacements = rule . getReplacements ( inputContext , lastChar = = ' \\ 0' ) ;"", 'if ( cachedString = = null ) {', 'for ( int index = 0 ; index < input . length ( ) ; index + + ) {', 'import java . util . LinkedHashSet ;', 'if ( ! ( other instanceof Branch ) ) {', 'final Set < Branch > currentBranches = new LinkedHashSet < Branch > ( ) ;', 'if ( builder . length ( ) > MAX LENGTH ) {', 'public DaitchMokotoffSoundex ( ) {', 'import org . apache . commons . codec . CharEncoding ;', 'return false ;', 'final String leftCharacter = parts [ 0 ] ;', 'throw new IllegalArgumentException ( ""Malformed folding statement split into "" + parts . length +', '} catch ( final IllegalArgumentException e ) {', 'int index = 0 ;', '/ /', 'Arrays . asList ( replacementBeforeVowel ) , Arrays . asList ( replacementDefault ) ) ;', 'this . replacementDefault = replacementDefault . split ( "" \\ \\ | "" ) ;', 'while ( builder . length ( ) < MAX LENGTH ) {', 'rules . add ( r ) ;', 'import java . util . Map ;', 'parseRules ( scanner , RESOURCE FILE , RULES , FOLDINGS ) ;', 'branch . lastReplacement = this . lastReplacement ;', 'static {', 'return cachedString ;', 'if ( line . endsWith ( MULTILINE COMMENT END ) ) {', 'public boolean equals ( final Object other ) {', 'for ( final Rule rule : rules ) {', 'public int hashCode ( ) {', 'line = line . trim ( ) ;', 'private static final class Rule {', 'throw new EncoderException (', 'public String encode ( final String source ) {', 'return result ;', '@ SuppressWarnings ( ""unchecked"" )', 'nextBranch . processNextReplacement ( nextReplacement , force ) ;', 'final String replacement2 = stripQuotes ( parts [ 2 ] ) ;', 'lastReplacement = null ;', 'asciiFoldings . put ( leftCharacter . charAt ( 0 ) , rightCharacter . charAt ( 0 ) ) ;', 'private final String [ ] replacementBeforeVowel ;', 'ch = Character . toLowerCase ( ch ) ;', 'public int getPatternLength ( ) {', 'import java . util . Set ;', 'builder . delete ( MAX LENGTH , builder . length ( ) ) ;', 'final char patternKey = r . pattern . charAt ( 0 ) ;', 'private static final String DOUBLE QUOTE = "" \\ """" ;', 'while ( scanner . hasNextLine ( ) ) {', 'import java . util . Arrays ;', 'throw new IllegalStateException (', 'builder = new StringBuilder ( ) ;', 'this . replacementAtStart = replacementAtStart . split ( "" \\ \\ | "" ) ;', 'return pattern . length ( ) ;', 'continue ;', 'if ( parts . length ! = 2 ) {', 'private final String [ ] replacementAtStart ;', 'if ( line . length ( ) = = 0 ) {', 'final String rawLine = scanner . nextLine ( ) ;', 'if ( folding & & FOLDINGS . containsKey ( ch ) ) {', 'ruleMapping . put ( patternKey , rules ) ;', 'result [ index + + ] = branch . toString ( ) ;', 'final String pattern = stripQuotes ( parts [ 0 ] ) ;', 'private boolean isVowel ( final char ch ) {', ""return ch = = 'a' | | ch = = 'e' | | ch = = 'i' | | ch = = 'o' | | ch = = 'u' ;"", 'return replacementDefault ;', 'Collections . sort ( ruleList , new Comparator < Rule > ( ) {', 'sb . append ( ch ) ;', 'private final String [ ] replacementDefault ;', 'public void processNextReplacement ( final String replacement , final boolean forceAppend ) {', 'branch . finish ( ) ;', 'index + = rule . getPatternLength ( ) - 1 ;', 'import java . util . ArrayList ;', 'currentBranches . add ( new Branch ( ) ) ;', 'final String [ ] parts = line . split ( "" = "" ) ;', 'final Branch nextBranch = branchingRequired ? branch . createBranch ( ) : branch ;', 'final String replacement3 = stripQuotes ( parts [ 3 ] ) ;', 'private static final class Branch {', 'return encode ( ( String ) obj ) ;', 'private String cachedString ;', 'final List < Rule > rules = RULES . get ( ch ) ;', 'public String toString ( ) {', 'this . pattern = pattern ;', 'return toString ( ) . hashCode ( ) ;', 'throw new IllegalArgumentException ( ""Malformed folding statement - "" +', 'private static final String MULTILINE COMMENT START = "" / * "" ;', 'currentBranches . clear ( ) ;', 'final String replacementDefault ) {', 'final String input = cleanup ( source ) ;', 'if ( parts . length ! = 4 ) {', 'final int cmtI = line . indexOf ( COMMENT ) ;', 'if ( this = = other ) {', 'inMultilineComment = true ;', 'public boolean matches ( final String context ) {', 'final char ch = input . charAt ( index ) ;', 'this . folding = folding ;', 'this . replacementBeforeVowel = replacementBeforeVowel . split ( "" \\ \\ | "" ) ;', 'return branch ;', 'rules = new ArrayList < Rule > ( ) ;', ""final boolean force = ( lastChar = = 'm' & & ch = = 'n' ) | | ( lastChar = = 'n' & & ch = = 'm' ) ;"", 'final String inputContext = input . substring ( index ) ;', 'final String replacement1 = stripQuotes ( parts [ 1 ] ) ;', '} else {', 'return toString ( ) . equals ( ( ( Branch ) other ) . toString ( ) ) ;', 'final boolean append = lastReplacement = = null | | !lastReplacement . endsWith ( replacement ) | | forceAppend ;', 'import java . util . Collections ;', 'import java . util . List ;', 'for ( final String nextReplacement : replacements ) {', 'return String . format ( "" % s = ( % s , % s , % s ) "" , pattern , Arrays . asList ( replacementAtStart ) ,', 'return rule2 . getPatternLength ( ) - rule1 . getPatternLength ( ) ;', 'if ( rules = = null ) {', 'if ( str . endsWith ( DOUBLE QUOTE ) ) {', 'return replacementAtStart ;', 'if ( nextCharIsVowel ) {', 'int currentLine = 0 ;', ""char lastChar = ' \\ 0' ;"", 'private static String stripQuotes ( String str ) {', 'currentBranches . addAll ( nextBranches ) ;', 'cachedString = builder . toString ( ) ;', 'if ( rule . matches ( inputContext ) ) {', 'if ( atStart ) {', 'return sb . toString ( ) ;', 'private static final Map < Character , List < Rule > > RULES = new HashMap < Character , List < Rule > > ( ) ;', 'List < Rule > rules = ruleMapping . get ( patternKey ) ;', 'if ( rulesIS = = null ) {', 'line = line . substring ( 0 , cmtI ) ;', 'builder . append ( replacement ) ;', 'lastReplacement = replacement ;', ""builder . append ( '0' ) ;"", 'boolean inMultilineComment = false ;', 'import java . util . Comparator ;', 'for ( final Branch branch : currentBranches ) {', 'import java . util . HashMap ;', 'try {', '""Problem parsing line \'"" + currentLine + ""\' in "" + location , e ) ;', 'private static final String MULTILINE COMMENT END = "" * / "" ;', 'lastChar = ch ;', 'str = str . substring ( 0 , str . length ( ) - 1 ) ;', 'if ( ! ( obj instanceof String ) ) {', '@ Override', 'private final StringBuilder builder ;', 'return soundex ( source , false ) [ 0 ] ;', 'sb . append ( branch ) ;', 'ch = FOLDINGS . get ( ch ) ;', 'public String [ ] getReplacements ( final String context , final boolean atStart ) {', 'import java . util . Scanner ;', '""patterns are not single characters : "" + rawLine + "" in "" + location ) ;', 'throw new IllegalArgumentException ( ""Unable to load resource : "" + RESOURCE FILE ) ;', 'private static void parseRules ( final Scanner scanner , final String location ,', 'if ( line . contains ( "" = "" ) ) {', 'private String cleanup ( final String input ) {', 'import java . io . InputStream ;', 'public Branch createBranch ( ) {', 'final Map < Character , List < Rule > > ruleMapping , final Map < Character , Character > asciiFoldings ) {', 'final String [ ] result = new String [ currentBranches . size ( ) ] ;', 'return str ;', ""sb . append ( ' | ' ) ;"", 'public class DaitchMokotoffSoundex implements StringEncoder {', '}', 'final Scanner scanner = new Scanner ( rulesIS , CharEncoding . UTF 8 ) ;', 'final boolean nextCharIsVowel = nextIndex < context . length ( ) ? isVowel ( context . charAt ( nextIndex ) ) : false ;', 'for ( final String branch : branches ) {', 'final String [ ] parts = line . split ( "" \\ \\ s + "" ) ;', 'if ( str . startsWith ( DOUBLE QUOTE ) ) {', 'if ( inMultilineComment ) {', 'final InputStream rulesIS = DaitchMokotoffSoundex . class . getClassLoader ( ) . getResourceAsStream ( RESOURCE FILE ) ;', 'str = str . substring ( 1 ) ;', 'private String [ ] soundex ( final String source , final boolean branching ) {', 'final int nextIndex = getPatternLength ( ) ;', 'final StringBuilder sb = new StringBuilder ( ) ;', 'break ;', 'public String soundex ( final String source ) {', 'private String lastReplacement ;', 'if ( branching ) {', 'private static final String COMMENT = "" / / "" ;', 'private static final String RESOURCE FILE = ""org / apache / commons / codec / language / dmrules . txt"" ;', '""Parameter supplied to DaitchMokotoffSoundex encode is not of type java . lang . String"" ) ;', 'public int compare ( final Rule rule1 , final Rule rule2 ) {', 'inMultilineComment = false ;', 'private static final Map < Character , Character > FOLDINGS = new HashMap < Character , Character > ( ) ;', 'branch . builder . append ( toString ( ) ) ;', 'if ( line . startsWith ( MULTILINE COMMENT START ) ) {', 'return replacementBeforeVowel ;', 'public Object encode ( final Object obj ) throws EncoderException {', '"" parts : "" + rawLine + "" in "" + location ) ;', 'final List < Rule > ruleList = rule . getValue ( ) ;', 'public void finish ( ) {', '} ) ;', 'return null ;', 'private static final int MAX LENGTH = 6 ;', 'for ( char ch : input . toCharArray ( ) ) {', 'final Rule r = new Rule ( pattern , replacement1 , replacement2 , replacement3 ) ;', 'throw new IllegalArgumentException ( ""Malformed rule statement split into "" + parts . length +', 'protected Rule ( final String pattern , final String replacementAtStart , final String replacementBeforeVowel ,', 'import org . apache . commons . codec . StringEncoder ;', 'public DaitchMokotoffSoundex ( final boolean folding ) {', 'if ( cmtI > = 0 ) {', 'return true ;', 'final List < Branch > nextBranches = branching ? new ArrayList < Branch > ( ) : Collections . EMPTY LIST ;', 'nextBranches . clear ( ) ;', 'private Branch ( ) {', 'if ( Character . isWhitespace ( ch ) ) {', 'return context . startsWith ( pattern ) ;', 'if ( append & & builder . length ( ) < MAX LENGTH ) {', 'package org . apache . commons . codec . language ;', 'final String rightCharacter = parts [ 1 ] ;'}, 'removed_code': set()}"
8f7c59ce888a687a6c9089caf0c5469984a073b4,1.0,[ MATH - 749 ] Add MonotoneChain implementation .,"{'added_code': {'final Vector2D linePoint2 ) {', 'import org . apache . commons . math3 . exception . NullArgumentException ;', 'public MonotoneChain ( final double tolerance ) {', 'this ( DEFAULT TOLERANCE ) ;', 'hullVertices . add ( upperHull . get ( idx ) ) ;', 'final int diff = ( int ) FastMath . signum ( o1 . getX ( ) - o2 . getX ( ) ) ;', 'return diff ;', 'private final double tolerance ;', 'MathUtils . checkNotNull ( points ) ;', '} else {', 'for ( int idx = 0 ; idx < lowerHull . size ( ) - 1 ; idx + + ) {', '}', 'import java . util . Collections ;', 'import java . util . List ;', 'public class MonotoneChain implements ConvexHullGenerator2D {', 'if ( getLocation ( p , p1 , p2 ) < = 0 ) {', 'if ( diff = = 0 ) {', 'return new ConvexHull2D ( points , tolerance ) ;', 'final List < Vector2D > lowerHull = new ArrayList < Vector2D > ( ) ;', 'final int size = upperHull . size ( ) ;', 'this . tolerance = tolerance ;', 'public ConvexHull2D generate ( final Collection < Vector2D > points ) throws NullArgumentException {', 'package org . apache . commons . math3 . geometry . euclidean . twod . hull ;', 'upperHull . add ( p ) ;', 'import org . apache . commons . math3 . util . MathUtils ;', 'public MonotoneChain ( ) {', 'List < Vector2D > hullVertices = new ArrayList < Vector2D > ( lowerHull . size ( ) + upperHull . size ( ) - 2 ) ;', 'import org . apache . commons . math3 . geometry . euclidean . twod . Vector2D ;', 'final Vector2D p2 = upperHull . get ( size - 1 ) ;', 'break ;', 'import org . apache . commons . math3 . util . FastMath ;', 'for ( int idx = pointsSortedByXAxis . size ( ) - 1 ; idx > = 0 ; idx - - ) {', 'return ( int ) FastMath . signum ( o1 . getY ( ) - o2 . getY ( ) ) ;', 'final Vector2D p2 = lowerHull . get ( size - 1 ) ;', 'while ( lowerHull . size ( ) > = 2 ) {', 'final List < Vector2D > upperHull = new ArrayList < Vector2D > ( ) ;', 'Collections . sort ( pointsSortedByXAxis , new Comparator < Vector2D > ( ) {', 'for ( int idx = 0 ; idx < upperHull . size ( ) - 1 ; idx + + ) {', 'upperHull . remove ( size - 1 ) ;', 'return ( linePoint2 . getX ( ) - linePoint1 . getX ( ) ) * ( point . getY ( ) - linePoint1 . getY ( ) ) -', 'final Vector2D p1 = upperHull . get ( size - 2 ) ;', 'import java . util . Comparator ;', 'return new ConvexHull2D ( hullVertices , tolerance ) ;', 'import java . util . Collection ;', 'import java . util . ArrayList ;', 'for ( Vector2D p : pointsSortedByXAxis ) {', 'final Vector2D p = pointsSortedByXAxis . get ( idx ) ;', 'final List < Vector2D > pointsSortedByXAxis = new ArrayList < Vector2D > ( points ) ;', 'final int size = lowerHull . size ( ) ;', '} ) ;', 'final Vector2D linePoint1 ,', 'final Vector2D p1 = lowerHull . get ( size - 2 ) ;', 'public int compare ( final Vector2D o1 , final Vector2D o2 ) {', 'lowerHull . remove ( size - 1 ) ;', 'private static final double DEFAULT TOLERANCE = 1e - 10 ;', 'lowerHull . add ( p ) ;', 'hullVertices . add ( lowerHull . get ( idx ) ) ;', '( point . getX ( ) - linePoint1 . getX ( ) ) * ( linePoint2 . getY ( ) - linePoint1 . getY ( ) ) ;', 'while ( upperHull . size ( ) > = 2 ) {', 'if ( points . size ( ) < 3 ) {', 'private double getLocation ( final Vector2D point ,'}, 'removed_code': set()}"
63f1d6b83bc10a2880f5ec17a172fab284d2eff5,1.0,LANG - 1055 : StrSubstitutor . replaceSystemProperties does not work consistently . This fixes #43 from github . Thanks to Jonathan Baker .,"{'added_code': {'}', 'private static final StrLookup < String > NONE LOOKUP = new MapStrLookup < String > ( null ) ;', 'return new MapStrLookup < String > ( propertiesMap ) ;', 'Properties systemProperties = null ;', 'Properties output = new Properties ( ) ;', 'if ( input = = null ) {', 'output . setProperty ( propertyName , input . getProperty ( propertyName ) ) ;', 'private static Properties copyProperties ( Properties input ) {', 'String propertyName = propertyNames . nextElement ( ) ;', 'systemProperties = System . getProperties ( ) ;', '} catch ( final SecurityException ex ) {', 'import java . util . Properties ;', 'try {', 'return output ;', 'return null ;', 'Enumeration < String > propertyNames = ( Enumeration < String > ) input . propertyNames ( ) ;', 'while ( propertyNames . hasMoreElements ( ) ) {', 'import java . util . Enumeration ;', '@ SuppressWarnings ( ""unchecked"" )', 'final Map < String , String > propertiesMap = ( Map ) properties ;', 'Properties properties = copyProperties ( systemProperties ) ;'}, 'removed_code': {'final Map < String , String > properties = ( Map < String , String > ) propMap ;', 'final Map < ? , ? > propMap = System . getProperties ( ) ;', 'return SYSTEM PROPERTIES LOOKUP ;', 'SYSTEM PROPERTIES LOOKUP = lookup ;', 'private static final StrLookup < String > SYSTEM PROPERTIES LOOKUP ;', '} catch ( final SecurityException ex ) {', 'NONE LOOKUP = new MapStrLookup < String > ( null ) ;', 'try {', 'lookup = new MapStrLookup < String > ( properties ) ;', '}', '@ SuppressWarnings ( ""unchecked"" )', 'private static final StrLookup < String > NONE LOOKUP ;', 'static {', 'StrLookup < String > lookup = null ;', 'lookup = NONE LOOKUP ;'}}"
59ffcad15d220c2bc1f70f01d58bc31dec04b423,1.0,[ IO - 332 ] Improve tailer's reading performance .,"{'added_code': {'switch ( ch ) {', 'this ( file , listener , delay , end , DEFAULT BUFSIZE ) ;', 'while ( run & & ( ( num = reader . read ( inbuf ) ) ! = - 1 ) ) {', 'Tailer tailer = new Tailer ( file , listener , delay , end , bufSize ) ;', '}', 'this . inbuf = new byte [ bufSize ] ;', 'public static Tailer create ( File file , TailerListener listener , long delay , boolean end ) {', 'reader . seek ( rePos ) ;', 'reader = new RandomAccessFile ( file , RAF MODE ) ;', 'listener . handle ( sb . toString ( ) ) ;', 'int num ;', 'private static final int DEFAULT BUFSIZE = 4096 ;', 'break ;', 'private static final String RAF MODE = ""r"" ;', 'return create ( file , listener , delay , end , DEFAULT BUFSIZE ) ;', 'private byte inbuf [ ] ;', 'sb = new StringBuilder ( ) ;', 'for ( int i = 0 ; i < num ; i + + ) {', 'pos = reader . getFilePointer ( ) ;', 'long rePos = pos ;', 'return rePos ;', 'rePos = pos + i + 1 ;', 'reader . seek ( position ) ;', 'StringBuilder sb = new StringBuilder ( ) ;', 'public Tailer ( File file , TailerListener listener , long delay , boolean end , int bufSize ) {', 'byte ch = inbuf [ i ] ;', 'sb . append ( ( char ) ch ) ;', 'public static Tailer create ( File file , TailerListener listener , long delay , boolean end , int bufSize ) {'}, 'removed_code': {'String line = readLine ( reader ) ;', 'reader . seek ( pos ) ;', 'switch ( ch ) {', 'listener . handle ( line ) ;', 'return pos ;', 'while ( ( ch = reader . read ( ) ) ! = - 1 ) {', '}', 'int ch ;', 'public static Tailer create ( File file , TailerListener listener , long delay , boolean end ) {', 'while ( line ! = null ) {', 'StringBuffer sb = new StringBuffer ( ) ;', 'return sb . toString ( ) ;', 'line = readLine ( reader ) ;', 'pos = reader . getFilePointer ( ) ;', 'reader . seek ( position ) ;', 'return null ;', 'reader = new RandomAccessFile ( file , ""r"" ) ;', 'private String readLine ( RandomAccessFile reader ) throws IOException {', 'Tailer tailer = new Tailer ( file , listener , delay , end ) ;', 'sb . append ( ( char ) ch ) ;'}}"
71d7c3264239c55b6e2daf89c44c5685085f26dd,1.0,LANG - 1133 FastDateParser TimeZoneStrategyTest#testTimeZoneStrategyPattern fails on Windows with German Locale reimplementing LANG - 1107,"{'added_code': {""case ' * ' :"", ""case ' [ ' :"", 'sb . append ( \' ( \' + RFC 822 TIME ZONE + "" | ( ? iu ) "" + GMT OPTION ) ;', '}', 'sb . append ( c ) ;', ""sb . append ( ' \\ \\ ' ) ;"", 'private static StringBuilder simpleQuote ( final StringBuilder sb , final String value ) {', 'if ( !tzNames . containsKey ( zoneName ) ) {', 'continue ;', 'this . locale = locale ;', 'tz = tzNames . get ( value . toLowerCase ( locale ) ) ;', ""case ' + ' :"", ""sb . append ( ' ) ' ) ;"", 'final StringBuilder sb = new StringBuilder ( ) ;', ""case ' { ' :"", ""case ' \\ \\ ' :"", 'char c = value . charAt ( i ) ;', 'final String tzId = zoneNames [ ID ] ;', 'private final Locale locale ;', ""simpleQuote ( sb . append ( ' | ' ) , zoneName ) ;"", 'default :', 'validTimeZoneChars = sb . toString ( ) ;', 'for ( int i = 0 ; i < value . length ( ) ; + + i ) {', ""case ' ( ' :"", 'tzNames . put ( zoneName , tz ) ;', ""case ' | ' :"", ""simpleQuote ( regex , textKeyValue ) . append ( ' | ' ) ;"", 'regex . append ( validTimeZoneChars ) ;', 'private final Map < String , TimeZone > tzNames = new HashMap < String , TimeZone > ( ) ;', ""case '$' :"", ""case ' ) ' :"", ""case ' ? ' :"", 'final TimeZone tz = TimeZone . getTimeZone ( tzId ) ;', 'for ( int i = 1 ; i < zoneNames . length ; + + i ) {', 'String zoneName = zoneNames [ i ] . toLowerCase ( locale ) ;', 'for ( final String [ ] zoneNames : zones ) {', 'private final String validTimeZoneChars ;', 'if ( tzId . equalsIgnoreCase ( ""GMT"" ) ) {', ""case ' . ' :"", ""case ' ^ ' :"", 'return sb ;', 'switch ( c ) {'}, 'removed_code': {'final TimeZone tz = TimeZone . getTimeZone ( zone [ ID ] ) ;', '}', 'static final String TZ DATABASE = "" ( ? : \\ \\ p { L } [ \\ \\ p { L } \\ \\ p { Mc } \\ \\ p { Nd } \\ \\ p { Zs } \\ \\ p { P } & & [ ^ - ] ] * - ? \\ \\ p { Zs } ? ) * "" ;', 'tz = tzNames . get ( value ) ;', 'tzNames . put ( zone [ SHORT STD ] , tz ) ;', 'tzNames . put ( zone [ LONG STD ] , tz ) ;', 'if ( !tzNames . containsKey ( zone [ SHORT DST ] ) ) {', 'import java . util . TreeMap ;', 'regex . append ( VALID TZ ) ;', 'private static final int LONG DST = 3 ;', 'private static final int SHORT DST = 4 ;', 'private static final int LONG STD = 1 ;', ""escapeRegex ( regex , textKeyValue , false ) . append ( ' | ' ) ;"", 'private final SortedMap < String , TimeZone > tzNames = new TreeMap < String , TimeZone > ( String . CASE INSENSITIVE ORDER ) ;', 'if ( !tzNames . containsKey ( zone [ SHORT STD ] ) ) {', 'for ( final String [ ] zone : zones ) {', 'tzNames . put ( zone [ SHORT DST ] , tz ) ;', 'private static final int SHORT STD = 2 ;', 'import java . util . SortedMap ;', 'private static final String VALID TZ = "" ( ( ? iu ) "" + RFC 822 TIME ZONE + "" | "" + GMT OPTION + "" | "" + TZ DATABASE + "" ) "" ;', 'if ( !tzNames . containsKey ( zone [ LONG STD ] ) ) {', 'tzNames . put ( zone [ LONG DST ] , tz ) ;', 'if ( !tzNames . containsKey ( zone [ LONG DST ] ) ) {', 'if ( tz . useDaylightTime ( ) ) {'}}"
1fbb16b037e62c6af90ab89ab3ac8d3633c59a90,1.0,Fix writing of multibyte name entries,"{'added_code': {'@ Deprecated', 'public int getHeaderPadCount ( Charset charset ) {', 'pad ( entry . getHeaderPadCount ( Charset . forName ( encoding ) ) ) ;', 'import java . nio . charset . Charset ;', 'return getHeaderPadCount ( name . length ( ) ) ;', 'return getHeaderPadCount ( null ) ;', '}', 'if ( name = = null ) {', 'return 0 ;', 'return getHeaderPadCount ( name . getBytes ( charset ) . length ) ;', 'if ( charset = = null ) {'}, 'removed_code': {'long namesize = name ! = null ? name . length ( ) : 0 ;', 'pad ( entry . getHeaderPadCount ( ) ) ;', 'return getHeaderPadCount ( namesize ) ;'}}"
c334a1bca8338c92e76f0f1cf2ef4884e3eb5dbd,1.0,"PARQUET - 290 : Add data model to Avro reader builder This PR currently includes #203 , which will be removed when it is merged . Author : Ryan Blue < blue @ apache . org > Closes #204 from rdblue / PARQUET - 290 - data - model - builder and squashes the following commits : d257a2c [ Ryan Blue ] PARQUET - 290 : Add Avro data model to reader builder .","{'added_code': {'import org . apache . avro . generic . GenericData ;', 'super ( path ) ;', '} else {', '}', 'isReflect = true ;', 'private Builder ( Path path ) {', 'this . model = model ;', 'model . getClass ( ) ! = SpecificData . class ) {', 'if ( isReflect ) {', 'private GenericData model = null ;', 'public Builder < T > withDataModel ( GenericData model ) {', 'public static class Builder < T > extends ParquetReader . Builder {', 'import org . apache . parquet . hadoop . api . ReadSupport ;', 'return this ;', 'conf . setBoolean ( AvroReadSupport . AVRO COMPATIBILITY , enableCompatibility ) ;', 'this . enableCompatibility = enableCompatibility ;', 'protected ReadSupport < T > getReadSupport ( ) {', 'import org . apache . avro . specific . SpecificData ;', 'this . enableCompatibility = false ;', 'private boolean isReflect = true ;', '@ Override', 'return new Builder < T > ( file ) ;', 'public Builder < T > disableCompatibility ( ) {', 'if ( model . getClass ( ) ! = GenericData . class & &', 'public Builder < T > withCompatibility ( boolean enableCompatibility ) {', 'private boolean enableCompatibility = true ;', 'return new AvroReadSupport < T > ( model ) ;', 'conf . setBoolean ( AvroReadSupport . AVRO COMPATIBILITY , false ) ;'}, 'removed_code': {'return ParquetReader . builder ( new AvroReadSupport < T > ( ) , file ) ;'}}"
28b7b958d39730fc278fd1919bf335c52133a1a2,1.0,[ CODEC - 199 ] Bug in HW rule in Soundex .,"{'added_code': {'final char prevChar = str . charAt ( i ) ;', 'if ( this . map ( prevChar ) = = mappedChar ) {', 'break ;', '}', 'for ( int i = index - 1 ; i > = 0 ; i - - ) {', ""if ( 'H'! = prevChar & & 'W'! = prevChar ) {""}, 'removed_code': {'final char preHWChar = str . charAt ( index - 2 ) ;', 'final char hwChar = str . charAt ( index - 1 ) ;', ""if ( firstCode = = mappedChar | | 'H' = = preHWChar | | 'W' = = preHWChar ) {"", ""if ( 'H' = = hwChar | | 'W' = = hwChar ) {"", 'final char firstCode = this . map ( preHWChar ) ;'}}"
02dc8c7e77db316553699f0e371f3e7803d3efbd,1.0,IO - 274 - Tailer returning partial lines when reaching EOF before EOL Added version of readLine ( ) that returns null if EOF seen before EOL Re - enabled test case Had to add sleep call to allow test file to be cleared up properly,"{'added_code': {'boolean seenCR = false ;', 'String line = readLine ( reader ) ;', 'reader . seek ( pos ) ;', 'switch ( ch ) {', 'return pos ;', 'while ( ( ch = reader . read ( ) ) ! = - 1 ) {', '}', 'int ch ;', 'long pos = reader . getFilePointer ( ) ;', 'StringBuffer sb = new StringBuffer ( ) ;', 'return sb . toString ( ) ;', 'break ;', 'seenCR = true ;', 'line = readLine ( reader ) ;', 'if ( seenCR ) {', 'pos = reader . getFilePointer ( ) ;', 'default :', 'seenCR = false ;', 'return null ;', 'private String readLine ( RandomAccessFile reader ) throws IOException {', ""case ' \\ n' :"", 'sb . append ( ( char ) ch ) ;'}, 'removed_code': {'line = reader . readLine ( ) ;', 'String line = reader . readLine ( ) ;', 'return reader . getFilePointer ( ) ;'}}"
88d3eccc6805ccdb122b0acd50891229646b5ec7,1.0,Initial version of an immutable configuration interface .,"{'added_code': {'double getDouble ( String key ) ;', 'Iterator < String > getKeys ( String prefix ) ;', 'long getLong ( String key ) ;', 'float getFloat ( String key , float defaultValue ) ;', 'byte getByte ( String key ) ;', 'long getLong ( String key , long defaultValue ) ;', 'int getInt ( String key , int defaultValue ) ;', 'boolean getBoolean ( String key ) ;', 'int getInt ( String key ) ;', 'byte getByte ( String key , byte defaultValue ) ;', '}', 'import java . util . List ;', 'List < Object > getList ( String key ) ;', 'String getString ( String key ) ;', 'import java . math . BigDecimal ;', 'Integer getInteger ( String key , Integer defaultValue ) ;', 'boolean containsKey ( String key ) ;', 'String getString ( String key , String defaultValue ) ;', 'Short getShort ( String key , Short defaultValue ) ;', 'Object getProperty ( String key ) ;', 'Iterator < String > getKeys ( ) ;', 'boolean getBoolean ( String key , boolean defaultValue ) ;', 'BigDecimal getBigDecimal ( String key , BigDecimal defaultValue ) ;', 'short getShort ( String key ) ;', 'short getShort ( String key , short defaultValue ) ;', 'import java . util . Properties ;', 'Long getLong ( String key , Long defaultValue ) ;', 'public interface ImmutableConfiguration', 'import java . math . BigInteger ;', 'Byte getByte ( String key , Byte defaultValue ) ;', 'List < Object > getList ( String key , List < Object > defaultValue ) ;', 'BigInteger getBigInteger ( String key , BigInteger defaultValue ) ;', 'Properties getProperties ( String key ) ;', 'Double getDouble ( String key , Double defaultValue ) ;', 'Boolean getBoolean ( String key , Boolean defaultValue ) ;', 'float getFloat ( String key ) ;', 'boolean isEmpty ( ) ;', 'Float getFloat ( String key , Float defaultValue ) ;', 'String [ ] getStringArray ( String key ) ;', 'package org . apache . commons . configuration ;', 'BigDecimal getBigDecimal ( String key ) ;', 'double getDouble ( String key , double defaultValue ) ;', '{', 'import java . util . Iterator ;', 'BigInteger getBigInteger ( String key ) ;'}, 'removed_code': set()}"
13188390f33649b1881dbd4d9f2440894a36463a,1.0,Starting work on BSP trees for spheres .,"{'added_code': {'import org . apache . commons . math3 . geometry . partitioning . BSPTree ;', 'new BSPTree < Sphere1D > ( subPlus , new BSPTree < Sphere1D > ( Boolean . FALSE ) ,', 'splitTree . getPlus ( ) , null ) ;', 'final BSPTree < Sphere1D > splitTree = getRemainingRegion ( ) . getTree ( false ) . split ( subMinus ) ;', 'final Circle otherCircle = ( Circle ) hyperplane ;', 'new BSPTree < Sphere1D > ( Boolean . FALSE ) :', 'package org . apache . commons . math3 . geometry . spherical . twod ;', 'new SubCircle ( thisCircle . copySelf ( ) , new ArcsSet ( minusTree ) ) ) ;', 'final Circle thisCircle = ( Circle ) getHyperplane ( ) ;', 'return ( global < - 1 . 0e - 10 ) ? Side . MINUS : ( ( global > 1 . 0e - 10 ) ? Side . PLUS : Side . HYPER ) ;', '}', 'import org . apache . commons . math3 . geometry . partitioning . Side ;', 'final double global = otherCircle . getOffset ( thisCircle . getPointAt ( 0 . 0 ) ) ;', 'public SubCircle ( final Hyperplane < Sphere2D > hyperplane ,', 'final boolean direct = FastMath . sin ( thisCircle . getAngle ( ) - otherCircle . getAngle ( ) ) < 0 ;', 'public class SubCircle extends AbstractSubHyperplane < Sphere2D , Sphere1D > {', 'new BSPTree < Sphere1D > ( subMinus , new BSPTree < Sphere1D > ( Boolean . FALSE ) ,', 'final SubHyperplane < Sphere1D > subMinus = new Chord ( x , direct ) . wholeHyperplane ( ) ;', 'final S2Point [ ] crossings = thisCircle . intersection ( otherCircle ) ;', 'import org . apache . commons . math3 . util . FastMath ;', 'final Region < Sphere1D > remainingRegion ) {', 'protected AbstractSubHyperplane < Sphere2D , Sphere1D > buildNew ( final Hyperplane < Sphere2D > hyperplane ,', 'final BSPTree < Sphere1D > minusTree = getRemainingRegion ( ) . isEmpty ( splitTree . getMinus ( ) ) ?', 'final SubHyperplane < Sphere1D > subPlus = new Chord ( x , !direct ) . wholeHyperplane ( ) ;', 'import org . apache . commons . math3 . geometry . spherical . oned . S1Point ;', 'import org . apache . commons . math3 . geometry . spherical . oned . Chord ;', 'super ( hyperplane , remainingRegion ) ;', 'return getRemainingRegion ( ) . side ( new Chord ( x , direct ) ) ;', 'import org . apache . commons . math3 . geometry . partitioning . Region ;', 'public Side side ( final Hyperplane < Sphere2D > hyperplane ) {', 'public SplitSubHyperplane < Sphere2D > split ( final Hyperplane < Sphere2D > hyperplane ) {', 'return ( global < - 1 . 0e - 10 ) ?', 'if ( crossings = = null ) {', '@ Override', 'splitTree . getMinus ( ) , null ) ;', 'import org . apache . commons . math3 . geometry . partitioning . AbstractSubHyperplane ;', 'import org . apache . commons . math3 . geometry . partitioning . SubHyperplane ;', 'new SplitSubHyperplane < Sphere2D > ( null , this ) :', 'return new SplitSubHyperplane < Sphere2D > ( new SubCircle ( thisCircle . copySelf ( ) , new ArcsSet ( plusTree ) ) ,', 'final BSPTree < Sphere1D > plusTree = getRemainingRegion ( ) . isEmpty ( splitTree . getPlus ( ) ) ?', 'import org . apache . commons . math3 . geometry . partitioning . Hyperplane ;', 'import org . apache . commons . math3 . geometry . spherical . oned . ArcsSet ;', 'return new SubCircle ( hyperplane , remainingRegion ) ;', 'new SplitSubHyperplane < Sphere2D > ( this , null ) ;', 'import org . apache . commons . math3 . geometry . spherical . oned . Sphere1D ;', 'final S1Point x = thisCircle . toSubSpace ( crossings ) ;'}, 'removed_code': set()}"
b985d79f12b7110e9b1e13dd437b25ebd40be551,1.0,Adapted PropertiesConfigurationLayout to new event mechanism .,"{'added_code': {'. getEventType ( ) ) )', 'public void onEvent ( ConfigurationEvent event )', 'layoutData . containsKey ( event . getPropertyName ( ) ) ;', 'PropertyLayoutData data =', 'import org . apache . commons . configuration . event . EventListener ;', 'public class PropertiesConfigurationLayout implements EventListener < ConfigurationEvent >', 'else if ( ConfigurationEvent . CLEAR PROPERTY . equals ( event', 'fetchLayoutData ( event . getPropertyName ( ) ) ;', 'else if ( ConfigurationEvent . CLEAR . equals ( event . getEventType ( ) ) )', '{', '}', 'boolean contained =', 'config . addEventListener ( ConfigurationEvent . ANY , this ) ;', 'else if ( ConfigurationEvent . SET PROPERTY . equals ( event', 'if ( ConfigurationEvent . ADD PROPERTY . equals ( event . getEventType ( ) ) )', 'config . removeEventListener ( ConfigurationEvent . ANY , this ) ;'}, 'removed_code': {'import org . apache . commons . configuration . event . ConfigurationListener ;', 'config . addConfigurationListener ( this ) ;', 'case AbstractConfiguration . EVENT CLEAR :', 'break ;', 'PropertyLayoutData data = fetchLayoutData ( event', 'case AbstractConfiguration . EVENT CLEAR PROPERTY :', 'switch ( event . getType ( ) )', '. getPropertyName ( ) ) ;', 'public class PropertiesConfigurationLayout implements ConfigurationListener', 'config . removeConfigurationListener ( this ) ;', 'public void configurationChanged ( ConfigurationEvent event )', 'case AbstractConfiguration . EVENT ADD PROPERTY :', 'boolean contained = layoutData . containsKey ( event', 'case AbstractConfiguration . EVENT SET PROPERTY :'}}"
0a75cbc380f537c06e26fa5bd9654cf878a9587a,1.0,Improved robustness of 1 - sphere regions ( ArcsSet ) at 0 / 2 \ pi crossing .,"{'added_code': {'plus . setAttribute ( Boolean . FALSE ) ;', 'public static class InconsistentStateAt2PiWrapping extends MathIllegalArgumentException {', 'super ( LocalizedFormats . INCONSISTENT STATE AT 2 PI WRAPPING ) ;', 'largest = n ;', 'plusIgnored = addArcEnd ( plus , plusToMinus , plusIgnored ) ;', 'return new ArcsSet ( tree , getTolerance ( ) ) ;', 'boolean minusIgnored = false ;', 'final boolean firstState = ( Boolean ) first . getAttribute ( ) ;', '} else {', 'minusIgnored = addArcStart ( minus , a [ 0 ] , minusIgnored ) ;', '}', 'if ( tree . getCut ( ) = = null & & ! ( Boolean ) tree . getAttribute ( ) ) {', 'BSPTree < Sphere1D > largest = null ;', 'minusIgnored = addArcEnd ( minus , minusToPlus , minusIgnored ) ;', 'last . setAttribute ( Boolean . TRUE ) ;', 'private boolean addArcEnd ( final BSPTree < Sphere1D > tree , final double alpha , final boolean ignored ) {', 'current = end ;', 'return leafBefore ( smallest ) ;', 'private BSPTree < Sphere1D > getLastLeaf ( final BSPTree < Sphere1D > root ) {', 'return ;', 'public ArcsSet ( final BSPTree < Sphere1D > tree , final double tolerance )', 'smallest = n ;', 'final boolean lastState = ( Boolean ) last . getAttribute ( ) ;', 'minusIgnored = addArcStart ( minus , plusToMinus , minusIgnored ) ;', 'if ( alpha < = getTolerance ( ) ) {', 'last . getMinus ( ) . setAttribute ( Boolean . TRUE ) ;', 'current = firstStart ;', 'return leafAfter ( largest ) ;', 'if ( stateBefore ^ stateAfter ) {', 'private static final long serialVersionUID = 20140107L ;', 'throws InconsistentStateAt2PiWrapping {', 'final BSPTree < Sphere1D > minus = new BSPTree < Sphere1D > ( ) ;', 'private BSPTree < Sphere1D > getFirstLeaf ( final BSPTree < Sphere1D > root ) {', 'private boolean addArcStart ( final BSPTree < Sphere1D > tree , final double alpha , final boolean ignored ) {', 'return ignored ;', 'last . getPlus ( ) . setAttribute ( Boolean . FALSE ) ;', 'if ( firstState ^ lastState ) {', 'final BSPTree < Sphere1D > first = getFirstLeaf ( tree ) ;', 'BSPTree < Sphere1D > start = current ;', 'minusIgnored = addArcEnd ( minus , a [ 1 ] , minusIgnored ) ;', 'return new Split ( createSplitPart ( plus , plusIgnored ) , createSplitPart ( minus , minusIgnored ) ) ;', 'minus . setAttribute ( Boolean . FALSE ) ;', 'BSPTree < Sphere1D > smallest = null ;', 'private BSPTree < Sphere1D > current ;', 'first . getMinus ( ) . setAttribute ( lastState ) ;', 'private ArcsSet createSplitPart ( final BSPTree < Sphere1D > tree , final boolean ignored ) {', 'import org . apache . commons . math3 . exception . MathIllegalArgumentException ;', 'for ( BSPTree < Sphere1D > n = root ; n ! = null ; n = nextInternalNode ( n ) ) {', 'current = null ;', 'for ( BSPTree < Sphere1D > n = root ; n ! = null ; n = previousInternalNode ( n ) ) {', 'first . getPlus ( ) . setAttribute ( firstState ) ;', 'last . insertCut ( new LimitAngle ( new S1Point ( alpha ) , false , getTolerance ( ) ) ) ;', 'final Boolean stateBefore = ( Boolean ) getFirstLeaf ( root ) . getAttribute ( ) ;', 'last . setAttribute ( null ) ;', 'if ( alpha > = MathUtils . TWO PI - getTolerance ( ) ) {', 'first . insertCut ( new LimitAngle ( new S1Point ( 0 . 0 ) , true , getTolerance ( ) ) ) ;', 'public InconsistentStateAt2PiWrapping ( ) {', 'return null ;', 'return root ;', 'private void check2PiConsistency ( ) throws InconsistentStateAt2PiWrapping {', 'check2PiConsistency ( ) ;', 'BSPTree < Sphere1D > root = getTree ( false ) ;', 'final BSPTree < Sphere1D > plus = new BSPTree < Sphere1D > ( ) ;', 'plusIgnored = addArcEnd ( plus , a [ 1 ] , plusIgnored ) ;', 'final Boolean stateAfter = ( Boolean ) getLastLeaf ( root ) . getAttribute ( ) ;', 'plusIgnored = addArcStart ( plus , minusToPlus , plusIgnored ) ;', 'public ArcsSet ( final Collection < SubHyperplane < Sphere1D > > boundary , final double tolerance )', 'final BSPTree < Sphere1D > last = getLastLeaf ( tree ) ;', 'last . insertCut ( new LimitAngle ( new S1Point ( alpha ) , true , getTolerance ( ) ) ) ;', 'return true ;', 'if ( root . getCut ( ) = = null ) {', 'node = getFirstLeaf ( node ) . getParent ( ) ;', 'plusIgnored = addArcStart ( plus , a [ 0 ] , plusIgnored ) ;', 'throw new InconsistentStateAt2PiWrapping ( ) ;', 'boolean plusIgnored = false ;', 'if ( ignored ) {'}, 'removed_code': {'minus . add ( arcStart ( a [ 0 ] ) ) ;', 'plus . add ( arcStart ( a [ 0 ] ) ) ;', '} else if ( previousInternalNode ( firstStart ) = = null & & nextInternalNode ( firstStart ) = = null ) {', '}', 'private SubLimitAngle arcEnd ( final double alpha ) {', 'return new LimitAngle ( new S1Point ( alpha ) , false , getTolerance ( ) ) . wholeHyperplane ( ) ;', 'public ArcsSet ( final Collection < SubHyperplane < Sphere1D > > boundary , final double tolerance ) {', 'while ( previous ! = null ) {', 'pending = new double [ ] {', 'node = null ;', 'previous = previousInternalNode ( node ) ;', 'minus . add ( arcEnd ( minusToPlus ) ) ;', 'node = firstStart ;', 'final List < SubHyperplane < Sphere1D > > minus = new ArrayList < SubHyperplane < Sphere1D > > ( ) ;', 'private SubLimitAngle arcStart ( final double alpha ) {', '} ;', '0 , MathUtils . TWO PI', 'return new Split ( plus . isEmpty ( ) ? null : new ArcsSet ( plus , getTolerance ( ) ) ,', 'final List < SubHyperplane < Sphere1D > > plus = new ArrayList < SubHyperplane < Sphere1D > > ( ) ;', 'minus . add ( arcStart ( plusToMinus ) ) ;', 'plus . add ( arcEnd ( a [ 1 ] ) ) ;', 'minus . add ( arcEnd ( a [ 1 ] ) ) ;', 'BSPTree < Sphere1D > start = node ;', 'minus . isEmpty ( ) ? null : new ArcsSet ( minus , getTolerance ( ) ) ) ;', 'plus . add ( arcEnd ( plusToMinus ) ) ;', 'BSPTree < Sphere1D > previous = previousInternalNode ( node ) ;', 'plus . add ( arcStart ( minusToPlus ) ) ;', 'node = previous ;', 'private BSPTree < Sphere1D > node ;', 'public ArcsSet ( final BSPTree < Sphere1D > tree , final double tolerance ) {', 'node = end ;', 'return new LimitAngle ( new S1Point ( alpha ) , true , getTolerance ( ) ) . wholeHyperplane ( ) ;'}}"
8a3b3b537a30b14c4ffb5eb32ffa41d5027bddad,1.0,OPENNLP - 904 Harmonize lemmatizer API and function to get multiple lemmas OPENNLP - 904 add minor correction after PR comment,"{'added_code': {'while ( ( line = breader . readLine ( ) ) ! = null ) {', '} else {', 'lemmas . add ( this . lemmatize ( tokens [ i ] , postags [ i ] ) ) ;', '}', 'return lemmasList ;', 'List < String > lemmasList = new ArrayList < > ( ) ;', 'final String [ ] elems = line . split ( """" ) ;', 'private String lemmatize ( final String word , final String postag ) {', 'List < List < String > > allLemmas = new ArrayList < > ( ) ;', 'if ( !keyValues . isEmpty ( ) ) {', 'public Map < List < String > , List < String > > getDictMap ( ) {', 'return allLemmas ;', 'public List < List < String > > lemmatize ( final List < String > tokens , final List < String > posTags ) {', 'final List < String > keys = this . getDictKeys ( word , postag ) ;', 'for ( int i = 0 ; i < tokens . size ( ) ; i + + ) {', 'this . dictMap . put ( Arrays . asList ( elems [ 0 ] , elems [ 1 ] ) , Arrays . asList ( elems [ 2 ] ) ) ;', 'lemmasList . add ( ""O"" ) ;', 'private List < String > getAllLemmas ( final String word , final String postag ) {', 'private final Map < List < String > , List < String > > dictMap ;', 'public DictionaryLemmatizer ( final InputStream dictionary ) throws IOException {', 'allLemmas . add ( this . getAllLemmas ( tokens . get ( i ) , posTags . get ( i ) ) ) ;', 'new InputStreamReader ( dictionary ) ) ;', 'lemma = keyValues . get ( 0 ) ;', 'final BufferedReader breader = new BufferedReader (', 'final List < String > keyValues = this . dictMap . get ( keys ) ;', 'lemmasList . addAll ( keyValues ) ;'}, 'removed_code': {'lemmas . add ( this . apply ( tokens [ i ] , postags [ i ] ) ) ;', 'e . printStackTrace ( ) ;', 'private final Map < List < String > , String > dictMap ;', 'while ( ( line = breader . readLine ( ) ) ! = null ) {', 'final String [ ] elems = line . split ( """" ) ;', 'final String keyValue = this . dictMap . get ( keys ) ;', 'try {', '}', 'this . dictMap . put ( Arrays . asList ( elems [ 0 ] , elems [ 1 ] ) , elems [ 2 ] ) ;', 'lemma = keyValue ;', 'public DictionaryLemmatizer ( final InputStream dictionary ) {', 'public String apply ( final String word , final String postag ) {', 'if ( keyValue ! = null ) {', 'public Map < List < String > , String > getDictMap ( ) {', 'final BufferedReader breader = new BufferedReader ( new InputStreamReader ( dictionary ) ) ;', '} catch ( final IOException e ) {'}}"
b45c4bdb496381b5f90df6872edca12e0a2e68ca,1.0,"PARQUET - 382 : Add methods to append encoded data to files . This allows appending encoded data blocks to open ParquetFileWriters , which makes it possible to merge multiple Parquet files without re - encoding all of the records . This works by finding the column chunk for each column in the file schema and then streaming the encoded data from one file to the other . New starting offsets are tracked and the column chunk metadata in the footer is updated with the new starting positions . Author : Ryan Blue < blue @ apache . org > Closes #278 from rdblue / PARQUET - 382 - append - encoded - blocks and squashes the following commits : cb98552 [ Ryan Blue ] PARQUET - 382 : Add methods to append encoded data to files .","{'added_code': {'if ( DEBUG ) LOG . debug (', 'List < BlockMetaData > rowGroups ,', 'private static void copy ( FSDataInputStream from , FSDataOutputStream to ,', 'long length = 0 ;', 'if ( !dropColumns & & !columnsToCopy . isEmpty ( ) ) {', '""Columns cannot be copied ( missing from target schema ) : % s"" ,', 'List < ColumnChunkMetaData > columnsInOrder =', 'newChunkStart ,', '""Copying "" + length + "" bytes at "" + start + "" to "" + to . getPos ( ) ) ;', 'chunk . getTotalUncompressedSize ( ) ) ) ;', 'ParquetFileReader . open ( conf , file ) . appendTo ( this ) ;', 'chunk . getEncodings ( ) ,', 'appendRowGroup ( file , block , dropColumns ) ;', 'chunk . getCodec ( ) ,', 'public void appendRowGroups ( FSDataInputStream file ,', 'throw new IllegalArgumentException (', 'private static final ThreadLocal < byte [ ] > COPY BUFFER =', 'if ( ( i + 1 ) = = columnsInOrder . size ( ) | |', '""Missing column \' % s\' , cannot copy row group : % s"" , path , rowGroup ) ) ;', 'String path = ColumnPath . get ( descriptor . getPath ( ) ) . toDotString ( ) ;', 'private long currentChunkDictionaryPageOffset ;', 'private ColumnPath currentChunkPath ;', 'new ThreadLocal < byte [ ] > ( ) {', 'private Set < Encoding > currentEncodings ;', 'chunk . getPath ( ) ,', 'chunk . getStatistics ( ) ,', 'length = 0 ;', 'columnsToCopy . put ( chunk . getPath ( ) . toDotString ( ) , chunk ) ;', 'private long currentChunkValueCount ;', 'for ( ColumnDescriptor descriptor : schema . getColumns ( ) ) {', 'long bytesLeft = length - bytesCopied ;', '""Unexpected end of input file at "" + start + bytesCopied ) ;', 'protected byte [ ] initialValue ( ) {', 'currentBlock . setTotalByteSize ( blockCompressedSize ) ;', 'if ( start < 0 ) {', 'if ( bytesRead < 0 ) {', 'chunk . getValueCount ( ) ,', 'startBlock ( rowGroup . getRowCount ( ) ) ;', 'import org . apache . hadoop . fs . FSDataInputStream ;', 'length + = chunk . getTotalSize ( ) ;', 'endBlock ( ) ;', 'currentBlock . addColumn ( ColumnChunkMetaData . get (', 'import org . apache . parquet . Strings ;', '} else {', 'while ( bytesCopied < length ) {', 'private Statistics currentStatistics ;', 'for ( int i = 0 ; i < columnsInOrder . size ( ) ; i + = 1 ) {', '( buffer . length < bytesLeft ? buffer . length : ( int ) bytesLeft ) ) ;', 'if ( chunk ! = null ) {', 'copy ( from , out , start , length ) ;', 'long newChunkStart = out . getPos ( ) + length ;', 'return new byte [ 8192 ] ;', 'throw new IllegalArgumentException ( String . format (', 'private BlockMetaData currentBlock ;', 'private long currentRecordCount ;', '} ;', 'long start = - 1 ;', '@ Override', 'chunk . getTotalSize ( ) ,', 'byte [ ] buffer = COPY BUFFER . get ( ) ;', 'private CompressionCodecName currentChunkCodec ;', 'start = chunk . getStartingPos ( ) ;', 'ColumnChunkMetaData chunk = columnsInOrder . get ( i ) ;', 'private PrimitiveTypeName currentChunkType ;', 'start = - 1 ;', 'long bytesCopied = 0 ;', 'new HashMap < String , ColumnChunkMetaData > ( ) ;', 'public void appendFile ( Configuration conf , Path file ) throws IOException {', 'import java . io . OutputStream ;', 'long blockCompressedSize = 0 ;', 'Map < String , ColumnChunkMetaData > columnsToCopy =', '}', 'chunk . getType ( ) ,', 'bytesCopied + = bytesRead ;', 'columnsInOrder . add ( chunk ) ;', 'for ( ColumnChunkMetaData chunk : rowGroup . getColumns ( ) ) {', 'new ArrayList < ColumnChunkMetaData > ( ) ;', 'from . seek ( start ) ;', 'int bytesRead = from . read ( buffer , 0 ,', 'private long currentChunkFirstDataPage ;', 'to . write ( buffer , 0 , bytesRead ) ;', 'Strings . join ( columnsToCopy . keySet ( ) , "" , "" ) ) ) ;', 'blockCompressedSize + = chunk . getTotalSize ( ) ;', 'ColumnChunkMetaData chunk = columnsToCopy . remove ( path ) ;', 'long start , long length ) throws IOException {', 'boolean dropColumns ) throws IOException {', 'columnsInOrder . get ( i + 1 ) . getStartingPos ( ) ! = ( start + length ) ) {', 'for ( BlockMetaData block : rowGroups ) {', 'public void appendRowGroup ( FSDataInputStream from , BlockMetaData rowGroup ,'}, 'removed_code': {'private Set < Encoding > currentEncodings ;', 'private CompressionCodecName currentChunkCodec ;', 'private long currentChunkDictionaryPageOffset ;', 'private PrimitiveTypeName currentChunkType ;', 'private long currentChunkFirstDataPage ;', 'private Statistics currentStatistics ;', 'private BlockMetaData currentBlock ;', 'private ColumnPath currentChunkPath ;', 'private long currentRecordCount ;', 'private long currentChunkValueCount ;'}}"
addf9529dd35a7a01b3baee7472736dcff28d294,1.0,Always use { } blocks for conditional code,"{'added_code': {'if ( !FTPReply . isPositiveIntermediate ( rnfr ( from ) ) ) {', 'while ( ( line = reader . readLine ( ) ) ! = null ) {', 'if ( offset > = 0 ) {', 'dataConnectionMode ! = PASSIVE LOCAL DATA CONNECTION MODE ) {', 'if ( fileType = = ASCII FILE TYPE ) {', '}', 'if ( pasv ( ) ! = FTPReply . ENTERING PASSIVE MODE ) {', 'if ( dataTimeout > = 0 ) {', 'if ( FTPReply . isPositiveCompletion ( help ( command ) ) ) {', 'if ( !FTPReply . isPositiveIntermediate ( replyCode ) ) {', 'if ( FTPReply . isPositiveCompletion ( mdtm ( pathname ) ) ) {', 'dataConnectionMode = = PASSIVE REMOTE DATA CONNECTION MODE ) {', '| | ! ( delim3 = = delim4 ) ) {', 'if ( ( socket = openDataConnection ( FTPCommand . NLST , getListArguments ( pathname ) ) ) = = null ) {', 'if ( FTPReply . isPositiveCompletion ( replyCode ) ) {', 'if ( FTPReply . isPositiveCompletion ( help ( ) ) ) {', 'if ( activeMaxPort = = activeMinPort ) {', 'if ( FTPReply . isPositiveCompletion ( stat ( ) ) ) {', 'if ( pwd ( ) ! = FTPReply . PATHNAME CREATED ) {', 'if ( systemName = = null & & FTPReply . isPositiveCompletion ( syst ( ) ) ) {', 'if ( ( socket = openDataConnection ( command , remote ) ) = = null ) {', 'if ( FTPReply . isPositiveCompletion ( stat ( pathname ) ) ) {'}, 'removed_code': {'if ( pasv ( ) ! = FTPReply . ENTERING PASSIVE MODE )', '| | ! ( delim3 = = delim4 ) )', 'while ( ( line = reader . readLine ( ) ) ! = null )', 'if ( offset > = 0 )', 'if ( systemName = = null & & FTPReply . isPositiveCompletion ( syst ( ) ) )', 'if ( ( socket = openDataConnection ( command , remote ) ) = = null )', 'if ( !FTPReply . isPositiveIntermediate ( replyCode ) )', 'if ( FTPReply . isPositiveCompletion ( help ( command ) ) )', 'dataConnectionMode ! = PASSIVE LOCAL DATA CONNECTION MODE )', 'if ( pwd ( ) ! = FTPReply . PATHNAME CREATED )', 'if ( FTPReply . isPositiveCompletion ( stat ( pathname ) ) )', 'dataConnectionMode = = PASSIVE REMOTE DATA CONNECTION MODE )', 'if ( dataTimeout > = 0 )', 'if ( FTPReply . isPositiveCompletion ( help ( ) ) )', 'if ( ( socket = openDataConnection ( FTPCommand . NLST , getListArguments ( pathname ) ) ) = = null )', 'if ( FTPReply . isPositiveCompletion ( replyCode ) )', 'if ( fileType = = ASCII FILE TYPE )', 'if ( !FTPReply . isPositiveIntermediate ( rnfr ( from ) ) )', 'if ( activeMaxPort = = activeMinPort )', 'if ( FTPReply . isPositiveCompletion ( stat ( ) ) )', 'if ( FTPReply . isPositiveCompletion ( mdtm ( pathname ) ) )'}}"
792839b464bc3df40f773147b7694b761cf23b5a,1.0,MATH - 1134 Flag to request initialization of the internal data needed to call the partial derivatives methods .,"{'added_code': {'double [ ] [ ] f ,', 'this . initializeDerivatives = initializeDerivatives ;', 'partialDerivativeX = null ;', 'public BicubicSplineFunction ( double [ ] coeff ,', '} else {', 'for ( int j = 0 ; j < N ; j + + ) {', 'final double [ ] [ ] aYY = new double [ N ] [ N ] ;', 'partialDerivativeXX = new BivariateFunction ( ) {', 'for ( int i = 0 ; i < lastI ; i + + ) {', '}', 'final double [ ] [ ] aXY = new double [ N ] [ N ] ;', 'final BicubicSplineFunction bcs = splines [ i ] [ j ] ;', 'final double [ ] pX = { 0 , 0 , 1 , x } ;', 'final double [ ] pY = { 0 , 0 , 1 , y } ;', 'return apply ( pX , pY , aXY ) ;', 'return apply ( pX , pY , aY ) ;', 'dFdX , dFdY , d2FdXdY ,', 'public double value ( double x , double y ) {', 'partialDerivatives [ 0 ] [ i ] [ j ] = bcs . partialDerivativeX ( ) ;', 'partialDerivatives [ 3 ] [ i ] [ j ] = bcs . partialDerivativeYY ( ) ;', 'final double c = a [ i ] [ j ] ;', 'partialDerivatives [ 1 ] [ i ] [ j ] = bcs . partialDerivativeY ( ) ;', 'partialDerivatives = null ;', 'public BicubicSplineInterpolatingFunction ( double [ ] x ,', 'aYY [ i ] [ j ] = ( j - 1 ) * aY [ i ] [ j ] ;', 'for ( int j = 0 ; j < lastJ ; j + + ) {', 'final double [ ] pY = { 1 , y , y2 , y3 } ;', 'final double x3 = x2 * x ;', 'partialDerivativeY = null ;', 'this ( false ) ;', 'final double [ ] pY = { 0 , 1 , y , y2 } ;', 'final double [ ] pX = { 0 , 1 , x , x2 } ;', 'double [ ] [ ] dFdY ,', 'final double [ ] [ ] aX = new double [ N ] [ N ] ;', 'double [ ] [ ] dFdX ,', 'this ( coeff , false ) ;', 'partialDerivativeYY = new BivariateFunction ( ) {', 'private final boolean initializeDerivatives ;', 'return apply ( pX , pY , aYY ) ;', 'final double y2 = y * y ;', 'NonMonotonicSequenceException {', '} ;', 'double [ ] [ ] d2FdXdY ,', 'partialDerivatives = new BivariateFunction [ 5 ] [ lastI ] [ lastJ ] ;', 'final BicubicSplineInterpolator bsi = new BicubicSplineInterpolator ( true ) ;', 'partialDerivativeXY = null ;', 'NoDataException ,', 'splines [ i ] [ j ] = new BicubicSplineFunction ( computeSplineCoefficients ( beta ) ,', 'partialDerivativeYY = null ;', 'final double y3 = y2 * y ;', 'throws DimensionMismatchException ,', 'return apply ( pX , pY , aX ) ;', 'this ( x , y , f , dFdX , dFdY , d2FdXdY , false ) ;', 'partialDerivatives [ 4 ] [ i ] [ j ] = bcs . partialDerivativeXY ( ) ;', 'aXX [ i ] [ j ] = ( i - 1 ) * aX [ i ] [ j ] ;', 'boolean initializeDerivatives ) {', 'partialDerivativeXY = new BivariateFunction ( ) {', 'for ( int i = 0 ; i < N ; i + + ) {', 'initializeDerivatives ) ;', 'partialDerivativeXX = null ;', 'aY [ i ] [ j ] = j * c ;', 'partialDerivativeX = new BivariateFunction ( ) {', 'final double [ ] [ ] aY = new double [ N ] [ N ] ;', 'boolean initializeDerivatives )', 'public BicubicSplineInterpolator ( ) {', 'if ( initializeDerivatives ) {', 'partialDerivatives [ 2 ] [ i ] [ j ] = bcs . partialDerivativeXX ( ) ;', 'final double x2 = x * x ;', 'partialDerivativeY = new BivariateFunction ( ) {', 'double [ ] y ,', 'return apply ( pX , pY , aXX ) ;', 'public BicubicSplineInterpolator ( boolean initializeDerivatives ) {', 'final double [ ] pX = { 1 , x , x2 , x3 } ;', 'aXY [ i ] [ j ] = j * aX [ i ] [ j ] ;', 'aX [ i ] [ j ] = i * c ;', 'final double [ ] [ ] aXX = new double [ N ] [ N ] ;'}, 'removed_code': {'final double [ ] pX = { 0 , 0 , 1 , x } ;', 'for ( int j = 0 ; j < N ; j + + ) {', 'final double [ ] [ ] aYY = new double [ N ] [ N ] ;', 'partialDerivativeXX = new BivariateFunction ( ) {', 'for ( int i = 0 ; i < lastI ; i + + ) {', '}', 'final double [ ] [ ] aXY = new double [ N ] [ N ] ;', 'final BicubicSplineFunction bcs = splines [ i ] [ j ] ;', 'final double [ ] pY = { 0 , 0 , 1 , y } ;', 'return apply ( pX , pY , aXY ) ;', 'return apply ( pX , pY , aY ) ;', 'public double value ( double x , double y ) {', 'partialDerivatives [ 0 ] [ i ] [ j ] = bcs . partialDerivativeX ( ) ;', 'partialDerivatives [ 3 ] [ i ] [ j ] = bcs . partialDerivativeYY ( ) ;', 'dFdX , dFdY , d2FdXdY ) ;', 'final double c = a [ i ] [ j ] ;', 'partialDerivatives [ 1 ] [ i ] [ j ] = bcs . partialDerivativeY ( ) ;', 'for ( int j = 0 ; j < lastJ ; j + + ) {', 'aYY [ i ] [ j ] = ( j - 1 ) * aY [ i ] [ j ] ;', 'final double [ ] pY = { 1 , y , y2 , y3 } ;', 'final double x3 = x2 * x ;', 'final BicubicSplineInterpolator bsi = new BicubicSplineInterpolator ( ) ;', 'final double [ ] pY = { 0 , 1 , y , y2 } ;', 'final double [ ] pX = { 0 , 1 , x , x2 } ;', 'final double [ ] [ ] aX = new double [ N ] [ N ] ;', 'partialDerivativeYY = new BivariateFunction ( ) {', 'return apply ( pX , pY , aYY ) ;', 'final double y2 = y * y ;', '} ;', 'partialDerivatives = new BivariateFunction [ 5 ] [ lastI ] [ lastJ ] ;', 'final double y3 = y2 * y ;', 'return apply ( pX , pY , aX ) ;', 'splines [ i ] [ j ] = new BicubicSplineFunction ( computeSplineCoefficients ( beta ) ) ;', 'partialDerivatives [ 4 ] [ i ] [ j ] = bcs . partialDerivativeXY ( ) ;', 'aXX [ i ] [ j ] = ( i - 1 ) * aX [ i ] [ j ] ;', 'partialDerivativeXY = new BivariateFunction ( ) {', 'for ( int i = 0 ; i < N ; i + + ) {', 'aY [ i ] [ j ] = j * c ;', 'partialDerivativeX = new BivariateFunction ( ) {', 'final double [ ] [ ] aY = new double [ N ] [ N ] ;', 'partialDerivatives [ 2 ] [ i ] [ j ] = bcs . partialDerivativeXX ( ) ;', 'final double x2 = x * x ;', 'partialDerivativeY = new BivariateFunction ( ) {', 'return apply ( pX , pY , aXX ) ;', 'final double [ ] pX = { 1 , x , x2 , x3 } ;', 'aXY [ i ] [ j ] = j * aX [ i ] [ j ] ;', 'aX [ i ] [ j ] = i * c ;', 'final double [ ] [ ] aXX = new double [ N ] [ N ] ;'}}"
efa48b214d30537bb184884ea30ce817bb350153,1.0,"PARQUET - 382 : Add methods to append encoded data to files . This allows appending encoded data blocks to open ParquetFileWriters , which makes it possible to merge multiple Parquet files without re - encoding all of the records . This works by finding the column chunk for each column in the file schema and then streaming the encoded data from one file to the other . New starting offsets are tracked and the column chunk metadata in the footer is updated with the new starting positions . Author : Ryan Blue < blue @ apache . org > Closes #278 from rdblue / PARQUET - 382 - append - encoded - blocks and squashes the following commits : cb98552 [ Ryan Blue ] PARQUET - 382 : Add methods to append encoded data to files .","{'added_code': {'if ( DEBUG ) LOG . debug (', 'List < BlockMetaData > rowGroups ,', 'private static void copy ( FSDataInputStream from , FSDataOutputStream to ,', 'long length = 0 ;', 'if ( !dropColumns & & !columnsToCopy . isEmpty ( ) ) {', '""Columns cannot be copied ( missing from target schema ) : % s"" ,', 'List < ColumnChunkMetaData > columnsInOrder =', 'newChunkStart ,', '""Copying "" + length + "" bytes at "" + start + "" to "" + to . getPos ( ) ) ;', 'chunk . getTotalUncompressedSize ( ) ) ) ;', 'ParquetFileReader . open ( conf , file ) . appendTo ( this ) ;', 'chunk . getEncodings ( ) ,', 'appendRowGroup ( file , block , dropColumns ) ;', 'chunk . getCodec ( ) ,', 'public void appendRowGroups ( FSDataInputStream file ,', 'throw new IllegalArgumentException (', 'private static final ThreadLocal < byte [ ] > COPY BUFFER =', 'if ( ( i + 1 ) = = columnsInOrder . size ( ) | |', '""Missing column \' % s\' , cannot copy row group : % s"" , path , rowGroup ) ) ;', 'String path = ColumnPath . get ( descriptor . getPath ( ) ) . toDotString ( ) ;', 'private long currentChunkDictionaryPageOffset ;', 'private ColumnPath currentChunkPath ;', 'new ThreadLocal < byte [ ] > ( ) {', 'private Set < Encoding > currentEncodings ;', 'chunk . getPath ( ) ,', 'chunk . getStatistics ( ) ,', 'length = 0 ;', 'columnsToCopy . put ( chunk . getPath ( ) . toDotString ( ) , chunk ) ;', 'private long currentChunkValueCount ;', 'for ( ColumnDescriptor descriptor : schema . getColumns ( ) ) {', 'long bytesLeft = length - bytesCopied ;', '""Unexpected end of input file at "" + start + bytesCopied ) ;', 'protected byte [ ] initialValue ( ) {', 'currentBlock . setTotalByteSize ( blockCompressedSize ) ;', 'if ( start < 0 ) {', 'if ( bytesRead < 0 ) {', 'chunk . getValueCount ( ) ,', 'startBlock ( rowGroup . getRowCount ( ) ) ;', 'import org . apache . hadoop . fs . FSDataInputStream ;', 'length + = chunk . getTotalSize ( ) ;', 'endBlock ( ) ;', 'currentBlock . addColumn ( ColumnChunkMetaData . get (', 'import org . apache . parquet . Strings ;', '} else {', 'while ( bytesCopied < length ) {', 'private Statistics currentStatistics ;', 'for ( int i = 0 ; i < columnsInOrder . size ( ) ; i + = 1 ) {', '( buffer . length < bytesLeft ? buffer . length : ( int ) bytesLeft ) ) ;', 'if ( chunk ! = null ) {', 'copy ( from , out , start , length ) ;', 'long newChunkStart = out . getPos ( ) + length ;', 'return new byte [ 8192 ] ;', 'throw new IllegalArgumentException ( String . format (', 'private BlockMetaData currentBlock ;', 'private long currentRecordCount ;', '} ;', 'long start = - 1 ;', '@ Override', 'chunk . getTotalSize ( ) ,', 'byte [ ] buffer = COPY BUFFER . get ( ) ;', 'private CompressionCodecName currentChunkCodec ;', 'start = chunk . getStartingPos ( ) ;', 'ColumnChunkMetaData chunk = columnsInOrder . get ( i ) ;', 'private PrimitiveTypeName currentChunkType ;', 'start = - 1 ;', 'long bytesCopied = 0 ;', 'new HashMap < String , ColumnChunkMetaData > ( ) ;', 'public void appendFile ( Configuration conf , Path file ) throws IOException {', 'import java . io . OutputStream ;', 'long blockCompressedSize = 0 ;', 'Map < String , ColumnChunkMetaData > columnsToCopy =', '}', 'chunk . getType ( ) ,', 'bytesCopied + = bytesRead ;', 'columnsInOrder . add ( chunk ) ;', 'for ( ColumnChunkMetaData chunk : rowGroup . getColumns ( ) ) {', 'new ArrayList < ColumnChunkMetaData > ( ) ;', 'from . seek ( start ) ;', 'int bytesRead = from . read ( buffer , 0 ,', 'private long currentChunkFirstDataPage ;', 'to . write ( buffer , 0 , bytesRead ) ;', 'Strings . join ( columnsToCopy . keySet ( ) , "" , "" ) ) ) ;', 'blockCompressedSize + = chunk . getTotalSize ( ) ;', 'ColumnChunkMetaData chunk = columnsToCopy . remove ( path ) ;', 'long start , long length ) throws IOException {', 'boolean dropColumns ) throws IOException {', 'columnsInOrder . get ( i + 1 ) . getStartingPos ( ) ! = ( start + length ) ) {', 'for ( BlockMetaData block : rowGroups ) {', 'public void appendRowGroup ( FSDataInputStream from , BlockMetaData rowGroup ,'}, 'removed_code': {'private Set < Encoding > currentEncodings ;', 'private CompressionCodecName currentChunkCodec ;', 'private long currentChunkDictionaryPageOffset ;', 'private PrimitiveTypeName currentChunkType ;', 'private long currentChunkFirstDataPage ;', 'private Statistics currentStatistics ;', 'private BlockMetaData currentBlock ;', 'private ColumnPath currentChunkPath ;', 'private long currentRecordCount ;', 'private long currentChunkValueCount ;'}}"
01fd9c792b8a2f3a7206d43c21d34de8135eaf6e,1.0,VALIDATOR - 380 UrlValidator does not allow for optional port digits,"{'added_code': {'if ( authority . contains ( "" : "" ) ) {', 'if ( !"""" . equals ( authority ) ) {', '"" ( ? : \\ \\ [ ( "" + IPV6 REGEX + "" ) \\ \\ ] | ( ? : ( ? : "" + USERINFO FIELD REGEX + "" ) ? ( [ "" + AUTHORITY CHARS REGEX + "" ] * ) ) ) ( : \\ \\ d * ) ? ( . * ) ? "" ;', '} else {', '}', 'return false ;', 'private static final int PARSE AUTHORITY HOST IP = 2 ;', 'if ( ""file"" . equals ( scheme ) ) {'}, 'removed_code': {'private static final Pattern PORT PATTERN = Pattern . compile ( PORT REGEX ) ;', '"" ^ ( ? : \\ \\ [ ( "" + IPV6 REGEX + "" ) \\ \\ ] | ( ? : ( ? : "" + USERINFO FIELD REGEX + "" ) ? ( [ "" + AUTHORITY CHARS REGEX + "" ] * ) ) ) ( : \\ \\ d * ) ? ( . * ) ? "" ;', 'if ( port ! = null & & !PORT PATTERN . matcher ( port ) . matches ( ) ) {', 'if ( ""file"" . equals ( scheme ) & & """" . equals ( authority ) ) {', '} else {', '}', 'return false ;', 'String port = authorityMatcher . group ( PARSE AUTHORITY PORT ) ;', 'private static final int PARSE AUTHORITY HOST IP = 2 ;', 'private static final int PARSE AUTHORITY PORT = 3 ;', 'private static final String PORT REGEX = "" ^ : ( \\ \\ d { 1 , 5 } ) $"" ;'}}"
e5a21c4bb27055cad85f1d9dd494867c0fae8c22,1.0,GIRAPH - 755 : Make ZooKeeper port list available to input / output format ( armax00 via claudio ),"{'added_code': {'ZOOKEEPER IS EXTERNAL . set ( this , false ) ;', 'public boolean isZookeeperExternal ( ) {', '}', 'set ( ZOOKEEPER LIST , zkList ) ;', 'return ZOOKEEPER IS EXTERNAL . get ( this ) ;', 'public void setZookeeperList ( String zkList ) {'}, 'removed_code': set()}"
dcdfd7ed9e8c34637a54e52ffe1eae6692d05e01,1.0,Change private least square problem implementation to internal class .,"{'added_code': {'public RealVector getPoint ( ) {', 'value . getSecond ( ) ,', 'private UnweightedEvaluation ( final RealVector values ,', 'final int maxEvaluations ,', 'public RealMatrix getJacobian ( ) {', 'extends AbstractOptimizationProblem < Evaluation >', '}', 'super ( maxEvaluations , maxIterations , checker ) ;', 'super ( target . getDimension ( ) ) ;', 'this . start = start ;', 'this . model = model ;', 'public RealVector getValue ( ) {', 'final ConvergenceChecker < Evaluation > checker ,', 'private static class UnweightedEvaluation extends AbstractEvaluation {', 'this . jacobian = jacobian ;', 'this . values = values ;', 'this . target = target ;', 'return this . point ;', 'return target . getDimension ( ) ;', 'import org . apache . commons . math3 . optim . AbstractOptimizationProblem ;', 'private RealVector start ;', 'return target . subtract ( this . getValue ( ) ) ;', 'final RealVector target ,', 'final RealVector point ) {', 'private MultivariateJacobianFunction model ;', 'return this . values ;', 'private final RealMatrix jacobian ;', 'this . point = point ;', 'private final RealVector target ;', 'this . target ,', 'private final RealVector values ;', 'return new LocalLeastSquaresProblem (', 'final RealMatrix jacobian ,', 'public Evaluation evaluate ( final RealVector point ) {', 'return this . jacobian ;', 'private final RealVector point ;', 'point ) ;', 'implements LeastSquaresProblem {', 'public RealVector getStart ( ) {', 'private static class LocalLeastSquaresProblem', 'private RealVector target ;', 'return new UnweightedEvaluation (', 'final Pair < RealVector , RealMatrix > value = this . model . value ( point ) ;', 'public RealVector getResiduals ( ) {', 'public int getParameterSize ( ) {', 'return start = = null ? null : start . copy ( ) ;', 'value . getFirst ( ) ,', 'final RealVector start ,', 'return start . getDimension ( ) ;', 'final int maxIterations ) {', 'LocalLeastSquaresProblem ( final MultivariateJacobianFunction model ,', 'public int getObservationSize ( ) {'}, 'removed_code': {'return new LeastSquaresProblemImpl ('}}"
cb04562742688f8a444a52c90b2183c4be528be6,1.0,"PARQUET - 248 : Add ParquetWriter . Builder . This refactors the builder recently added to parquet - avro so that it can be used by all object models . The Builder class is abstract and implementations should extend it . This changes the API slightly from AvroParquetWriter , renaming withBlockSize to withRowGroupSize . The Avro builder has not been released so this isn't a breaking change . Author : Ryan Blue < blue @ apache . org > Closes #199 from rdblue / PARQUET - 248 - add - parquet - writer - builder and squashes the following commits : a1a25ee [ Ryan Blue ] PARQUET - 248 : Add write mode and max padding to writer builder . 622af4c [ Ryan Blue ] PARQUET - 248 : Add ParquetWriter . Builder .","{'added_code': {'@ Deprecated', 'CodecFactory . BytesCompressor compressor = codecFactory . getCompressor ( compressionCodecName , 0 ) ;', 'pageSize ,', 'this . writerVersion = version ;', 'enableDictionary ,', 'this . mode = mode ;', 'public SELF withPageSize ( int pageSize ) {', 'writeSupport ,', 'boolean validating ,', 'int maxPaddingSize ) throws IOException {', 'public SELF enableDictionaryEncoding ( ) {', 'private WriterVersion writerVersion = DEFAULT WRITER VERSION ;', 'ParquetFileWriter fileWriter = new ParquetFileWriter (', 'return self ( ) ;', 'private boolean enableDictionary = DEFAULT IS DICTIONARY ENABLED ;', 'public SELF withMaxPaddingSize ( int maxPaddingSize ) {', 'WriteSupport . WriteContext writeContext = writeSupport . init ( conf ) ;', 'this . rowGroupSize = rowGroupSize ;', 'private int pageSize = DEFAULT PAGE SIZE ;', 'ParquetWriter (', 'dictionaryPageSize ,', 'conf , schema , file , mode , blockSize , maxPaddingSize ) ;', 'public SELF enableValidation ( ) {', 'compressor ,', 'public SELF withWriteMode ( ParquetFileWriter . Mode mode ) {', 'int blockSize ,', 'this . codecName = codecName ;', 'private Configuration conf = new Configuration ( ) ;', 'this . file = file ;', 'rowGroupSize , pageSize , dictionaryPageSize , enableDictionary ,', 'protected abstract WriteSupport < T > getWriteSupport ( Configuration conf ) ;', 'private boolean enableValidation = DEFAULT IS VALIDATING ENABLED ;', 'this . pageSize = pageSize ;', 'CompressionCodecName compressionCodecName ,', 'this . dictionaryPageSize = dictionaryPageSize ;', 'Path file ,', 'boolean enableDictionary ,', 'this . enableValidation = true ;', 'WriteSupport < T > writeSupport ,', 'int dictionaryPageSize ,', 'return new ParquetWriter < T > ( file , mode , getWriteSupport ( conf ) , codecName ,', 'WriterVersion writerVersion ,', 'schema ,', 'protected Builder ( Path file ) {', 'this . maxPaddingSize = maxPaddingSize ;', 'enableValidation , writerVersion , conf , maxPaddingSize ) ;', 'validating ,', 'this ( file , mode , writeSupport , compressionCodecName , blockSize , pageSize ,', 'this . conf = conf ;', 'public SELF withCompressionCodec ( CompressionCodecName codecName ) {', 'private ParquetFileWriter . Mode mode ;', 'this . enableValidation = enableValidation ;', 'CodecFactory codecFactory = new CodecFactory ( conf ) ;', 'this . writer = new InternalParquetRecordWriter < T > (', 'MAX PADDING SIZE DEFAULT ) ;', 'fileWriter ,', 'this . enableDictionary = enableDictionary ;', 'private CompressionCodecName codecName = DEFAULT COMPRESSION CODEC NAME ;', 'public SELF withDictionaryPageSize ( int dictionaryPageSize ) {', 'int pageSize ,', 'public SELF withRowGroupSize ( int rowGroupSize ) {', 'private int dictionaryPageSize = DEFAULT PAGE SIZE ;', 'public SELF withValidation ( boolean enableValidation ) {', '}', 'writeContext . getExtraMetaData ( ) ,', 'public SELF withWriterVersion ( WriterVersion version ) {', 'private int rowGroupSize = DEFAULT BLOCK SIZE ;', 'ParquetFileWriter . Mode mode ,', 'fileWriter . start ( ) ;', 'writerVersion ) ;', 'private final Path file ;', 'public SELF withDictionaryEncoding ( boolean enableDictionary ) {', 'blockSize ,', 'MessageType schema = writeContext . getSchema ( ) ;', 'public SELF withConf ( Configuration conf ) {', 'public abstract static class Builder < T , SELF extends Builder < T , SELF > > {', 'Configuration conf ,', 'public ParquetWriter < T > build ( ) throws IOException {', 'dictionaryPageSize , enableDictionary , validating , writerVersion , conf ,', 'protected abstract SELF self ( ) ;', 'private int maxPaddingSize = MAX PADDING SIZE DEFAULT ;', 'this . enableDictionary = true ;'}, 'removed_code': {'compressor ,', 'CodecFactory . BytesCompressor compressor = codecFactory . getCompressor ( compressionCodecName , 0 ) ;', 'pageSize ,', 'writeContext . getExtraMetaData ( ) ,', 'ParquetFileWriter fileWriter = new ParquetFileWriter ( conf , schema , file ,', 'enableDictionary ,', 'mode , blockSize , MAX PADDING SIZE DEFAULT ) ;', 'writeSupport ,', 'fileWriter . start ( ) ;', 'writerVersion ) ;', 'blockSize ,', 'MessageType schema = writeContext . getSchema ( ) ;', 'CodecFactory codecFactory = new CodecFactory ( conf ) ;', 'this . writer = new InternalParquetRecordWriter < T > (', 'fileWriter ,', 'schema ,', 'WriteSupport . WriteContext writeContext = writeSupport . init ( conf ) ;', 'dictionaryPageSize ,', 'validating ,'}}"
e650290f85e431f59ba3e11953fbd1afdd16687a,1.0,JCS - 130 : Simplify RemoteCacheFactory & friends . Get rid of criss - cross static calls,"{'added_code': {'managers . put ( cattr . getRemoteLocation ( ) , ins ) ;', 'private Lock managerLock ;', 'RemoteCacheManager ins = getManager ( cattr ) ;', 'RemoteCacheNoWait < K , V > rcnw = ( RemoteCacheNoWait < K , V > ) nw ;', 'private RemoteCacheMonitor monitor ;', 'ins = managers . get ( cattr . getRemoteLocation ( ) ) ;', 'public RemoteCacheManager getManager ( IRemoteCacheAttributes cattr , ICompositeCacheManager cacheMgr ,', '( ( RemoteCache < K , V > ) rcnw . getRemoteCache ( ) ) . setFacade ( this ) ;', 'private ConcurrentMap < RemoteLocation , RemoteCacheManager > managers ;', 'this . noWaits . add ( rcnw ) ;', 'public RemoteCacheManager getManager ( IRemoteCacheAttributes cattr )', 'new RemoteCacheNoWaitFacade < K , V > ( noWaits , rca , cacheMgr , cacheEventLogger , elementSerializer , this ) ;'}, 'removed_code': {'this . noWaits . add ( ( RemoteCacheNoWait < K , V > ) nw ) ;', 'public static < K , V > RemoteCacheNoWaitFacade < K , V > getFacade ( String cacheName )', 'new RemoteCacheNoWaitFacade < K , V > ( noWaits , rca , cacheMgr , cacheEventLogger , elementSerializer ) ;', '}', 'facades . put ( rca . getCacheName ( ) , rcnwf ) ;', 'public static RemoteCacheManager getManager ( IRemoteCacheAttributes cattr , ICompositeCacheManager cacheMgr ,', 'RemoteCacheManager ins = managers . get ( loc ) ;', 'private static ConcurrentMap < String , RemoteCacheNoWaitFacade < ? , ? > > facades ;', 'if ( cattr . getRemoteLocation ( ) = = null )', 'managers . put ( loc , ins ) ;', 'ins = managers . get ( loc ) ;', 'private static RemoteCacheMonitor monitor ;', 'private static ConcurrentMap < RemoteLocation , RemoteCacheManager > managers ;', 'return ( RemoteCacheNoWaitFacade < K , V > ) facades . get ( cacheName ) ;', 'facades = new ConcurrentHashMap < String , RemoteCacheNoWaitFacade < ? , ? > > ( ) ;', 'public static RemoteCacheManager getManager ( IRemoteCacheAttributes cattr )', 'private static Lock managerLock ;', 'cattr . setRemoteLocation ( """" , Registry . REGISTRY PORT ) ;', 'facades . clear ( ) ;', '{', '@ SuppressWarnings ( ""unchecked"" )', 'RemoteLocation loc = cattr . getRemoteLocation ( ) ;'}}"
9b6d6f9f6f91c5d6a8a153635f7e5f3c52a1f4f2,1.0,GIRAPH - 1065 : Allow extending JobProgressTrackerService Summary : We might want to perform additional actions on events from JobProgressTrackerService . Allow overriding it and specifying another class to use . Test Plan : Ran a job with custom JobProgressTrackerService and verify actions on it are called Differential Revision : https : / / reviews . facebook . net / D58383,"{'added_code': {'private static final int UPDATE MILLISECONDS = 10 * 1000 ;', 'mappersStarted + + ;', 'CombinedWorkerProgress combinedWorkerProgress =', 'import org . apache . hadoop . mapreduce . Job ;', 'return jobProgressTrackerService ;', 'this . job = job ;', 'if ( mappersStarted = = conf . getMaxWorkers ( ) + 1 ) {', 'import java . io . IOException ;', 'jobGotAllMappers ( ) ;', 'JobProgressTrackerService jobProgressTrackerService =', '""interrupted"" ) ;', 'private final Map < Integer , WorkerProgress > workerProgresses =', 'private Job job ;', 'import java . util . Map ;', 'GiraphConstants . JOB PROGRESS TRACKER CLASS . newInstance ( conf ) ;', 'writerThread . setDaemon ( true ) ;', 'writerThread . start ( ) ;', 'Thread . sleep ( maxAllowedJobTimeMs ) ;', 'LOG . error ( logLine ) ;', 'killThread . start ( ) ;', 'writerThread . interrupt ( ) ;', 'finished = true ;', 'LOG . info ( ""Got "" + mappersStarted + "" but needs "" +', '} catch ( IOException e ) {', 'if ( System . currentTimeMillis ( ) - lastTimeMappersStartedLogged >', 'new ConcurrentHashMap < > ( ) ;', 'GiraphConfiguration conf , GiraphJobObserver jobObserver ) {', 'public void logInfo ( String logLine ) {', 'public class DefaultJobProgressTrackerService', 'if ( maxAllowedJobTimeMs > 0 ) {', 'LOG . debug ( ""Thread checking for jobs max allowed time "" +', 'LOG . info ( logLine ) ;', 'private GiraphConfiguration conf ;', 'private static final Logger LOG =', 'LOG . warn ( ""Failed to kill job"" , e ) ;', 'public void updateProgress ( WorkerProgress workerProgress ) {', '!workerProgresses . isEmpty ( ) ) {', 'private void jobGotAllMappers ( ) {', 'public void setJob ( Job job ) {', 'private volatile boolean finished = false ;', 'public void logFailure ( String reason ) {', 'private GiraphJobObserver jobObserver ;', 'private int mappersStarted ;', 'final long maxAllowedJobTimeMs =', 'if ( LOG . isDebugEnabled ( ) ) {', 'this . conf = conf ;', 'new CombinedWorkerProgress ( workerProgresses . values ( ) , conf ) ;', 'LOG . warn ( ""Killing job because it took longer than "" +', '} else {', 'LOG . fatal ( reason ) ;', 'public static JobProgressTrackerService createJobProgressTrackerService (', 'Logger . getLogger ( JobProgressTrackerService . class ) ;', 'implements JobProgressTrackerService {', 'private void startWriterThread ( ) {', 'killThread . setDaemon ( true ) ;', 'import java . util . concurrent . ConcurrentHashMap ;', 'private Thread writerThread ;', 'jobProgressTrackerService . init ( conf , jobObserver ) ;', 'public void logError ( String logLine ) {', 'startWriterThread ( ) ;', 'try {', 'maxAllowedJobTimeMs + "" milliseconds"" ) ;', '@ Override', 'LOG . info ( ""Progress thread interrupted"" ) ;', 'if ( !conf . trackJobProgressOnClient ( ) ) {', 'public void init ( GiraphConfiguration conf , GiraphJobObserver jobObserver ) {', 'LOG . info ( combinedWorkerProgress . toString ( ) ) ;', 'public synchronized void mapperStarted ( ) {', 'Thread killThread = new Thread ( new Runnable ( ) {', 'writerThread = new Thread ( new Runnable ( ) {', 'import org . apache . giraph . conf . GiraphConfiguration ;', 'import org . apache . giraph . worker . WorkerProgress ;', 'LOG . info ( ""Job "" + ( succeeded ? ""finished successfully"" : ""failed"" ) +', 'private long lastTimeMappersStartedLogged ;', '}', 'LOG . info ( ""Got all "" + mappersStarted + "" mappers"" ) ;', 'Thread . sleep ( UPDATE MILLISECONDS ) ;', '} catch ( InterruptedException e ) {', 'GiraphConstants . MAX ALLOWED JOB TIME MS . get ( conf ) ;', 'break ;', 'public void run ( ) {', 'if ( combinedWorkerProgress . isDone ( conf . getMaxWorkers ( ) ) ) {', 'package org . apache . giraph . job ;', 'lastTimeMappersStartedLogged = System . currentTimeMillis ( ) ;', 'import org . apache . giraph . conf . GiraphConstants ;', 'job . killJob ( ) ;', 'LOG . info ( ""Waiting for job to start . . . ( this may take a minute ) "" ) ;', 'this . jobObserver = jobObserver ;', 'workerProgresses . put ( workerProgress . getTaskId ( ) , workerProgress ) ;', 'jobObserver . jobGotAllMappers ( job ) ;', 'if ( mappersStarted = = conf . getMaxWorkers ( ) + 1 & &', 'UPDATE MILLISECONDS ) {', '( conf . getMaxWorkers ( ) + 1 ) + "" mappers"" ) ;', 'return null ;', '} ) ;', '"" , cleaning up . . . "" ) ;', 'if ( LOG . isInfoEnabled ( ) ) {', 'public void stop ( boolean succeeded ) {', 'import org . apache . log4j . Logger ;', 'while ( !finished ) {'}, 'removed_code': set()}"
f965bc23bc9f12748b6693424f829b6b08c8a71b,1.0,[ COMPRESS - 368 ] Allow compressor extensions through a standard JRE ServiceLoader .,"{'added_code': {'. unmodifiableSortedMap ( findAvailableCompressorInputStreamProviders ( ) ) ;', 'TreeMap < String , CompressorStreamProvider > map ) {', 'return new ServiceLoaderIterator < > ( CompressorStreamProvider . class ) ;', 'public static String getSnappyRaw ( ) {', 'private SortedMap < String , CompressorStreamProvider > compressorOutputStreamProviders ;', 'public static String getXz ( ) {', 'private static Iterator < CompressorStreamProvider > serviceLoaderIterator ( ) {', 'public Set < String > getInputStreamCompressorNames ( ) {', 'return compressorOutputStreamProviders ;', 'import org . apache . commons . compress . compressors . xz . XZUtils ;', 'import org . apache . commons . compress . compressors . xz . XZCompressorOutputStream ;', 'public static String getDeflate ( ) {', 'public static String getLzma ( ) {', 'if ( compressorOutputStreamProviders = = null ) {', 'putAll ( SINGLETON . getInputStreamCompressorNames ( ) , SINGLETON , map ) ;', 'if ( compressorStreamProvider ! = null ) {', 'public static String getBzip2 ( ) {', 'return name . toUpperCase ( Locale . ROOT ) ;', 'import java . security . AccessController ;', 'putAll ( provider . getInputStreamCompressorNames ( ) , provider , map ) ;', 'public SortedMap < String , CompressorStreamProvider > getCompressorOutputStreamProviders ( ) {', 'compressorOutputStreamProviders = Collections', 'throw new IllegalArgumentException ( ""Compressor name and stream must not be null . "" ) ;', 'compressorInputStreamProviders = Collections', 'TreeMap < String , CompressorStreamProvider > map = new TreeMap < > ( ) ;', 'return map ;', 'import java . util . Set ;', 'return decompressUntilEOF ;', 'return BZIP2 ;', 'private static String toKey ( final String name ) {', 'for ( CompressorStreamProvider provider : findCompressorStreamProviders ( ) ) {', 'return AccessController . doPrivileged ( new PrivilegedAction < SortedMap < String , CompressorStreamProvider > > ( ) {', 'static void putAll ( Set < String > names , CompressorStreamProvider provider ,', 'HashSet < String > set = new HashSet < > ( ) ;', 'public CompressorInputStream createCompressorInputStream ( final InputStream in ) throws CompressorException {', 'public SortedMap < String , CompressorStreamProvider > getCompressorInputStreamProviders ( ) {', 'import java . util . ArrayList ;', 'return XZ ;', 'throws CompressorException {', 'return PACK200 ;', 'public CompressorOutputStream createCompressorOutputStream ( final String name , final OutputStream out )', 'Collections . addAll ( set , GZIP , BZIP2 , XZ , LZMA , PACK200 , SNAPPY RAW , SNAPPY FRAMED , Z , DEFLATE ) ;', 'final CompressorStreamProvider compressorStreamProvider = getCompressorInputStreamProviders ( ) . get ( toKey ( name ) ) ;', 'throw new CompressorException ( ""Could not create CompressorOutputStream"" , e ) ;', 'return Z ;', 'public static String getGzip ( ) {', 'final CompressorStreamProvider compressorStreamProvider = getCompressorOutputStreamProviders ( ) . get ( toKey ( name ) ) ;', 'private static ArrayList < CompressorStreamProvider > findCompressorStreamProviders ( ) {', 'return SNAPPY FRAMED ;', 'Collections . addAll ( set , GZIP , BZIP2 , XZ , PACK200 , DEFLATE ) ;', 'import java . util . Collections ;', 'return LZMA ;', 'import java . util . TreeMap ;', 'return GZIP ;', 'return Lists . newArrayList ( serviceLoaderIterator ( ) ) ;', 'return compressorStreamProvider . createCompressorOutputStream ( name , out ) ;', 'public CompressorInputStream createCompressorInputStream ( final String name , final InputStream in )', 'public static SortedMap < String , CompressorStreamProvider > findAvailableCompressorOutputStreamProviders ( ) {', 'return set ;', 'return compressorInputStreamProviders ;', 'if ( LZMAUtils . matches ( signature , signatureLength ) & & LZMAUtils . isLZMACompressionAvailable ( ) ) {', 'import java . util . SortedMap ;', '@ Override', 'import java . util . Locale ;', 'public static SortedMap < String , CompressorStreamProvider > findAvailableCompressorInputStreamProviders ( ) {', 'import java . util . Iterator ;', 'throw new CompressorException ( ""Could not create CompressorInputStream . "" , e ) ;', 'import org . apache . commons . compress . utils . Lists ;', 'private static final CompressorStreamFactory SINGLETON = new CompressorStreamFactory ( ) ;', 'import java . security . PrivilegedAction ;', 'putAll ( SINGLETON . getOutputStreamCompressorNames ( ) , SINGLETON , map ) ;', 'if ( compressorInputStreamProviders = = null ) {', 'import org . apache . commons . compress . utils . ServiceLoaderIterator ;', '}', 'public static String getSnappyFramed ( ) {', 'public static CompressorStreamFactory getSingleton ( ) {', '. unmodifiableSortedMap ( findAvailableCompressorOutputStreamProviders ( ) ) ;', 'public Set < String > getOutputStreamCompressorNames ( ) {', 'import org . apache . commons . compress . compressors . xz . XZCompressorInputStream ;', 'return DEFLATE ;', 'public static String getPack200 ( ) {', 'return SINGLETON ;', 'public Boolean getDecompressUntilEOF ( ) {', 'putAll ( provider . getOutputStreamCompressorNames ( ) , provider , map ) ;', 'public class CompressorStreamFactory implements CompressorStreamProvider {', 'for ( String name : names ) {', 'map . put ( toKey ( name ) , provider ) ;', 'this . decompressUntilEOF = null ;', '} ) ;', 'public static String getZ ( ) {', 'if ( XZUtils . matches ( signature , signatureLength ) & & XZUtils . isXZCompressionAvailable ( ) ) {', 'return compressorStreamProvider . createCompressorInputStream ( name , in ) ;', 'public SortedMap < String , CompressorStreamProvider > run ( ) {', 'return SNAPPY RAW ;', 'private SortedMap < String , CompressorStreamProvider > compressorInputStreamProviders ;', 'import java . util . HashSet ;'}, 'removed_code': {'final String name , final OutputStream out )', 'public CompressorInputStream createCompressorInputStream ( final String name ,', 'LZMAUtils . isLZMACompressionAvailable ( ) ) {', '""Could not create CompressorOutputStream"" , e ) ;', '""Compressor name and stream must not be null . "" ) ;', 'public CompressorInputStream createCompressorInputStream ( final InputStream in )', 'import org . apache . commons . compress . compressors . xz . XZCompressorInputStream ;', 'import org . apache . commons . compress . compressors . xz . XZUtils ;', 'import org . apache . commons . compress . compressors . xz . XZCompressorOutputStream ;', 'throw new IllegalArgumentException (', 'throw new CompressorException (', 'if ( XZUtils . matches ( signature , signatureLength ) & &', 'public CompressorOutputStream createCompressorOutputStream (', 'this . decompressUntilEOF = null ;', 'if ( LZMAUtils . matches ( signature , signatureLength ) & &', 'throws CompressorException {', '""Could not create CompressorInputStream . "" , e ) ;', 'XZUtils . isXZCompressionAvailable ( ) ) {', 'final InputStream in ) throws CompressorException {', 'public class CompressorStreamFactory {'}}"
7cfbc0da48c8cc8939e97427d8ee5b22c5e55f28,1.0,Fixed error when splitting an arc close to its end . fixes : MATH - 1093,"{'added_code': {'if ( lEnd - lStart > FastMath . PI ) {', 'addArcLimit ( tree , limits . get ( i + 1 ) , false ) ;', 'minus . add ( minusToPlus ) ;', '} else {', 'plus . add ( plusToMinus ) ;', '}', 'final List < Double > plus = new ArrayList < Double > ( ) ;', 'minus . add ( a [ 0 ] ) ;', 'minus . add ( plusToMinus ) ;', 'limits . add ( limits . remove ( 0 ) + MathUtils . TWO PI ) ;', 'node . insertCut ( limit ) ;', 'final int j = ( i + 1 ) % limits . size ( ) ;', 'final double lA = limits . get ( i ) ;', 'BSPTree < Sphere1D > tree = new BSPTree < Sphere1D > ( Boolean . FALSE ) ;', 'if ( syncedStart < = arcLength - getTolerance ( ) | | syncedEnd > = MathUtils . TWO PI + getTolerance ( ) ) {', 'if ( syncedEnd > = arcLength + getTolerance ( ) ) {', 'final List < Double > minus = new ArrayList < Double > ( ) ;', 'if ( j > 0 ) {', 'limits . remove ( i ) ;', 'node . getPlus ( ) . setAttribute ( Boolean . FALSE ) ;', 'limits . remove ( j ) ;', 'final double lEnd = limits . remove ( limits . size ( ) - 1 ) ;', 'minus . add ( a [ 1 ] ) ;', 'private ArcsSet createSplitPart ( final List < Double > limits ) {', 'final double lB = MathUtils . normalizeAngle ( limits . get ( j ) , lA ) ;', 'if ( limits . isEmpty ( ) ) {', 'plus . add ( minusToPlus ) ;', 'return null ;', 'addArcLimit ( tree , limits . get ( i ) , true ) ;', 'final double lStart = limits . remove ( 0 ) ;', 'i = i - 1 ;', 'plus . add ( a [ 1 ] ) ;', 'if ( tree . getCut ( ) = = null ) {', 'node . setAttribute ( null ) ;', 'for ( int i = 0 ; i < limits . size ( ) - 1 ; i + = 2 ) {', 'for ( int i = 0 ; i < limits . size ( ) ; + + i ) {', 'node . getMinus ( ) . setAttribute ( Boolean . TRUE ) ;', 'throw new MathInternalError ( ) ;', 'return new ArcsSet ( new BSPTree < Sphere1D > ( Boolean . TRUE ) , getTolerance ( ) ) ;', 'if ( FastMath . abs ( lB - lA ) < = getTolerance ( ) ) {', 'plus . add ( a [ 0 ] ) ;'}, 'removed_code': {'plus . setAttribute ( Boolean . FALSE ) ;', 'if ( syncedStart < arcLength | | syncedEnd > MathUtils . TWO PI ) {', '} else {', 'if ( tree . getCut ( ) = = null & & ! ( Boolean ) tree . getAttribute ( ) ) {', 'private ArcsSet createSplitPart ( final BSPTree < Sphere1D > tree ) {', 'addArcLimit ( minus , a [ 1 ] , false ) ;', 'if ( syncedEnd > arcLength ) {', 'addArcLimit ( plus , a [ 1 ] , false ) ;', 'addArcLimit ( minus , a [ 0 ] , true ) ;', 'node . insertCut ( limit ) ;', 'leafBefore ( node ) . setAttribute ( Boolean . valueOf ( !isStart ) ) ;', 'addArcLimit ( plus , a [ 0 ] , true ) ;', 'final BSPTree < Sphere1D > minus = new BSPTree < Sphere1D > ( ) ;', 'addArcLimit ( plus , minusToPlus , true ) ;', 'minus . setAttribute ( Boolean . FALSE ) ;', 'node . getPlus ( ) . setAttribute ( Boolean . FALSE ) ;', 'addArcLimit ( minus , plusToMinus , true ) ;', 'final BSPTree < Sphere1D > plus = new BSPTree < Sphere1D > ( ) ;', 'node . setAttribute ( null ) ;', 'node . getMinus ( ) . setAttribute ( Boolean . TRUE ) ;', 'addArcLimit ( plus , plusToMinus , false ) ;', 'addArcLimit ( minus , minusToPlus , false ) ;'}}"
80fced6db6c15d7833e2c06fac4098640ff4c742,1.0,Attempt to fix JCS - 116 : CompositeCacheManager is thread - hostile,"{'added_code': {'String auxName , String regName )', 'cache = parseRegion ( props , ccm , regionName , auxiliaries ) ;', 'protected void parseRegions ( Properties props , CompositeCacheManager ccm )', 'if ( key . startsWith ( SYSTEM PROPERTY KEY PREFIX ) )', 'if ( ! ( auxiliaries . startsWith ( "" , "" ) | | auxiliaries . equals ( """" ) ) )', 'log . info ( ""Using system property [ [ "" + key + "" ] [ "" + sysProps . getProperty ( key ) + "" ] ] "" ) ;', 'eAttr = defaultEAttr ;', 'IElementAttributes ea = parseElementAttributes ( props , regName ,', 'log . debug ( ""Parsing region name \'"" + regName + ""\' , value \'"" + auxiliaries + ""\'"" ) ;', 'ccm . getDefaultElementAttributes ( ) , regionPrefix ) ;', 'if ( auxiliaries ! = null )', 'public CompositeCacheConfigurator ( )', '}', 'Properties props , CompositeCacheManager ccm , String regName , String auxiliaries ,', 'Properties props , CompositeCacheManager ccm , String regName , String auxiliaries )', '( ( IRequireScheduler ) auxCache ) . setScheduledExecutorService (', 'cache = parseRegion ( props , ccm , regionName , auxiliaries , null , SYSTEM REGION PREFIX ) ;', 'AuxiliaryCacheConfigurator . parseCacheEventLogger ( props , auxPrefix ) ;', 'protected static final String ELEMENT ATTRIBUTE PREFIX = "" . elementattributes"" ;', 'ccm . addAuxiliaryCache ( auxName , regName , auxCache ) ;', 'cache . setElementEventQueue ( ccm . getElementEventQueue ( ) ) ;', 'ccm . registryAttrPut ( auxAttr ) ;', 'protected < K , V > AuxiliaryCache < K , V > parseAuxiliary ( Properties props , CompositeCacheManager ccm ,', 'ccAttr = defaultCCAttr ;', 'AuxiliaryCacheConfigurator . parseElementSerializer ( props , auxPrefix ) ;', 'StringTokenizer st = new StringTokenizer ( auxiliaries , "" , "" ) ;', 'protected static final String SYSTEM PROPERTY KEY PREFIX = ""jcs"" ;', 'for ( String key : sysProps . stringPropertyNames ( ) )', 'protected void parseSystemRegions ( Properties props , CompositeCacheManager ccm )', 'ccm . registryFacPut ( auxFac ) ;', 'ICompositeCacheAttributes cca )', 'IElementAttributes defaultEAttr , String regionPrefix )', 'protected static final String REGION PREFIX = ""jcs . region . "" ;', 'protected static final String CACHE ATTRIBUTE PREFIX = "" . cacheattributes"" ;', '? new CompositeCache < K , V > ( parseCompositeCacheAttributes ( props , regName ,', 'if ( log . isInfoEnabled ( ) )', 'ICacheEventLogger cacheEventLogger =', 'AuxiliaryCacheFactory auxFac = ccm . registryFacGet ( auxName ) ;', 'protected IElementAttributes parseElementAttributes ( Properties props , String regName ,', 'protected static final String SYSTEM REGION PREFIX = ""jcs . system . "" ;', 'protected < K > IKeyMatcher < K > parseKeyMatcher ( Properties props , String auxPrefix )', 'AuxiliaryCacheAttributes auxAttr = ccm . registryAttrGet ( auxName ) ;', '( ( IRequireScheduler ) auxFac ) . setScheduledExecutorService ( ccm . getScheduledExecutorService ( ) ) ;', 'return parseCompositeCacheAttributes ( props , regName , defaultCCAttr , REGION PREFIX ) ;', 'props . setProperty ( key , sysProps . getProperty ( key ) ) ;', 'AuxiliaryCache < K , V > auxCache = ( AuxiliaryCache < K , V > ) ccm . getAuxiliaryCache ( auxName , regName ) ;', 'protected ICompositeCacheAttributes parseCompositeCacheAttributes ( Properties props ,', 'return parseRegion ( props , ccm , regName , auxiliaries , cca , REGION PREFIX ) ;', 'for ( String key : props . stringPropertyNames ( ) )', 'auxCache = auxFac . createCache ( auxAttr , ccm , cacheEventLogger , elementSerializer ) ;', 'auxCache = parseAuxiliary ( props , ccm , auxName , regName ) ;', 'ccm . getDefaultCacheAttributes ( ) , regionPrefix ) , ea )', 'String auxiliaries = OptionConverter . findAndSubst ( key , props ) ;', 'String regName , ICompositeCacheAttributes defaultCCAttr , String regionPrefix )', 'cache . setScheduledExecutorService ( ccm . getScheduledExecutorService ( ) ) ;', 'IElementSerializer elementSerializer =', 'ccm . addCache ( regionName , cache ) ;', 'protected static void overrideWithSystemProperties ( Properties props )', 'ccm . getScheduledExecutorService ( ) ) ;', '{', 'protected static final String ATTRIBUTE PREFIX = "" . attributes"" ;', 'protected static final String AUXILIARY PREFIX = ""jcs . auxiliary . "" ;', 'return parseRegion ( props , ccm , regName , auxiliaries , null , REGION PREFIX ) ;', 'String regName , ICompositeCacheAttributes defaultCCAttr )', 'Properties sysProps = System . getProperties ( ) ;'}, 'removed_code': {'protected void parseRegions ( Properties props )', 'cache = parseRegion ( props , regionName , auxiliaryList ) ;', 'IElementAttributes iea = parseElementAttributes ( props , """" , CompositeCacheConfigurator . DEFAULT REGION ) ;', 'CompositeCacheConfigurator . DEFAULT REGION ) ;', 'compositeCacheManager . getScheduledExecutorService ( ) ) ;', 'public CompositeCacheConfigurator ( CompositeCacheManager ccMgr )', 'compositeCacheManager . setConfigurationProperties ( properties ) ;', 'static final String CACHE ATTRIBUTE PREFIX = "" . cacheattributes"" ;', 'return ;', 'Properties props , String regName , String value )', 'import java . io . IOException ;', 'protected ICompositeCacheAttributes parseCompositeCacheAttributes ( Properties props , String regName )', 'setDefaultCompositeCacheAttributes ( properties ) ;', 'istream . close ( ) ;', 'protected void setDefaultAuxValues ( Properties props )', 'finally', 'try', 'static final String DEFAULT REGION = ""jcs . default"" ;', 'catch ( IOException e )', 'String value = OptionConverter . findAndSubst ( key , props ) ;', 'protected IElementAttributes parseElementAttributes ( Properties props , String regName , String regionPrefix )', 'props . load ( istream ) ;', 'compositeCacheManager . registryFacPut ( auxFac ) ;', 'IElementSerializer elementSerializer = AuxiliaryCacheConfigurator . parseElementSerializer ( props , auxPrefix ) ;', 'IElementAttributes ea = parseElementAttributes ( props , regName , regionPrefix ) ;', 'setDefaultAuxValues ( properties ) ;', 'ICacheEventLogger cacheEventLogger = AuxiliaryCacheConfigurator . parseCacheEventLogger ( props , auxPrefix ) ;', 'import java . util . Enumeration ;', 'return parseCompositeCacheAttributes ( props , regName , REGION PREFIX ) ;', 'return parseRegion ( props , regName , value , null , REGION PREFIX ) ;', 'parseRegions ( properties ) ;', 'cache = parseRegion ( props , regionName , value , null , SYSTEM REGION PREFIX ) ;', 'static final String AUXILIARY PREFIX = ""jcs . auxiliary . "" ;', 'ICompositeCacheAttributes ccAttr2 = compositeCacheManager . getDefaultCacheAttributes ( ) ;', 'if ( istream ! = null )', 'log . error ( ""Could not close configuration file "" + configFileName , e ) ;', 'public static < K > IKeyMatcher < K > parseKeyMatcher ( Properties props , String auxPrefix )', 'protected ICompositeCacheAttributes parseCompositeCacheAttributes ( Properties props , String regName ,', 'log . error ( ""Could not read configuration file , ignored : "" + configFileName , e ) ;', 'AuxiliaryCache < K , V > auxCache = ( AuxiliaryCache < K , V > ) compositeCacheManager . getAuxiliaryCache ( auxName , regName ) ;', '( ( IRequireScheduler ) auxCache ) . setScheduledExecutorService (', 'protected void setDefaultCompositeCacheAttributes ( Properties props )', 'ccAttr = ccAttr2 . clone ( ) ;', 'this . compositeCacheManager = ccMgr ;', 'if ( value ! = null )', 'FileInputStream istream = null ;', 'AuxiliaryCacheAttributes auxAttr = compositeCacheManager . registryAttrGet ( auxName ) ;', 'protected void doConfigure ( String configFileName )', '? new CompositeCache < K , V > ( parseCompositeCacheAttributes ( props , regName , regionPrefix ) , ea )', 'static final String ATTRIBUTE PREFIX = "" . attributes"" ;', 'auxCache = auxFac . createCache ( auxAttr , compositeCacheManager , cacheEventLogger , elementSerializer ) ;', 'protected void parseSystemRegions ( Properties props )', 'if ( ! ( value . startsWith ( "" , "" ) | | value . equals ( """" ) ) )', 'auxCache = parseAuxiliary ( props , auxName , regName ) ;', 'long start = System . currentTimeMillis ( ) ;', 'parseSystemRegions ( properties ) ;', 'import java . io . FileInputStream ;', 'compositeCacheManager . registryAttrPut ( auxAttr ) ;', 'log . info ( ""Setting default auxiliaries to "" + value ) ;', 'Enumeration < ? > en = props . propertyNames ( ) ;', 'static final String ELEMENT ATTRIBUTE PREFIX = "" . elementattributes"" ;', 'String key = ( String ) en . nextElement ( ) ;', 'return parseRegion ( props , regName , value , cca , REGION PREFIX ) ;', 'istream = new FileInputStream ( configFileName ) ;', '{', 'Properties props , String regName , String value , ICompositeCacheAttributes cca )', 'ICompositeCacheAttributes icca = parseCompositeCacheAttributes ( props , """" ,', 'log . debug ( ""Parsing region name \'"" + regName + ""\' , value \'"" + value + ""\'"" ) ;', 'String value = OptionConverter . findAndSubst ( DEFAULT REGION , props ) ;', 'Properties props = new Properties ( ) ;', 'IElementAttributes eAttr2 = compositeCacheManager . getDefaultElementAttributes ( ) ;', 'while ( en . hasMoreElements ( ) )', '( ( IRequireScheduler ) auxFac ) . setScheduledExecutorService ( compositeCacheManager . getScheduledExecutorService ( ) ) ;', 'log . info ( ""setting defaultCompositeCacheAttributes to "" + icca ) ;', 'String regionPrefix )', 'doConfigure ( props ) ;', 'protected void setDefaultElementAttributes ( Properties props )', 'long end = System . currentTimeMillis ( ) ;', 'setDefaultElementAttributes ( properties ) ;', 'cache . setElementEventQueue ( compositeCacheManager . getElementEventQueue ( ) ) ;', 'compositeCacheManager . setDefaultAuxValues ( value ) ;', 'private final CompositeCacheManager compositeCacheManager ;', 'compositeCacheManager . setDefaultElementAttributes ( iea ) ;', '}', 'AuxiliaryCacheFactory auxFac = compositeCacheManager . registryFacGet ( auxName ) ;', 'Properties props , String regName , String value ,', 'cache . setScheduledExecutorService ( compositeCacheManager . getScheduledExecutorService ( ) ) ;', 'eAttr = eAttr2 . clone ( ) ;', 'static final String REGION PREFIX = ""jcs . region . "" ;', 'log . info ( ""Finished configuration in "" + ( end - start ) + "" ms . "" ) ;', 'public void doConfigure ( Properties properties )', 'log . info ( ""setting defaultElementAttributes to "" + iea ) ;', 'StringTokenizer st = new StringTokenizer ( value , "" , "" ) ;', 'if ( log . isInfoEnabled ( ) )', 'String auxiliaryList = OptionConverter . findAndSubst ( key , props ) ;', 'static final String SYSTEM REGION PREFIX = ""jcs . system . "" ;', 'protected < K , V > AuxiliaryCache < K , V > parseAuxiliary ( Properties props , String auxName , String regName )', 'compositeCacheManager . addAuxiliaryCache ( auxName , regName , auxCache ) ;', 'compositeCacheManager . setDefaultCacheAttributes ( icca ) ;', 'compositeCacheManager . addCache ( regionName , cache ) ;'}}"
e5a3039f7a1e727fca40db7357a9191b6a7cf41d,1.0,"LANG - 1077 StringUtils . ordinalIndexOf ( ""aaaaaa"" , ""aa"" , 2 ) ! = 3 in StringUtils","{'added_code': {'index = CharSequenceUtils . indexOf ( str , searchStr , index + searchStr . length ( ) ) ;', 'index = CharSequenceUtils . lastIndexOf ( str , searchStr , index - searchStr . length ( ) ) ;'}, 'removed_code': {'index = CharSequenceUtils . lastIndexOf ( str , searchStr , index - 1 ) ;', 'index = CharSequenceUtils . indexOf ( str , searchStr , index + 1 ) ;'}}"
663521121083c36fbff550f23fa14bc74b73174b,1.0,"CONFIGURATION - 687 : Removed duplicate builders . The builders for the child configurations of a combined configuration are no longer created each time the managed configuration is created ; rather , they are created once initially . This resolves the memory leak that the list of child builders grows more and more .","{'added_code': {'private Collection < ConfigurationDeclaration > createDeclarations (', 'data . createAndAddConfigurations ( addConfig , data . unionDeclarations ,', 'private final List < ConfigurationBuilder < ? extends Configuration > > unionBuilders ;', 'public List < ConfigurationDeclaration > getUnionSources ( )', 'private final List < ConfigurationDeclaration > unionDeclarations ;', 'addChildConfiguration ( ccResult , srcDecl . get ( i ) , builders . get ( i ) ) ;', 'allBuilders = new LinkedList < > ( ) ;', 'return overrideDeclarations ;', 'List < ConfigurationDeclaration > srcDecl ,', 'unionBuilders . add ( createConfigurationBuilder ( cd ) ) ;', '}', 'overrideBuilders . add ( createConfigurationBuilder ( cd ) ) ;', 'providerForTag ( decl . getConfiguration ( ) . getRootElementName ( ) ) ;', 'return unionDeclarations ;', 'new ArrayList < > ( configs . size ( ) ) ;', 'List < ConfigurationBuilder < ? extends Configuration > > builders )', 'changeListener = createBuilderChangeListener ( ) ;', 'for ( ConfigurationDeclaration cd : unionDeclarations )', 'Collection < ConfigurationDeclaration > declarations =', 'overrideBuilders = new ArrayList < > ( ) ;', 'for ( ConfigurationDeclaration cd : overrideDeclarations )', 'overrideDeclarations . addAll ( createDeclarations ( fetchTopLevelOverrideConfigs ( config ) ) ) ;', 'declarations . add ( new ConfigurationDeclaration ( this , c ) ) ;', 'for ( int i = 0 ; i < srcDecl . size ( ) ; i + + )', 'unionDeclarations . addAll ( createDeclarations ( config . childConfigurationsAt ( KEY UNION ) ) ) ;', 'data . createAndAddConfigurations ( result , data . getOverrideSources ( ) ,', 'return new EventListener < ConfigurationBuilderEvent > ( )', 'private final List < ConfigurationDeclaration > overrideDeclarations ;', 'for ( HierarchicalConfiguration < ? > c : configs )', 'overrideDeclarations . addAll ( createDeclarations ( config . childConfigurationsAt ( KEY OVERRIDE ) ) ) ;', 'import java . util . ArrayList ;', 'unionDeclarations = new ArrayList < > ( ) ;', 'private final EventListener < ConfigurationBuilderEvent > changeListener ;', 'unionBuilders = new ArrayList < > ( ) ;', 'data . unionBuilders ) ;', 'namedBuilders = new HashMap < > ( ) ;', 'data . overrideBuilders ) ;', 'private final List < ConfigurationBuilder < ? extends Configuration > > overrideBuilders ;', 'private EventListener < ConfigurationBuilderEvent > createBuilderChangeListener ( )', 'public List < ConfigurationDeclaration > getOverrideSources ( )', '+ decl . getConfiguration ( ) . getRootElementName ( ) ) ;', 'return declarations ;', '{', 'ConfigurationDeclaration decl ) throws ConfigurationException', 'overrideDeclarations = new ArrayList < > ( ) ;', 'Collection < ? extends HierarchicalConfiguration < ? > > configs )'}, 'removed_code': {'ConfigurationDeclaration decl =', 'providerForTag ( src . getRootElementName ( ) ) ;', 'overrideBuilders . addAll ( config . childConfigurationsAt ( KEY OVERRIDE ) ) ;', 'return unionBuilders ;', 'overrideBuilders =', 'public Collection < HierarchicalConfiguration < ? > > getOverrideSources ( )', 'private EventListener < ConfigurationBuilderEvent > changeListener ;', 'unionBuilders =', 'overrideBuilders . addAll ( fetchTopLevelOverrideConfigs ( config ) ) ;', 'ConfigurationBuilder < ? extends Configuration > builder =', 'data . createAndAddConfigurations ( addConfig , data . getUnionSources ( ) ) ;', 'private final Collection < HierarchicalConfiguration < ? > > overrideBuilders ;', 'addChildConfiguration ( ccResult , decl , builder ) ;', 'unionBuilders . addAll ( config . childConfigurationsAt ( KEY UNION ) ) ;', 'new ConfigurationDeclaration (', 'createBuilderChangeListener ( ) ;', 'throws ConfigurationException', 'Collection < HierarchicalConfiguration < ? > > srcDecl )', 'CombinedConfigurationBuilder . this , src ) ;', 'createConfigurationBuilder ( src , decl ) ;', 'return overrideBuilders ;', 'private void createBuilderChangeListener ( )', 'new LinkedList < > ( ) ;', 'data . createAndAddConfigurations ( result , data . getOverrideSources ( ) ) ;', 'new HashMap < > ( ) ;', 'changeListener = new EventListener < ConfigurationBuilderEvent > ( )', 'HierarchicalConfiguration < ? > src , ConfigurationDeclaration decl )', '+ src . getRootElementName ( ) ) ;', 'allBuilders =', 'public Collection < HierarchicalConfiguration < ? > > getUnionSources ( )', 'namedBuilders =', 'for ( HierarchicalConfiguration < ? > src : srcDecl )', 'private final Collection < HierarchicalConfiguration < ? > > unionBuilders ;'}}"
f7c09b93c2386c6928a082e96d1ddd0925a19092,1.0,"[ IO - 226 ] question with byteCountToDisplaySize ( long size ) . Add more tests . Add commented out code for processing terabyte , petabyte and exabyte . Add constants for terabyte , petabyte and exabyte , zettabyte , and yottabyte .","{'added_code': {'public static final long ONE PB = ONE KB * ONE TB ;', 'public static final BigInteger ONE YB = ONE ZB . multiply ( BigInteger . valueOf ( ONE EB ) ) ;', 'public static final long ONE EB = ONE KB * ONE PB ;', 'public static final long ONE TB = ONE KB * ONE GB ;', 'import java . math . BigInteger ;', 'public static final BigInteger ONE ZB = BigInteger . valueOf ( ONE KB ) . multiply ( BigInteger . valueOf ( ONE EB ) ) ;'}, 'removed_code': set()}"
c4ddbe6456c9631c301171098a8ac016eb4e582c,1.0,LANG - 1015 : Add JsonToStringStyle implementation to ToStringStyle . This fixes #12 and #26 from github . Thanks to Thiago Andrade .,"{'added_code': {'private Object readResolve ( ) {', '+ FIELD NAME PREFIX ) ;', 'this . setSizeEndText ( "" > \\ """" ) ;', 'super . append ( buffer , fieldName , array , fullDetail ) ;', '}', 'this . setArrayStart ( "" [ "" ) ;', 'float [ ] array , Boolean fullDetail ) {', 'this . setNullText ( ""null"" ) ;', 'this . setSummaryObjectEndText ( "" > \\ """" ) ;', 'double [ ] array , Boolean fullDetail ) {', 'this . setSummaryObjectStartText ( "" \\ "" < "" ) ;', 'return ToStringStyle . JSON STYLE ;', 'return ;', 'this . setUseIdentityHashCode ( false ) ;', 'public void append ( StringBuffer buffer , String fieldName , byte [ ] array ,', 'short [ ] array , Boolean fullDetail ) {', 'Boolean fullDetail ) {', 'private String FIELD NAME PREFIX = "" \\ """" ;', 'super . appendFieldStart ( buffer , FIELD NAME PREFIX + fieldName', 'if ( fieldName = = null ) {', 'this . setSizeStartText ( "" \\ "" < size = "" ) ;', 'if ( !isFullDetail ( fullDetail ) ) {', 'buffer . append ( "" \\ """" + value + "" \\ """" ) ;', 'private static final class JsonToStringStyle extends ToStringStyle {', 'this . setFieldNameValueSeparator ( "" : "" ) ;', 'boolean [ ] array , Boolean fullDetail ) {', 'protected void appendFieldStart ( StringBuffer buffer , String fieldName ) {', 'public void append ( StringBuffer buffer , String fieldName , long [ ] array ,', 'appendNullText ( buffer , fieldName ) ;', 'if ( value = = null ) {', 'public void append ( StringBuffer buffer , String fieldName , int [ ] array ,', 'Object [ ] array , Boolean fullDetail ) {', 'private void appendValueAsString ( StringBuffer buffer , String value ) {', 'public void append ( StringBuffer buffer , String fieldName , Object value ,', 'JsonToStringStyle ( ) {', 'if ( value . getClass ( ) = = String . class ) {', '""Field names are mandatory when using JsonToStringStyle"" ) ;', 'public static final ToStringStyle JSON STYLE = new JsonToStringStyle ( ) ;', 'this . setFieldSeparator ( "" , "" ) ;', 'super . append ( buffer , fieldName , value , fullDetail ) ;', 'throw new UnsupportedOperationException (', '@ Override', 'buffer . append ( value ) ;', 'public void append ( StringBuffer buffer , String fieldName ,', 'super ( ) ;', 'protected void appendDetail ( StringBuffer buffer , String fieldName , Object value ) {', 'this . setContentStart ( "" { "" ) ;', 'appendValueAsString ( buffer , ( String ) value ) ;', 'this . setContentEnd ( "" } "" ) ;', 'this . setArrayEnd ( "" ] "" ) ;', 'this . setUseClassName ( false ) ;', '""FullDetail must be true when using JsonToStringStyle"" ) ;', 'private static final long serialVersionUID = 1L ;', 'public void append ( StringBuffer buffer , String fieldName , char [ ] array ,'}, 'removed_code': set()}"
9d090d40ef488c6c8e0784da877b93a05034e339,1.0,"[ NET - 511 ] Exception for new SubnetUtils ( ""0 . 0 . 0 . 0 / 0"" ) .","{'added_code': {'throw new IllegalArgumentException ( ""Cannot have / 0 cidr with non - zero address"" ) ;', 'netmask | = ( 1 < < 31 - j ) ;', '}', 'int cidrPart = rangeCheck ( Integer . parseInt ( matcher . group ( 5 ) ) , 0 , NBITS ) ;', 'if ( cidrPart = = 0 & & address ! = 0 ) {'}, 'removed_code': {'netmask | = ( 1 < < 31 - j ) ;', 'int cidrPart = rangeCheck ( Integer . parseInt ( matcher . group ( 5 ) ) , 1 , NBITS ) ;'}}"
581baeaa99864979aad55bdd45f054c8a53c341d,1.0,Support schedulers in cache factories,"{'added_code': {'if ( auxFac instanceof IRequireScheduler )', 'import java . util . StringTokenizer ;', '( ( IRequireScheduler ) auxFac ) . setScheduledExecutorService ( compositeCacheManager . getScheduledExecutorService ( ) ) ;', 'import java . util . Properties ;', 'import java . io . IOException ;', '{', 'import java . io . FileInputStream ;', 'import java . util . ArrayList ;', '}', 'import java . util . List ;', 'import java . util . Enumeration ;'}, 'removed_code': {'import java . util . StringTokenizer ;', 'import java . util . Properties ;', 'import java . io . IOException ;', 'import java . io . FileInputStream ;', 'import java . util . ArrayList ;', 'import java . util . Enumeration ;', 'import java . util . List ;'}}"
ee5885049faf1933fac107065874d54a2c6ceea3,1.0,Integrated ListDelimiterHandler with INIConfiguration . There was a bug that list delimiter characters in property values were not correctly escaped when saving an INIConfiguration . For this problem test cases were added to verify that it is fixed after this change .,"{'added_code': {'return String . valueOf ( getListDelimiterHandler ( ) . escape (', 'private String escapeValue ( String value )', 'values = getListDelimiterHandler ( ) . split ( value , false ) ;', 'out . print ( escapeValue ( value . toString ( ) ) ) ;', '{', '}', 'escapeComments ( value ) , ListDelimiterHandler . NOOP TRANSFORMER ) ) ;', 'private static String escapeComments ( String value )'}, 'removed_code': {'values = PropertyConverter . split ( value , getListDelimiter ( ) , false ) ;', 'private String formatValue ( String value )', 'out . print ( formatValue ( value . toString ( ) ) ) ;'}}"
daa69a5981c7c12e0af5922f0a07653446261b07,1.0,COMPRESS - 388 : Improve stream performance with wrapped buffers,"{'added_code': {'else {', 'int read = read ( loc + + , singleByteBuffer ) ;', '}', 'return singleByteBuffer . get ( ) & 0xff ;', 'this . end = start + remaining ;', 'private ByteBuffer singleByteBuffer ;', 'private final long end ;', 'return ret ;', 'return - 1 ;', 'if ( loc > = end ) {', 'b [ off ] = 0 ;', 'if ( singleByteBuffer = = null ) {', 'if ( loc = = end & & addDummy ) {', 'if ( len > end - loc ) {', 'singleByteBuffer . rewind ( ) ;', 'return 1 ;', 'private boolean addDummy = false ;', 'this . addDummy = true ;', 'public synchronized int read ( final byte [ ] b , final int off , int len ) throws IOException {', 'private long loc ;', 'int ret = read ( loc , buf ) ;', 'public synchronized int read ( ) throws IOException {', 'len = ( int ) ( end - loc ) ;', '+ + loc ;', 'if ( this . end < start ) {', 'buf = ByteBuffer . wrap ( b , off , len ) ;', 'throw new IllegalArgumentException ( ""Invalid length of stream at offset = "" + start + "" , length = "" + remaining ) ;', 'singleByteBuffer = ByteBuffer . allocate ( 1 ) ;', 'loc = start ;'}, 'removed_code': {'int ret = - 1 ;', 'return read ;', 'protected final ByteBuffer buffer ;', 'ret = read ( loc , buf ) ;', 'if ( remaining - - < = 0 ) {', 'public int read ( ) throws IOException {', '} else {', 'buffer = ByteBuffer . allocate ( ( int ) remaining ) ;', '}', 'archive . position ( pos ) ;', 'buffer = ByteBuffer . allocate ( MAX BUF LEN ) ;', 'return - 1 ;', 'if ( addDummyByte ) {', 'buf . get ( b , off , ret ) ;', 'buffer . flip ( ) ;', 'addDummyByte = false ;', 'b [ off ] = 0 ;', 'buf = ByteBuffer . allocate ( len ) ;', 'public int read ( final byte [ ] b , final int off , int len ) throws IOException {', 'protected int read ( long pos , int len ) throws IOException {', 'addDummyByte = true ;', 'return 1 ;', 'if ( len > remaining ) {', 'len = ( int ) remaining ;', 'this . remaining = remaining ;', 'if ( remaining < MAX BUF LEN & & remaining > 0 ) {', 'synchronized ( archive ) {', 'buffer . rewind ( ) . limit ( len ) ;', 'if ( remaining < = 0 ) {', 'protected boolean addDummyByte = false ;', 'int read = archive . read ( buffer , position ) ;', 'ret = read ( loc , len ) ;', 'if ( len < = buffer . capacity ( ) ) {', '@ Override', 'protected long loc ;', 'return buffer . get ( ) & 0xff ;', 'buf = buffer ;', 'protected static final int MAX BUF LEN = 8192 ;', 'protected int read ( long position , int len ) throws IOException {', 'int read = read ( loc + + , 1 ) ;', 'remaining - = ret ;', 'read = archive . read ( buffer ) ;', 'int read ;', 'protected long remaining ;', 'loc = start ;'}}"
ac65ef8457de014462967ee6d9354ed43cace618,1.0,NET - 492 FTPClient . printWorkingDirectory ( ) incorrectly parses certain valid PWD command results,"{'added_code': {'end = param . length ( ) - 1 ;', 'int end ;', 'if ( end ! = - 1 ) {', 'end = param . lastIndexOf ( "" \\ "" "" ) ;', '} else {', 'if ( param . endsWith ( "" \\ """" ) ) {', '}', 'return param . substring ( 1 , end ) . replace ( "" \\ "" \\ """" , "" \\ """" ) ;', 'if ( param . startsWith ( "" \\ """" ) ) {'}, 'removed_code': {'if ( param . startsWith ( "" \\ """" ) & & param . endsWith ( "" \\ """" ) ) {', 'return param . substring ( 1 , param . length ( ) - 1 ) . replace ( "" \\ "" \\ """" , "" \\ """" ) ;'}}"
b72b5c716ac18150396d05988d9eab745bea02b9,1.0,"COMPRESS - 316 detect DEFLATE streams with ZLIB header , submitted by Nick Burch","{'added_code': {'}', 'return new DeflateCompressorInputStream ( in ) ;', 'if ( DeflateCompressorInputStream . matches ( signature , signatureLength ) ) {'}, 'removed_code': set()}"
