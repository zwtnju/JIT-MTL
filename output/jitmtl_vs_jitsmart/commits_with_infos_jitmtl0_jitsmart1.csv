commit_id,label,msg,code
2759abae42100a486dda09e787d5aee13a9ba1f9,1.0,Initial revision,"{'added_code': {'resultSetConcurrency = new Integer ( resultSetConcurrency ) ;', '( ( PoolableConnection ) obj ) . reallyClose ( ) ;', 'try {', 'synchronized public void setValidationQuery ( String validationQuery ) {', 'public Object makeObject ( Object obj ) {', 'synchronized public boolean validateObject ( Object obj ) {', 'protected String sql = null ;', 'conn . setReadOnly ( defaultReadOnly ) ;', 'return new PStmtKey ( normalizeSQL ( sql ) ) ;', '} catch ( SQLException e ) {', 'public boolean equals ( Object that ) {', 'return pool ;', '( ( DelegatingPreparedStatement ) obj ) . getInnermostDelegate ( ) . close ( ) ;', 'sql = sql ;', 'ResultSet rset = null ;', 'closed = false ;', 'package org . apache . commons . dbcp ;', 'if ( this = = c ) {', 'pool . setFactory ( this ) ;', 'public CallableStatement prepareCall ( String sql ) throws SQLException { checkOpen ( ) ; return conn . prepareCall ( sql ) ; }', 'if ( null ! = stmtPoolFactory ) {', 'synchronized public void setConnectionFactory ( ConnectionFactory connFactory ) {', 'public void setCatalog ( String catalog ) throws SQLException { checkOpen ( ) ; conn . setCatalog ( catalog ) ; }', 'if ( closed ) {', 'conn . rollback ( ) ;', 'if ( obj instanceof DelegatingConnection ) {', 'PStmtKey ( String sql , int resultSetType , int resultSetConcurrency ) {', '} catch ( NullPointerException e ) {', 'return new PoolablePreparedStatement ( getDelegate ( ) . prepareStatement ( key . sql , key . resultSetType . intValue ( ) , key . resultSetConcurrency . intValue ( ) ) , key , pstmtPool , this ) ;', 'public boolean isReadOnly ( ) throws SQLException { checkOpen ( ) ; return conn . isReadOnly ( ) ; }', 'protected Object createKey ( String sql ) {', 'public class PoolableConnectionFactory implements PoolableObjectFactory {', 'public SQLWarning getWarnings ( ) throws SQLException { checkOpen ( ) ; return conn . getWarnings ( ) ; }', 'conn = c ;', 'public String toString ( ) {', 'rset . close ( ) ;', 'protected ObjectPool pool = null ;', 'public void setDefaultAutoCommit ( boolean defaultAutoCommit ) {', 'protected Integer resultSetType = null ;', 'defaultReadOnly = defaultReadOnly ;', 'return ""PoolingConnection : "" + pstmtPool . toString ( ) ;', 'conn . setAutoCommit ( defaultAutoCommit ) ;', 'protected KeyedObjectPool pstmtPool = null ;', 'if ( !conn . getAutoCommit ( ) ) {', 'public int getTransactionIsolation ( ) throws SQLException { checkOpen ( ) ; return conn . getTransactionIsolation ( ) ; }', 'import org . apache . commons . pool . * ;', 'public void setDelegate ( Connection c ) {', 'public void commit ( ) throws SQLException { checkOpen ( ) ; conn . commit ( ) ; }', 'synchronized public void setStatementPoolFactory ( KeyedObjectPoolFactory stmtPoolFactory ) {', 'throw new RuntimeException ( e . toString ( ) ) ;', 'pstmtPool = null ;', 'return ( ( ( null = = sql & & null = = key . sql ) | | sql . equals ( key . sql ) ) & &', '( ( PreparedStatement ) obj ) . close ( ) ;', 'public boolean isClosed ( ) throws SQLException { return conn . isClosed ( ) ; }', 'protected KeyedObjectPoolFactory stmtPoolFactory = null ;', 'throw new IllegalArgumentException ( ) ;', 'synchronized public void setPool ( ObjectPool pool ) {', 'return null ;', 'if ( obj instanceof Connection ) {', 'pool = pool ;', 'public CallableStatement prepareCall ( String sql , int resultSetType , int resultSetConcurrency ) throws SQLException { checkOpen ( ) ; return conn . prepareCall ( sql , resultSetType , resultSetConcurrency ) ; }', 'public Map getTypeMap ( ) throws SQLException { checkOpen ( ) ; return conn . getTypeMap ( ) ; }', 'buf . append ( resultSetType ) ;', 'super ( c ) ;', 'throw new SQLException ( ""Connection is closed . "" ) ;', 'buf . append ( "" , resultSetType = "" ) ;', 'public DatabaseMetaData getMetaData ( ) throws SQLException { checkOpen ( ) ; return conn . getMetaData ( ) ; }', 'connFactory = connFactory ;', '( ( DelegatingPreparedStatement ) obj ) . activate ( ) ;', 'c = ( ( DelegatingConnection ) c ) . getDelegate ( ) ;', 'public String getCatalog ( ) throws SQLException { checkOpen ( ) ; return conn . getCatalog ( ) ; }', 'Connection c = conn ;', 'rset = stmt . executeQuery ( query ) ;', 'if ( null = = key . resultSetType & & null = = key . resultSetConcurrency ) {', 'throw new SQLException ( e . toString ( ) ) ;', 'protected void passivate ( ) {', 'class PStmtKey {', 'PStmtKey key = ( PStmtKey ) that ;', 'protected Integer resultSetConcurrency = null ;', '} catch ( Exception e ) {', '} else {', 'public PoolableConnectionFactory ( ConnectionFactory connFactory , ObjectPool pool , KeyedObjectPoolFactory stmtPoolFactory , String validationQuery , boolean defaultReadOnly , boolean defaultAutoCommit ) {', 'validationQuery = validationQuery ;', 'return new PoolablePreparedStatement ( getDelegate ( ) . prepareStatement ( key . sql ) , key , pstmtPool , this ) ;', 'stmt . close ( ) ;', 'public void passivateObject ( Object key , Object obj ) {', 'public void passivateObject ( Object obj ) {', 'protected boolean defaultReadOnly = false ;', '( ( DelegatingConnection ) conn ) . activate ( ) ;', 'protected boolean defaultAutoCommit = true ;', 'public String nativeSQL ( String sql ) throws SQLException { checkOpen ( ) ; return conn . nativeSQL ( sql ) ; }', 'pool . close ( ) ;', '( ( DelegatingPreparedStatement ) obj ) . passivate ( ) ;', 'public class PoolingConnection extends DelegatingConnection implements Connection , KeyedPoolableObjectFactory {', 'PStmtKey ( String sql ) {', 'while ( c ! = null & & c instanceof DelegatingConnection ) {', 'if ( obj instanceof PoolableConnection ) {', 'defaultAutoCommit = defaultAutoCommit ;', 'return ( null = = sql ? 0 : sql . hashCode ( ) ) ;', 'public Statement createStatement ( int resultSetType , int resultSetConcurrency ) throws SQLException { checkOpen ( ) ; return conn . createStatement ( resultSetType , resultSetConcurrency ) ; }', 'protected Object createKey ( String sql , int resultSetType , int resultSetConcurrency ) {', 'public void setReadOnly ( boolean readOnly ) throws SQLException { checkOpen ( ) ; conn . setReadOnly ( readOnly ) ; }', 'synchronized public Object makeObject ( ) {', 'closed = true ;', 'return new PStmtKey ( normalizeSQL ( sql ) , resultSetType , resultSetConcurrency ) ;', '} catch ( ClassCastException e ) {', '} catch ( Throwable t ) {', 'KeyedObjectPool stmtpool = stmtPoolFactory . createPool ( ) ;', 'return c ;', 'if ( conn instanceof DelegatingConnection ) {', 'public boolean validateObject ( Object key , Object obj ) {', 'public void rollback ( ) throws SQLException { checkOpen ( ) ; conn . rollback ( ) ; }', 'protected ConnectionFactory connFactory = null ;', 'Statement stmt = null ;', 'public PoolingConnection ( Connection c , KeyedObjectPool pool ) {', 'protected void checkOpen ( ) throws SQLException {', 'public synchronized PreparedStatement prepareStatement ( String sql , int resultSetType , int resultSetConcurrency ) throws SQLException {', '( ( DelegatingConnection ) obj ) . activate ( ) ;', '} catch ( RuntimeException e ) {', 'buf . append ( "" , resultSetConcurrency = "" ) ;', '} catch ( SQLException e2 ) {', '( ( DelegatingConnection ) obj ) . passivate ( ) ;', 'stmt = conn . createStatement ( ) ;', 'public Connection getInnermostDelegate ( ) {', 'public PreparedStatement prepareStatement ( String sql ) throws SQLException { checkOpen ( ) ; return conn . prepareStatement ( sql ) ; }', 'public PoolingConnection ( Connection c ) {', 'public void setTransactionIsolation ( int level ) throws SQLException { checkOpen ( ) ; conn . setTransactionIsolation ( level ) ; }', 'return new PoolableConnection ( conn , pool ) ;', 'buf . append ( sql ) ;', 'protected void activate ( ) {', 'public PreparedStatement prepareStatement ( String sql , int resultSetType , int resultSetConcurrency ) throws SQLException { checkOpen ( ) ; return conn . prepareStatement ( sql , resultSetType , resultSetConcurrency ) ; }', 'pstmtPool = pool ;', 'return buf . toString ( ) ;', '( ( null = = resultSetType & & null = = key . resultSetType ) | | resultSetType . equals ( key . resultSetType ) ) & &', '( ( PreparedStatement ) obj ) . clearParameters ( ) ;', ';', 'return ( PreparedStatement ) ( pstmtPool . borrowObject ( createKey ( sql , resultSetType , resultSetConcurrency ) ) ) ;', 'import java . util . Map ;', 'protected boolean closed = false ;', 'public void setTypeMap ( Map map ) throws SQLException { checkOpen ( ) ; conn . setTypeMap ( map ) ; }', 'public DelegatingConnection ( Connection c ) {', '}', ') ;', 'if ( null = = obj | | ! ( obj instanceof PStmtKey ) ) {', 'protected Connection conn = null ;', 'public void setAutoCommit ( boolean autoCommit ) throws SQLException { checkOpen ( ) ; conn . setAutoCommit ( autoCommit ) ; }', 'public synchronized PreparedStatement prepareStatement ( String sql ) throws SQLException {', '} catch ( ClassCastException e2 ) {', 'import java . sql . * ;', 'if ( null ! = query ) {', 'String query = validationQuery ;', 'Connection conn = connFactory . createConnection ( ) ;', 'public void close ( ) throws SQLException { passivate ( ) ; conn . close ( ) ; }', 'return sql . trim ( ) ;', 'getInnermostDelegate ( ) . close ( ) ;', 'Connection conn = ( Connection ) obj ;', 'if ( rset . next ( ) ) {', 'return conn ;', 'public void destroyObject ( Object obj ) {', 'PStmtKey key = ( PStmtKey ) obj ;', 'public void activateObject ( Object key , Object obj ) {', 'public void setDefaultReadOnly ( boolean defaultReadOnly ) {', 'pstmtPool . close ( ) ;', 'public synchronized void close ( ) throws SQLException {', 'throw e ;', '( ( DelegatingConnection ) conn ) . passivate ( ) ;', 'if ( null ! = pool & & pool ! = pool ) {', 'buf . append ( ""PStmtKey : sql = "" ) ;', 'StringBuffer buf = new StringBuffer ( ) ;', 'public class DelegatingConnection implements Connection {', 'public int hashCode ( ) {', 'protected String validationQuery = null ;', 'public void clearWarnings ( ) throws SQLException { checkOpen ( ) ; conn . clearWarnings ( ) ; }', 'return true ;', 'buf . append ( resultSetConcurrency ) ;', 'conn = new PoolingConnection ( conn , stmtpool ) ;', 'public Connection getDelegate ( ) {', 'if ( conn . isClosed ( ) ) {', 'public Statement createStatement ( ) throws SQLException { checkOpen ( ) ; return conn . createStatement ( ) ; }', 'resultSetType = new Integer ( resultSetType ) ;', 'public ObjectPool getPool ( ) {', 'stmtPoolFactory = stmtPoolFactory ;', 'protected String normalizeSQL ( String sql ) {', 'return false ;', 'if ( null ! = pstmtPool ) {', 'stmtpool . setFactory ( ( PoolingConnection ) conn ) ;', '( ( null = = resultSetConcurrency & & null = = key . resultSetConcurrency ) | | resultSetConcurrency . equals ( key . resultSetConcurrency ) )', 'return ( PreparedStatement ) ( pstmtPool . borrowObject ( createKey ( sql ) ) ) ;', 'public void activateObject ( Object obj ) {', 'public void destroyObject ( Object key , Object obj ) {', 'public boolean getAutoCommit ( ) throws SQLException { checkOpen ( ) ; return conn . getAutoCommit ( ) ; }'}, 'removed_code': set()}"
53d3e8ce790cbf01580dad2391e9b7691f5d6c3a,1.0,"When retrieving , the uncompressed artifact should take the place of the real artifact","{'added_code': {'artifact . getQualifiedExtraAttributes ( ) ) ;', 'aMrid . getOrganisation ( ) , aMrid . getName ( ) , aMrid . getBranch ( ) ,', 'adr . getArtifactOrigin ( ) , aMrid . getQualifiedExtraAttributes ( ) ,', 'ext = """" ;', 'String ext = artifact . getExt ( ) ;', 'aMrid . getRevision ( ) , artifact . getName ( ) , artifact . getType ( ) , ext , conf ,', 'ModuleRevisionId aMrid = artifact . getModuleRevisionId ( ) ;'}, 'removed_code': {'artifact . getModuleRevisionId ( ) , artifact , conf , adr . getArtifactOrigin ( ) ) ;', 'artifact = adr . buildUncompressedArtifact ( ) ;'}}"
a3cefc2063d220efdc8a42a66164a5ff0bfd690a,1.0,Fix DBCP - 180 The garbage collector needs to be able to collect JDBC resources that the client is no longer referencing . The AbandonedTrace code was stopping this . This has been fixed by using WeakReferences . A secondary issue was that pooled statements would not get returned to the pool once the WeakReference was used since AbandonedTrace lost the ability to trace all the child resources . Use of a finalizer ( I couldn't think of a better way ) addresses that .,"{'added_code': {'ArrayList < AbandonedTrace > result = new ArrayList < > ( traceList . size ( ) ) ;', 'return result ;', 'private final List < WeakReference < AbandonedTrace > > traceList = new ArrayList < > ( ) ;', '} else {', 'import java . lang . ref . WeakReference ;', 'WeakReference < AbandonedTrace > ref = iter . next ( ) ;', 'this . traceList . add ( new WeakReference < > ( trace ) ) ;', 'if ( ref . get ( ) = = null ) {', 'iter . remove ( ) ;', 'if ( trace . equals ( ref . get ( ) ) ) {', 'result . add ( ref . get ( ) ) ;', 'import java . util . Iterator ;', 'Iterator < WeakReference < AbandonedTrace > > iter = traceList . iterator ( ) ;', '}', 'while ( iter . hasNext ( ) ) {', '} else if ( ref . get ( ) = = null ) {', 'break ;'}, 'removed_code': {'this . traceList . add ( trace ) ;', 'return new ArrayList < > ( traceList ) ;', 'private final List < AbandonedTrace > traceList = new ArrayList < > ( ) ;', 'this . traceList . remove ( trace ) ;'}}"
f7ab3a70ec426669398b4f16d0f2dd5458d87a2e,1.0,Modified KolmogororSmirnovTest 2 - sample test to use random jitter to break ties in input data . JIRA : MATH - 1246 .,"{'added_code': {'int ct = 0 ;', 'double [ ] xa = null ;', 'return ;', 'for ( int i = 0 ; i < data . length ; i + + ) {', 'do {', 'if ( ties ) {', 'minDelta = delta ;', 'final HashSet < Double > values = new HashSet < Double > ( ) ;', '} while ( ties & & ct < 1000 ) ;', 'private static void fixTies ( double [ ] x , double [ ] y ) {', 'jitter ( y , dist ) ;', 'ya = y ;', 'ct + + ;', 'prev = values [ i ] ;', 'if ( lengthProduct < LARGE SAMPLE PRODUCT & & hasTies ( x , y ) ) {', 'xa = x ;', 'return integralExactP ( integralKolmogorovSmirnovStatistic ( xa , ya ) + ( strict ? 1l : 0l ) , x . length , y . length ) ;', 'new UniformRealDistribution ( new JDKRandomGenerator ( 100 ) , - minDelta , minDelta ) ;', '} else {', 'import org . apache . commons . math4 . random . JDKRandomGenerator ;', 'xa = MathArrays . copyOf ( x ) ;', 'final RealDistribution dist =', 'import org . apache . commons . math4 . exception . MathInternalError ;', 'if ( delta < minDelta ) {', 'throw new MathInternalError ( ) ;', 'import org . apache . commons . math4 . distribution . UniformRealDistribution ;', 'jitter ( x , dist ) ;', 'final double [ ] values = MathArrays . unique ( MathArrays . concatenate ( x , y ) ) ;', 'private static void jitter ( double [ ] data , RealDistribution dist ) {', 'minDelta / = 2 ;', 'return integralMonteCarloP ( integralKolmogorovSmirnovStatistic ( xa , ya ) + ( strict ? 1l : 0l ) , x . length , y . length , MONTE CARLO ITERATIONS ) ;', 'double prev = values [ 0 ] ;', 'double [ ] ya = null ;', 'if ( values . length = = x . length + y . length ) {', 'delta = prev - values [ i ] ;', 'boolean ties = true ;', 'fixTies ( xa , ya ) ;', 'ya = MathArrays . copyOf ( y ) ;', 'for ( int i = 1 ; i < values . length ; i + + ) {', 'data [ i ] = data [ i ] + dist . sample ( ) ;', '}', 'ties = hasTies ( x , y ) ;', 'private static boolean hasTies ( double [ ] x , double [ ] y ) {', 'double delta = 1 ;', 'double minDelta = 1 ;'}, 'removed_code': {'return integralMonteCarloP ( integralKolmogorovSmirnovStatistic ( x , y ) + ( strict ? 1l : 0l ) , x . length , y . length , MONTE CARLO ITERATIONS ) ;', 'HashSet < Double > values = new HashSet < Double > ( ) ;', 'private boolean hasTies ( double [ ] x , double [ ] y ) {', 'return integralExactP ( integralKolmogorovSmirnovStatistic ( x , y ) + ( strict ? 1l : 0l ) , x . length , y . length ) ;'}}"
d50feb67569fb5881b8a2ff5996f656c5f207c2e,1.0,COMPRESS - 306 ArchiveStreamFactory fails to pass on the encoding when creating some streams .,"{'added_code': {'currEntry . setName ( zipEncoding . decode ( longNameData ) ) ;', 'final String encoding ;', 'private final ZipEncoding zipEncoding ;', 'this . zipEncoding = ZipEncodingHelper . getZipEncoding ( encoding ) ;', 'currEntry = new TarArchiveEntry ( headerBuf , zipEncoding ) ;', 'this . encoding = encoding ;', 'currEntry . setLinkName ( zipEncoding . decode ( longLinkData ) ) ;'}, 'removed_code': {'currEntry . setName ( encoding . decode ( longNameData ) ) ;', 'currEntry . setLinkName ( encoding . decode ( longLinkData ) ) ;', 'currEntry = new TarArchiveEntry ( headerBuf , encoding ) ;', 'private final ZipEncoding encoding ;', 'this . encoding = ZipEncodingHelper . getZipEncoding ( encoding ) ;'}}"
3b98bf44eba7958f12faa33cc0e5635b33fdf0b5,1.0,[ CONFIGURATION - 518 ] Reworked ConfigurationInterpolator class .,"{'added_code': {'ConfigurationInterpolator parent = getParentInterpolator ( ) ;', 'private StrSubstitutor initSubstitutor ( )', 'import org . apache . commons . lang3 . text . StrLookup ;', 'return this . parentInterpolator ;', 'public void setParentInterpolator (', 'import java . util . concurrent . ConcurrentHashMap ;', 'if ( parent ! = null )', 'public boolean deregisterLookup ( String prefix )', 'public String lookup ( String key )', 'prefixLookups . putAll ( lookups ) ;', 'return null ;', 'return defaultLookups . remove ( lookup ) ;', 'import java . util . ArrayList ;', 'return getParentInterpolator ( ) . resolve ( var ) ;', '}', 'return ( result ! = null ) ? result . toString ( ) : null ;', 'Object result = resolve ( key ) ;', 'public void addDefaultLookup ( Lookup defaultLookup )', 'import org . apache . commons . lang3 . text . StrSubstitutor ;', 'public Map < String , Lookup > getLookups ( )', 'private final List < Lookup > defaultLookups ;', '{', '@ Override', 'prefixLookups = new ConcurrentHashMap < String , Lookup > ( ) ;', 'public boolean removeDefaultLookup ( Lookup lookup )', 'Object value = fetchLookupForPrefix ( prefix ) . lookup ( name ) ;', 'lookup = DummyLookup . INSTANCE ;', 'defaultLookups = new CopyOnWriteArrayList < Lookup > ( ) ;', 'public Object resolve ( String var )', 'if ( value instanceof String )', 'if ( lookups ! = null )', 'return new HashMap < String , Lookup > ( prefixLookups ) ;', 'Object value = l . lookup ( var ) ;', 'return substitutor . isEnableSubstitutionInVariables ( ) ;', 'return new ArrayList < Lookup > ( defaultLookups ) ;', 'Lookup lookup = prefixLookups . get ( prefix ) ;', 'public Set < String > prefixSet ( )', 'public void addDefaultLookups ( Collection < ? extends Lookup > lookups )', 'public void registerLookups ( Map < String , ? extends Lookup > lookups )', 'defaultLookups . add ( defaultLookup ) ;', 'return Collections . unmodifiableSet ( prefixLookups . keySet ( ) ) ;', 'import java . util . Collection ;', 'public void setEnableSubstitutionInVariables ( boolean f )', 'if ( value ! = null )', 'private volatile ConfigurationInterpolator parentInterpolator ;', 'import java . util . List ;', 'substitutor . setEnableSubstitutionInVariables ( f ) ;', 'protected Lookup fetchLookupForPrefix ( String prefix )', 'import java . util . concurrent . CopyOnWriteArrayList ;', 'public class ConfigurationInterpolator', 'public Object interpolate ( Object value )', 'return new StrSubstitutor ( new StrLookup < Object > ( )', 'ConfigurationInterpolator parentInterpolator )', 'prefixLookups . put ( prefix , lookup ) ;', 'return value ;', 'defaultLookups . addAll ( lookups ) ;', 'for ( Lookup l : defaultLookups )', 'public boolean isEnableSubstitutionInVariables ( )', 'private final Map < String , Lookup > prefixLookups ;', 'substitutor = initSubstitutor ( ) ;', 'public void registerLookup ( String prefix , Lookup lookup )', 'return substitutor . replace ( ( String ) value ) ;', 'return prefixLookups . remove ( prefix ) ! = null ;', 'public List < Lookup > getDefaultLookups ( )', 'import java . util . Collections ;', 'private final StrSubstitutor substitutor ;', 'public ConfigurationInterpolator getParentInterpolator ( )', '} ) ;', 'this . parentInterpolator = parentInterpolator ;'}, 'removed_code': {'private ConfigurationInterpolator parentInterpolator ;', 'public static boolean deregisterGlobalLookup ( String prefix )', 'public static final String PREFIX ENVIRONMENT = ""env"" ;', 'this . defaultLookup = defaultLookup ;', 'return this . parentInterpolator ;', 'public void registerLocalLookups ( ConfigurationInterpolator interpolator )', 'globalLookups . put ( PREFIX SYSPROPERTIES , StrLookup . systemPropertiesLookup ( ) ) ;', 'private Map < String , StrLookup > localLookups ;', 'public void setParentInterpolator ( ConfigurationInterpolator parentInterpolator )', 'public static void registerGlobalLookup ( String prefix , StrLookup lookup )', 'return globalLookups . remove ( prefix ) ! = null ;', 'public void registerLookup ( String prefix , StrLookup lookup )', 'private static Map < String , StrLookup > globalLookups ;', 'interpolator . localLookups . putAll ( localLookups ) ;', 'public boolean deregisterLookup ( String prefix )', 'globalLookups . put ( prefix , lookup ) ;', 'public static final String PREFIX SYSPROPERTIES = ""sys"" ;', 'value = getParentInterpolator ( ) . lookup ( var ) ;', 'return ( getDefaultLookup ( ) ! = null ) ? getDefaultLookup ( ) : StrLookup . noneLookup ( ) ;', '{', '@ Override', 'import org . apache . commons . lang . text . StrLookup ;', 'public static final String PREFIX CONSTANTS = ""const"" ;', '""Lookup object must not be null!"" ) ;', 'globalLookups . put ( PREFIX CONSTANTS , new ConstantLookup ( ) ) ;', 'return localLookups . keySet ( ) ;', 'value = getParentInterpolator ( ) . lookup ( name ) ;', 'if ( lookup = = null )', 'localLookups . put ( prefix , lookup ) ;', 'String value = fetchLookupForPrefix ( prefix ) . lookup ( name ) ;', 'this . parentInterpolator = parentInterpolator ;', 'public Set < String > prefixSet ( )', 'if ( prefix = = null )', 'String value = fetchNoPrefixLookup ( ) . lookup ( var ) ;', 'throw new IllegalArgumentException (', 'public class ConfigurationInterpolator extends StrLookup', 'protected StrLookup fetchNoPrefixLookup ( )', 'lookup = StrLookup . noneLookup ( ) ;', 'if ( value = = null & & getParentInterpolator ( ) ! = null )', 'static', 'StrLookup lookup = localLookups . get ( prefix ) ;', 'localLookups = new HashMap < String , StrLookup > ( globalLookups ) ;', 'globalLookups . put ( PREFIX ENVIRONMENT , new EnvironmentLookup ( ) ) ;', 'synchronized ( globalLookups )', 'return localLookups . remove ( prefix ) ! = null ;', 'return value ;', 'public StrLookup getDefaultLookup ( )', 'return defaultLookup ;', '""Prefix for lookup object must not be null!"" ) ;', 'public String lookup ( String var )', 'private StrLookup defaultLookup ;', 'globalLookups = new HashMap < String , StrLookup > ( ) ;', 'protected StrLookup fetchLookupForPrefix ( String prefix )', '}', 'public ConfigurationInterpolator getParentInterpolator ( )', 'public void setDefaultLookup ( StrLookup defaultLookup )'}}"
96968fdcadb1f87017c6e7853c4a63ba065c6611,1.0,GIRAPH - 752 : Better support for supernodes ( majakabiljo ),"{'added_code': {'return n - bytesLeftToSkip + bytesSkipped ;', 'public class BigDataInput implements ExtendedDataInput {', 'private final List < ExtendedDataInput > dataInputs ;', 'currentPositionInInputs = - 1 ;', 'int bytesSkipped = currentInput . skipBytes ( bytesLeftToSkip ) ;', 'dataOutput . getByteArray ( ) , 0 , dataOutput . getPos ( ) ) ) ;', 'import org . apache . giraph . utils . ExtendedDataInput ;', 'if ( currentInput . available ( ) = = 0 ) {', 'return currentInput . readShort ( ) ;', 'currentInput = dataInputs . get ( currentPositionInInputs ) ;', 'int available = 0 ;', 'return currentInput . readFloat ( ) ;', 'return pos ;', 'pos + = dataInputs . get ( i ) . getPos ( ) ;', 'private ExtendedDataInput currentInput ;', 'public int skipBytes ( int n ) throws IOException {', 'import java . util . ArrayList ;', 'if ( currentPositionInInputs < dataInputs . size ( ) ) {', 'public float readFloat ( ) throws IOException {', 'public BigDataInput ( BigDataOutput bigDataOutput ) {', 'currentInput . readFully ( b , off , len ) ;', 'public boolean readBoolean ( ) throws IOException {', 'while ( bytesLeftToSkip > = currentInput . available ( ) ) {', 'return currentInput . readLong ( ) ;', 'dataInputs = new ArrayList < ExtendedDataInput > (', 'public double readDouble ( ) throws IOException {', '@ Override', 'currentInput = EMPTY INPUT ;', 'checkIfShouldMoveToNextDataInput ( ) ;', 'public int available ( ) {', 'currentPositionInInputs + + ;', 'return currentInput . readChar ( ) ;', 'return currentInput . readUnsignedShort ( ) ;', 'public void readFully ( byte [ ] b ) throws IOException {', 'public int readInt ( ) throws IOException {', 'public char readChar ( ) throws IOException {', 'for ( int i = 0 ; i < = currentPositionInInputs ; i + + ) {', 'int bytesLeftToSkip = n ;', 'new ExtendedByteArrayDataInput ( new byte [ 0 ] ) ;', 'return currentInput . readLine ( ) ;', 'import org . apache . giraph . utils . ExtendedByteArrayDataInput ;', 'import org . apache . giraph . utils . ExtendedDataOutput ;', 'public short readShort ( ) throws IOException {', 'dataInputs . add ( bigDataOutput . getConf ( ) . createExtendedDataInput (', '} else {', 'available + = dataInputs . get ( i ) . available ( ) ;', 'private void checkIfShouldMoveToNextDataInput ( ) {', 'currentInput . readFully ( b ) ;', 'public byte readByte ( ) throws IOException {', 'bigDataOutput . getNumberOfDataOutputs ( ) ) ;', 'int pos = 0 ;', 'return currentInput . readInt ( ) ;', 'private void moveToNextDataInput ( ) {', 'public String readLine ( ) throws IOException {', 'import java . util . List ;', 'private static final ExtendedDataInput EMPTY INPUT =', 'public int readUnsignedByte ( ) throws IOException {', 'public long readLong ( ) throws IOException {', 'for ( ExtendedDataOutput dataOutput : bigDataOutput . getDataOutputs ( ) ) {', 'public int readUnsignedShort ( ) throws IOException {', 'return currentInput . readUTF ( ) ;', 'return currentInput . readByte ( ) ;', 'private int currentPositionInInputs ;', 'for ( int i = currentPositionInInputs ; i < dataInputs . size ( ) ; i + + ) {', 'return currentInput . readDouble ( ) ;', 'bytesLeftToSkip - = currentInput . available ( ) ;', 'return available ;', 'return currentInput . readBoolean ( ) ;', 'return currentInput . readUnsignedByte ( ) ;', 'moveToNextDataInput ( ) ;', 'public void readFully ( byte [ ] b , int off , int len ) throws IOException {', 'package org . apache . giraph . utils . io ;', 'public String readUTF ( ) throws IOException {', 'import java . io . IOException ;', '}', 'public int getPos ( ) {'}, 'removed_code': set()}"
ab1ee1b68b15234b62a840c4b1f6d2485d771450,1.0,Use final where possible .,"{'added_code': {'public PhonemeBuilder append ( final CharSequence str ) {', 'for ( final Rule rule : this . finalRules ) {', 'final String pattern = rule . getPattern ( ) ;', 'final Languages . LanguageSet languageSet = this . lang . guessLanguages ( input ) ;', 'public int difference ( final String s1 , final String s2 ) throws EncoderException {', 'for ( final Rule . Phoneme right : phonemeExpr . getPhonemes ( ) ) {', 'private char getMappingCode ( final String str , final int index ) {', 'final Set < Rule . Phoneme > newPhonemes = new LinkedHashSet < Rule . Phoneme > ( ) ;', 'final String combined = ""d"" + remainder ;', 'public Soundex ( final String mapping ) {', 'public RulesApplication ( final List < Rule > finalRules , final CharSequence input ,', 'public PhoneticEngine ( final NameType nameType , final RuleType ruleType , final boolean concat , final int maxPhonemes ) {', 'private char map ( final char ch ) {', 'public CharSequence subSequence ( final int start , final int end ) {', ""final int index = ch - 'A' ;"", 'final char preHWChar = str . charAt ( index - 2 ) ;', 'final RulesApplication rulesApplication =', 'public String encode ( final String str ) {', 'EXPR : for ( final Rule . Phoneme left : this . phonemes ) {', 'final PhonemeBuilder phonemeBuilder , final int i , final int maxPhonemes ) {', 'public char charAt ( final int index ) {', 'final CharSequence phonemeText = cacheSubSequence ( phoneme . getPhonemeText ( ) ) ;', 'public void setMaxLength ( final int maxLength ) {', 'final String remainder = input . substring ( 2 ) ;', 'final char firstCode = this . map ( preHWChar ) ;', 'private PhonemeBuilder ( final Set < Rule . Phoneme > phonemes ) {', 'private static String join ( final Iterable < String > strings , final String sep ) {', 'for ( final String l : NAME PREFIXES . get ( this . nameType ) ) {', 'for ( final Rule . Phoneme phoneme : phonemeBuilder . getPhonemes ( ) ) {', 'private PhonemeBuilder applyFinalRules ( final PhonemeBuilder phonemeBuilder , final List < Rule > finalRules ) {', 'final StringBuilder result = new StringBuilder ( ) ;', 'final CharSequence inputCache = cacheSubSequence ( input ) ;', 'final StringBuilder sb = new StringBuilder ( ) ;', 'final String remainder = input . substring ( l . length ( ) + 1 ) ;', 'final Iterator < String > si = strings . iterator ( ) ;', 'for ( final String word : words2 ) {', ""final char out [ ] = { '0' , '0' , '0' , '0' } ;"", 'public String encode ( final String input ) {', 'public Soundex ( final char [ ] mapping ) {', 'final String combined = l + remainder ;', 'final boolean found = rulesApplication . isFound ( ) ;', 'public Object encode ( final Object obj ) throws EncoderException {', 'final Rule . Phoneme join = left . join ( right ) ;', 'final String lastPart = parts [ parts . length - 1 ] ;', 'for ( final Rule . Phoneme ph : this . phonemes ) {', 'final String [ ] parts = aWord . split ( ""\'"" ) ;', 'final char mappedChar = this . map ( str . charAt ( index ) ) ;', 'final char hwChar = str . charAt ( index - 1 ) ;', 'public PhoneticEngine ( final NameType nameType , final RuleType ruleType , final boolean concat ) {', 'public static PhonemeBuilder empty ( final Languages . LanguageSet languages ) {', 'for ( final String aWord : words ) {', 'final Set < Rule . Phoneme > phonemes = new TreeSet < Rule . Phoneme > ( Rule . Phoneme . COMPARATOR ) ;', 'private final int maxPhonemes ;', 'public PhonemeBuilder apply ( final Rule . PhonemeExpr phonemeExpr , final int maxPhonemes ) {'}, 'removed_code': {'char mappedChar = this . map ( str . charAt ( index ) ) ;', 'public CharSequence subSequence ( int start , int end ) {', 'CharSequence phonemeText = cacheSubSequence ( phoneme . getPhonemeText ( ) ) ;', 'for ( Rule . Phoneme right : phonemeExpr . getPhonemes ( ) ) {', 'public void setMaxLength ( int maxLength ) {', 'String [ ] parts = aWord . split ( ""\'"" ) ;', 'public PhonemeBuilder apply ( Rule . PhonemeExpr phonemeExpr , int maxPhonemes ) {', 'private char map ( char ch ) {', ""int index = ch - 'A' ;"", 'RulesApplication rulesApplication =', 'for ( Rule . Phoneme phoneme : phonemeBuilder . getPhonemes ( ) ) {', 'for ( Rule rule : this . finalRules ) {', 'Rule . Phoneme join = left . join ( right ) ;', 'String combined = l + remainder ;', 'public String encode ( String input ) {', 'public String encode ( String str ) {', ""char out [ ] = { '0' , '0' , '0' , '0' } ;"", 'public Soundex ( char [ ] mapping ) {', 'char hwChar = str . charAt ( index - 1 ) ;', 'public RulesApplication ( List < Rule > finalRules , CharSequence input ,', 'for ( String aWord : words ) {', 'String lastPart = parts [ parts . length - 1 ] ;', 'public PhonemeBuilder append ( CharSequence str ) {', 'boolean found = rulesApplication . isFound ( ) ;', 'private int maxPhonemes ;', 'public PhoneticEngine ( NameType nameType , RuleType ruleType , boolean concat ) {', 'String remainder = input . substring ( l . length ( ) + 1 ) ;', 'public Object encode ( Object obj ) throws EncoderException {', 'for ( String word : words2 ) {', 'String remainder = input . substring ( 2 ) ;', 'char preHWChar = str . charAt ( index - 2 ) ;', 'StringBuilder result = new StringBuilder ( ) ;', 'StringBuilder sb = new StringBuilder ( ) ;', 'char firstCode = this . map ( preHWChar ) ;', 'String combined = ""d"" + remainder ;', 'public int difference ( String s1 , String s2 ) throws EncoderException {', 'EXPR : for ( Rule . Phoneme left : this . phonemes ) {', 'private static String join ( Iterable < String > strings , String sep ) {', 'String pattern = rule . getPattern ( ) ;', 'public static PhonemeBuilder empty ( Languages . LanguageSet languages ) {', 'private char getMappingCode ( String str , int index ) {', 'Set < Rule . Phoneme > phonemes = new TreeSet < Rule . Phoneme > ( Rule . Phoneme . COMPARATOR ) ;', 'public Soundex ( String mapping ) {', 'for ( Rule . Phoneme ph : this . phonemes ) {', 'Languages . LanguageSet languageSet = this . lang . guessLanguages ( input ) ;', 'public char charAt ( int index ) {', 'Set < Rule . Phoneme > newPhonemes = new LinkedHashSet < Rule . Phoneme > ( ) ;', 'PhonemeBuilder phonemeBuilder , int i , int maxPhonemes ) {', 'for ( String l : NAME PREFIXES . get ( this . nameType ) ) {', 'private PhonemeBuilder applyFinalRules ( PhonemeBuilder phonemeBuilder , List < Rule > finalRules ) {', 'CharSequence inputCache = cacheSubSequence ( input ) ;', 'Iterator < String > si = strings . iterator ( ) ;', 'public PhoneticEngine ( NameType nameType , RuleType ruleType , boolean concat , int maxPhonemes ) {', 'private PhonemeBuilder ( Set < Rule . Phoneme > phonemes ) {'}}"
dcd1c33f0dba247b43418b922c1c3a2fc432dc11,1.0,PARQUET - 352 : Add object model property to file footers . WriteSupport now has a getName getter method that is added to the footer if it returns a non - null string as writer . model . name . This is intended to help identify files written by object models incorrectly . Author : Ryan Blue < blue @ apache . org > Closes #289 from rdblue / PARQUET - 352 - add - object - model - property and squashes the following commits : 23f8f67 [ Ryan Blue ] PARQUET - 352 : Add object model property to file footers .,"{'added_code': {'if ( modelName ! = null ) {', 'String modelName = writeSupport . getName ( ) ;', '}', 'finalMetadata . put ( ParquetWriter . OBJECT MODEL NAME PROP , modelName ) ;'}, 'removed_code': set()}"
99189ff527554aa345f63fc038fc8eacf28cbb39,1.0,"Added KolmogorovSmirnovTest , deprecated KolmogorovSmirnovDistributio . JIRA : MATH - 437","{'added_code': {'final RealMatrix H = new Array2DRowRealMatrix ( m , m ) ;', 'copyPartition ( nSet , mSet , nPlusMSet , n , m ) ;', 'return ( double ) tail / ( double ) CombinatoricsUtils . binomialCoefficient ( n + m , n ) ;', 'try {', 'Arrays . sort ( dataCopy ) ;', 'return supD ;', 'double d = 0d ;', 'final int m = HBigFraction . getRowDimension ( ) ;', 'int k = 0 ;', 'if ( j < n & & nSetI [ j ] = = i ) {', 'return kolmogorovSmirnovTest ( distribution , data , false ) ;', 'protected static final int MONTE CARLO ITERATIONS = 1000000 ;', 'public boolean kolmogorovSmirnovTest ( RealDistribution distribution , double [ ] data , double alpha ) {', 'return approximateP ( kolmogorovSmirnovStatistic ( x , y ) , x . length , y . length ) ;', 'final double cdf y = ( i + 1d ) / m ;', 'Hdata [ i ] [ j ] = BigFraction . ONE ;', 'public class KolmogorovSmirnovTest {', 'throw new NumberIsTooLargeException ( hDouble , 1 . 0 , false ) ;', 'final int yIndex = Arrays . binarySearch ( sy , sx [ i ] ) ;', 'partialSum + = sign * delta ;', 'double pFrac = Hpower . getEntry ( k - 1 , k - 1 ) ;', 'private final RandomGenerator rng ;', 'pFrac = pFrac . multiply ( i ) . divide ( n ) ;', 'import java . math . BigDecimal ;', 'return exactP ( kolmogorovSmirnovStatistic ( x , y ) , x . length , y . length , strict ) ;', 'Hdata [ m - 1 ] [ 0 ] = Hdata [ m - 1 ] [ 0 ] . add ( h . multiply ( 2 ) . subtract ( 1 ) . pow ( m ) ) ;', 'final double f = 2 * d - ninv ;', 'if ( d < = ninvhalf ) {', '} else if ( 1 < = d ) {', 'for ( int i = 0 ; i < n + m ; i + + ) {', 'private void copyPartition ( double [ ] nSet , double [ ] mSet , int [ ] nSetI , int n , int m ) {', 'final FieldMatrix < BigFraction > H = this . createH ( d , n ) ;', 'import org . apache . commons . math3 . util . FastMath ;', 'final double dm = m ;', 'for ( int j = 0 ; j < i + 1 ; + + j ) {', 'import org . apache . commons . math3 . exception . InsufficientDataException ;', 'return new Array2DRowFieldMatrix < BigFraction > ( BigFractionField . getInstance ( ) , Hdata ) ;', 'sign * = - 1 ;', 'd = currD ;', 'final double cdf y = yIndex > = 0 ? ( yIndex + 1d ) / m : ( - yIndex - 1d ) / m ;', 'Hdata [ m - 1 ] [ i ] = Hdata [ m - 1 ] [ i ] . subtract ( hPowers [ m - i - 1 ] ) ;', 'final int [ ] nSetI = combinationsIterator . next ( ) ;', 'return 1 - ksSum ( d * FastMath . sqrt ( ( dm * dn ) / ( dm + dn ) ) , KS SUM CAUCHY CRITERION , MAXIMUM PARTIAL SUM COUNT ) ;', 'import org . apache . commons . math3 . linear . Array2DRowRealMatrix ;', 'final double hDouble = k - n * d ;', 'import org . apache . commons . math3 . fraction . BigFraction ;', 'throws MathArithmeticException {', 'tail + + ;', 'protected static final double KS SUM CAUCHY CRITERION = 1E - 20 ;', 'import java . util . Iterator ;', 'import org . apache . commons . math3 . random . RandomGenerator ;', 'if ( x . length * y . length < SMALL SAMPLE PRODUCT ) {', 'for ( int i = 0 ; i < m ; + + i ) {', 'long tail = 0 ;', 'import org . apache . commons . math3 . exception . MathArithmeticException ;', 'import org . apache . commons . math3 . linear . FieldMatrix ;', '} catch ( final FractionConversionException e1 ) {', 'Arrays . sort ( sy ) ;', 'double partialSum = 0 . 5d ;', 'import org . apache . commons . math3 . linear . Array2DRowFieldMatrix ;', 'return res ;', '} else if ( ninvhalf < d & & d < = ninv ) {', 'while ( combinationsIterator . hasNext ( ) ) {', 'final int xIndex = Arrays . binarySearch ( sx , sy [ i ] ) ;', 'i + + ;', 'final double dn = n ;', 'private FieldMatrix < BigFraction > createH ( double d , int n )', 'for ( int i = 0 ; i < m ; i + + ) {', 'if ( h . compareTo ( BigFraction . ONE HALF ) = = 1 ) {', '} else if ( 1 - ninv < = d & & d < 1 ) {', 'mSet [ k + + ] = i ;', 'supD = curD ;', 'BigFraction pFrac = Hpower . getEntry ( k - 1 , k - 1 ) ;', 'protected static final int MAXIMUM PARTIAL SUM COUNT = 100000 ;', 'final double ninvhalf = 0 . 5 * ninv ;', 'res * = i * f ;', 'import org . apache . commons . math3 . exception . NumberIsTooLargeException ;', 'int tail = 0 ;', '} else {', 'public double cdfExact ( double d , int n )', 'h = new BigFraction ( hDouble , 1 . 0e - 5 , 10000 ) ;', 'Hdata [ i ] [ j ] = BigFraction . ZERO ;', 'return cdf ( d , n , false ) ;', 'if ( hDouble > = 1 ) {', 'public double kolmogorovSmirnovTest ( double [ ] x , double [ ] y , boolean strict ) {', 'Hdata [ i ] [ j ] = Hdata [ i ] [ j ] . divide ( g ) ;', 'final double [ ] sy = MathArrays . copyOf ( y ) ;', 'final int m = sy . length ;', 'final double [ ] dataCopy = new double [ n ] ;', 'final FieldMatrix < BigFraction > Hpower = H . power ( n ) ;', 'final double cdf x = ( i + 1d ) / n ;', 'delta = FastMath . exp ( x * i * i ) ;', 'return cdf ( d , n , true ) ;', 'return kolmogorovSmirnovTest ( x , y , true ) ;', 'h = new BigFraction ( hDouble , 1 . 0e - 20 , 10000 ) ;', 'checkArray ( x ) ;', 'import org . apache . commons . math3 . exception . util . LocalizedFormats ;', 'protected static final int LARGE SAMPLE PRODUCT = 10000 ;', 'pFrac * = ( double ) i / ( double ) n ;', 'public double ksSum ( double t , double tolerance , int maxIterations ) {', 'checkArray ( y ) ;', 'Arrays . sort ( nPlusMSet , 0 , n ) ;', 'if ( x . length * y . length < LARGE SAMPLE PRODUCT ) {', 'final FieldMatrix < BigFraction > HBigFraction = this . createH ( d , n ) ;', 'import org . apache . commons . math3 . exception . OutOfRangeException ;', 'final int m = 2 * k - 1 ;', 'for ( int i = 0 ; i < n ; i + + ) {', 'int sign = - 1 ;', 'long i = 1 ;', 'return partialSum * 2 ;', 'if ( currD > d ) {', 'hPowers [ i ] = h . multiply ( hPowers [ i - 1 ] ) ;', 'public double cdf ( double d , int n , boolean exact )', 'if ( i - j + 1 < 0 ) {', 'for ( int i = 1 ; i < = n ; i + + ) {', 'if ( curD > d ) {', 'public double exactP ( double d , int n , int m , boolean strict ) {', 'BigFraction h = null ;', 'H . setEntry ( i , j , HBigFraction . getEntry ( i , j ) . doubleValue ( ) ) ;', 'import org . apache . commons . math3 . linear . RealMatrix ;', 'throw new InsufficientDataException ( LocalizedFormats . INSUFFICIENT OBSERVED POINTS IN SAMPLE , array . length ,', 'return pFrac ;', '} catch ( final FractionConversionException e2 ) {', 'h = new BigFraction ( hDouble , 1 . 0e - 10 , 10000 ) ;', 'System . arraycopy ( data , 0 , dataCopy , 0 , n ) ;', 'MathArrays . shuffle ( nPlusMSet , rng ) ;', 'if ( i - j + 1 > 0 ) {', 'final double yi = distribution . cumulativeProbability ( dataCopy [ i - 1 ] ) ;', 'throws NumberIsTooLargeException , FractionConversionException {', 'import org . apache . commons . math3 . exception . NullArgumentException ;', 'if ( i = = maxIterations ) {', 'for ( int i = 0 ; i < iterations ; i + + ) {', 'final double x = - 2 * t * t ;', 'final double nd = n ;', 'public double monteCarloP ( double d , int n , int m , boolean strict , int iterations ) {', 'import org . apache . commons . math3 . exception . TooManyIterationsException ;', 'if ( array . length < 2 ) {', '} else if ( curD = = d & & !strict ) {', 'import org . apache . commons . math3 . random . Well19937c ;', 'hPowers [ 0 ] = h ;', 'return monteCarloP ( kolmogorovSmirnovStatistic ( x , y ) , x . length , y . length , strict , MONTE CARLO ITERATIONS ) ;', 'return ( double ) tail / iterations ;', 'public double approximateP ( double d , int n , int m ) {', 'throw new TooManyIterationsException ( maxIterations ) ;', 'public double cdf ( double d , int n )', 'final double currD = FastMath . max ( yi - ( i - 1 ) / nd , i / nd - yi ) ;', 'Arrays . sort ( sx ) ;', 'public double kolmogorovSmirnovTest ( RealDistribution distribution , double [ ] data , boolean exact ) {', 'this . rng = rng ;', 'Hdata [ i ] [ 0 ] = Hdata [ i ] [ 0 ] . subtract ( hPowers [ i ] ) ;', 'for ( int i = 1 ; i < = n ; + + i ) {', 'package org . apache . commons . math3 . stat . inference ;', '}', 'public double kolmogorovSmirnovStatistic ( double [ ] x , double [ ] y ) {', 'final double [ ] sx = MathArrays . copyOf ( x ) ;', 'throw new NullArgumentException ( LocalizedFormats . NULL NOT ALLOWED ) ;', 'final double ninv = 1 / ( ( double ) n ) ;', 'rng = new Well19937c ( ) ;', 'return 1d - cdf ( kolmogorovSmirnovStatistic ( distribution , data ) , data . length , exact ) ;', 'final double curD = kolmogorovSmirnovStatistic ( nSet , mSet ) ;', 'import org . apache . commons . math3 . fraction . FractionConversionException ;', 'for ( int j = 0 ; j < m ; + + j ) {', 'final BigFraction [ ] [ ] Hdata = new BigFraction [ m ] [ m ] ;', 'final int n = sx . length ;', 'final int n = data . length ;', 'public double kolmogorovSmirnovStatistic ( RealDistribution distribution , double [ ] data ) {', 'public double kolmogorovSmirnovTest ( RealDistribution distribution , double [ ] data ) {', 'public KolmogorovSmirnovTest ( ) {', '2 ) ;', 'final double [ ] mSet = new double [ m ] ;', 'return exact ? exactK ( d , n ) : roundedK ( d , n ) ;', 'checkArray ( data ) ;', 'final double cdf x = xIndex > = 0 ? ( xIndex + 1d ) / n : ( - xIndex - 1d ) / n ;', 'protected static final int SMALL SAMPLE PRODUCT = 200 ;', 'double res = 1 ;', 'while ( delta > tolerance & & i < maxIterations ) {', 'return 1 ;', 'final int k = ( int ) Math . ceil ( n * d ) ;', 'public double kolmogorovSmirnovTest ( double [ ] x , double [ ] y ) {', 'private void checkArray ( double [ ] array ) {', 'double delta = 1 ;', 'return 0 ;', 'Iterator < int [ ] > combinationsIterator = CombinatoricsUtils . combinationsIterator ( n + m , n ) ;', 'import org . apache . commons . math3 . distribution . RealDistribution ;', 'return pFrac . bigDecimalValue ( 20 , BigDecimal . ROUND HALF UP ) . doubleValue ( ) ;', 'import java . util . Arrays ;', 'if ( array = = null ) {', 'if ( ( alpha < = 0 ) | | ( alpha > 0 . 5 ) ) {', 'final BigFraction [ ] hPowers = new BigFraction [ m ] ;', 'final RealMatrix Hpower = H . power ( n ) ;', 'final int [ ] nPlusMSet = MathArrays . natural ( m + n ) ;', 'final double [ ] nSet = new double [ n ] ;', 'import org . apache . commons . math3 . util . CombinatoricsUtils ;', 'public KolmogorovSmirnovTest ( RandomGenerator rng ) {', 'import org . apache . commons . math3 . fraction . BigFractionField ;', 'int j = 0 ;', 'return d ;', 'import org . apache . commons . math3 . util . MathArrays ;', 'return 1 - 2 * Math . pow ( 1 - d , n ) ;', 'final double curD = FastMath . abs ( cdf x - cdf y ) ;', 'for ( int i = 1 ; i < m ; + + i ) {', 'return kolmogorovSmirnovTest ( distribution , data ) < alpha ;', 'private double exactK ( double d , int n )', 'if ( curD > supD ) {', 'for ( int g = 2 ; g < = i - j + 1 ; + + g ) {', 'nSet [ j + + ] = i ;', 'throw new OutOfRangeException ( LocalizedFormats . OUT OF BOUND SIGNIFICANCE LEVEL , alpha , 0 , 0 . 5 ) ;', 'private double roundedK ( double d , int n )', 'double supD = 0d ;'}, 'removed_code': set()}"
6527a801c181090326f44bffef6709f898cae70b,1.0,"MATH - 1054 Standardize ""x = x op y"" to ""x op = y"" . Thanks to Sean Owen .","{'added_code': {'prod2A + = bc > > > 32 ;', 'z * = lnb ;', 'b + = sintA * cosEpsB + costA * sinEpsB ;', 'prodA + = bc > > > 32 ;', 'result * = x ;', 'zb * = epsilon ;', 'mantissa | = 1 < < 23 ;', 'za * = ya ;', 'b + = costB * cosEpsA + costA * cosEpsB + costB * cosEpsB ;', 'prod2B + = bc < < 32 ;', 'bits | = ( ( long ) next ( 32 ) ) & 0xffffffffL ;', 'ac + = ( bc + ad ) > > > 32 ;', 'mantissa & = 0x000fffffffffffffL ;', 'random > > = 8 ;', 'prodB + = bc < < 32 ;', 'lnza * = epsilon ;', 'b + = d ;', 'mantissa & = 0x007fffff ;', 'mantissa | = 1L < < 52 ;', 'xl & = MASK 30BITS ;', 'e > > = 1 ;', 'mantissa < < = 1 ;', 'b - = sintB * sinEpsA + sintA * sinEpsB + sintB * sinEpsB ;', 'mantissa > > > = 1 - scaledExponent ;', 'b + = sintB + costB * sinEpsA + sintB * cosEpsB + costB * sinEpsB ;'}, 'removed_code': {'z = z * lnb ;', 'mantissa = mantissa & 0x007fffff ;', 'random = random > > 8 ;', 'mantissa = mantissa < < 1 ;', 'b = b + costB * cosEpsA + costA * cosEpsB + costB * cosEpsB ;', 'result = result * x ;', 'prodA = prodA + ( bc > > > 32 ) ;', 'xl = xl & MASK 30BITS ;', 'za = za * ya ;', 'mantissa = mantissa | ( 1L < < 52 ) ;', 'mantissa = mantissa & 0x000fffffffffffffL ;', 'b = b + d ;', 'prod2B = prod2B + ( bc < < 32 ) ;', 'mantissa = mantissa > > > ( 1 - scaledExponent ) ;', 'b = b + sintB + costB * sinEpsA + sintB * cosEpsB + costB * sinEpsB ;', 'ac = ac + ( ( bc + ad ) > > > 32 ) ;', 'zb = zb * epsilon ;', 'b = b - ( sintB * sinEpsA + sintA * sinEpsB + sintB * sinEpsB ) ;', 'b = b + sintA * cosEpsB + costA * sinEpsB ;', 'bits = bits | ( ( ( long ) next ( 32 ) ) & 0xffffffffL ) ;', 'prod2A = prod2A + ( bc > > > 32 ) ;', 'mantissa = mantissa | ( 1 < < 23 ) ;', 'lnza = lnza * epsilon ;', 'prodB = prodB + ( bc < < 32 ) ;', 'e = e > > 1 ;'}}"
f10cb0ae4f7e395bff64990f94cf32ffa21b668a,1.0,[ CONFIGURATION - 518 ] Added set methods to AbstractConfiguration to manipulate the Lookup objects of the current ConfigurationInterpolator .,"{'added_code': {'if ( confLookup = = null )', 'import java . util . concurrent . atomic . AtomicReference ;', 'do', 'ciNew . removeDefaultLookup ( confLookup ) ;', 'return null ;', 'return interpolator . get ( ) ;', 'interpolator = new AtomicReference < ConfigurationInterpolator > ( ) ;', 'ConfigurationInterpolator ciOld = getInterpolator ( ) ;', 'ConfigurationInterpolator ciNew =', 'private final AtomicReference < ConfigurationInterpolator > interpolator ;', '{', 'confLookup = new ConfigurationLookup ( this ) ;', '( ciOld ! = null ) ? ciOld : new ConfigurationInterpolator ( ) ;', 'else', 'ciNew . registerLookups ( lookups ) ;', 'public final void setDefaultLookups ( Collection < ? extends Lookup > lookups )', 'success = interpolator . compareAndSet ( ciOld , ciNew ) ;', 'for ( Lookup l : ci . getDefaultLookups ( ) )', 'public final void setPrefixLookups ( Map < String , ? extends Lookup > lookups )', 'interpolator . set ( ci ) ;', 'if ( this = = ( ( ConfigurationLookup ) l ) . getConfiguration ( ) )', 'ciNew . addDefaultLookup ( confLookup ) ;', 'ciNew . addDefaultLookups ( lookups ) ;', 'if ( l instanceof ConfigurationLookup )', 'boolean success ;', '} while ( !success ) ;', 'Lookup confLookup = findConfigurationLookup ( ciNew ) ;', 'private Lookup findConfigurationLookup ( ConfigurationInterpolator ci )', 'return l ;', '}'}, 'removed_code': {'return interpolator ;', 'private volatile ConfigurationInterpolator interpolator ;', 'interpolator = ci ;'}}"
2e96cd40c91e1b40196d0d50a9e9c36e04b8465a,1.0,FIX : Resolved Ivy properties written to cache during ivy : resolve incorrectly represents forced revisions ( IVY - 1159 ),"{'added_code': {'String forcedRev = forcedRevisionId = = null ? rev : forcedRevisionId . getRevision ( ) ;', 'forcedRevisions . put ( dependencies [ i ] . getModuleId ( ) , dependencies [ i ] . getResolvedId ( ) ) ;', 'if ( dependencies [ i ] . getModuleRevision ( ) ! = null', 'ModuleRevisionId forcedRevisionId = ( ModuleRevisionId )', '& & dependencies [ i ] . getModuleRevision ( ) . isForce ( )', '& & !depResolvedId . equals ( depRevisionId )', 'forcedRevisions . get ( dependencies [ i ] . getModuleId ( ) ) ;', '& & !settings . getVersionMatcher ( ) . isDynamic ( depRevisionId ) ) {', '& & dependencies [ i ] . getModuleRevision ( ) . isForce ( ) ) {', 'depResolvedId = depRevisionId ;', 'import java . util . Map ;', 'props . put ( depRevisionId . encodeToString ( ) , rev + "" "" + status + "" "" + forcedRev ) ;', 'import java . util . HashMap ;', 'depDescriptor = null ;', 'for ( int i = 0 ; i < dependencies . length ; i + + ) {', 'Map forcedRevisions = new HashMap ( ) ;', '}'}, 'removed_code': {'props . put ( depRevisionId . encodeToString ( ) , rev + "" "" + status ) ;'}}"
454fc3655509f1f4f47ce44acaff7c1566ede108,1.0,PARQUET - 342 : Updates to be Java 6 compatible Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #248 from nezihyigitbasi / java6 - fixes and squashes the following commits : 2ab2598 [ Nezih Yigitbasi ] Updates to be Java 6 compatible,"{'added_code': {'int compareIntegers ( int x , int y ) {', 'int compareBooleans ( boolean x , boolean y ) {', 'return compareBooleans ( o . prerelease , prerelease ) ;', 'cmp = compareIntegers ( patch , o . patch ) ;', 'return ( x < y ) ? - 1 : ( ( x = = y ) ? 0 : 1 ) ;', 'cmp = compareIntegers ( minor , o . minor ) ;', '}', 'return ( x = = y ) ? 0 : ( x ? 1 : - 1 ) ;', 'cmp = compareIntegers ( major , o . major ) ;'}, 'removed_code': {'cmp = Integer . compare ( minor , o . minor ) ;', 'cmp = Integer . compare ( patch , o . patch ) ;', 'return Boolean . compare ( o . prerelease , prerelease ) ;', 'cmp = Integer . compare ( major , o . major ) ;'}}"
ae01f0399cae6baab045b2ece0d71096aebe8ca3,1.0,GIRAPH - 732,"{'added_code': {'return textOutputFormat . getRecordWriter ( context ) ;', 'lineRecordWriter . close ( context ) ;', 'msg . append ( delimiter ) ;', 'extends EdgeWriter < I , V , E > {', 'throws IOException , InterruptedException {', 'new GiraphTextOutputFormat ( ) {', 'protected GiraphTextOutputFormat textOutputFormat =', 'protected abstract Text convertEdgeToLine ( I sourceId ,', 'V sourceValue , Edge < I , E > edge ) throws IOException ;', 'public TextEdgeWriter createEdgeWriter ( TaskAttemptContext context ) {', 'msg . append ( edge . getTargetVertexId ( ) . toString ( ) ) ;', 'public RecordWriter < Text , Text > getRecordWriter ( ) {', 'private TaskAttemptContext context ;', 'ClassConfOption . create ( ""giraph . edgeOutputFormatClass"" , null ,', 'StrConfOption GIRAPH TEXT OUTPUT FORMAT SEPARATOR =', 'new StrConfOption ( ""giraph . vertex . output . subdir"" , """" ,', 'ClassConfOption < EdgeOutputFormat > EDGE OUTPUT FORMAT CLASS =', 'extends TextEdgeWriterToEachLine {', 'msg . append ( sourceId . toString ( ) ) ;', 'import static org . apache . giraph . conf . GiraphConstants . GIRAPH TEXT OUTPUT FORMAT SEPARATOR ;', 'msg . append ( edge . getValue ( ) . toString ( ) ) ;', 'V extends Writable , E extends Writable >', 'public TaskAttemptContext getContext ( ) {', 'protected String getSubdir ( ) {', 'context ) throws IOException , InterruptedException ;', 'delimiter = GIRAPH TEXT OUTPUT FORMAT SEPARATOR . get ( getConf ( ) ) ;', '} ;', 'return new Text ( msg . toString ( ) ) ;', 'public OutputCommitter getOutputCommitter ( TaskAttemptContext context )', 'import org . apache . hadoop . mapreduce . RecordWriter ;', 'protected RecordWriter < Text , Text > createLineRecordWriter (', 'import org . apache . hadoop . mapreduce . OutputCommitter ;', 'import org . apache . hadoop . mapreduce . JobContext ;', '""EdgeOutputFormat sub - directory"" ) ;', '@ Override', 'public void checkOutputSpecs ( JobContext context )', 'import org . apache . hadoop . mapreduce . TaskAttemptContext ;', 'protected Text convertEdgeToLine ( I sourceId , V sourceValue , Edge < I , E > edge )', 'EdgeOutputFormat . class , ""EdgeOutputFormat class"" ) ;', 'convertEdgeToLine ( sourceId , sourceValue , edge ) , null ) ;', 'if ( reverseOutput ) {', '} else {', 'return textOutputFormat . getOutputCommitter ( context ) ;', 'public abstract TextEdgeWriter createEdgeWriter ( TaskAttemptContext', 'throws IOException {', 'import org . apache . hadoop . io . Writable ;', 'this . context = context ;', 'StrConfOption VERTEX OUTPUT FORMAT SUBDIR =', 'public class SrcIdDstIdEdgeValueTextOutputFormat < I extends WritableComparable ,', '""VertexOutputFormat sub - directory"" ) ;', '""Reverse values in the output"" ) ;', 'return context ;', 'InterruptedException {', 'return lineRecordWriter ;', 'extends TextEdgeOutputFormat < I , V , E > {', 'return EDGE OUTPUT FORMAT SUBDIR . get ( getConf ( ) ) ;', 'public void initialize ( TaskAttemptContext context )', 'public void close ( TaskAttemptContext context ) throws IOException ,', 'protected abstract class TextEdgeWriterToEachLine extends TextEdgeWriter {', 'extends EdgeOutputFormat < I , V , E > {', 'new BooleanConfOption ( ""giraph . textoutputformat . reverse"" , false ,', 'import static org . apache . giraph . conf . GiraphConstants . EDGE OUTPUT FORMAT SUBDIR ;', 'package org . apache . giraph . io . formats ;', 'TaskAttemptContext context ) throws IOException , InterruptedException {', 'public abstract class TextEdgeOutputFormat < I extends WritableComparable ,', 'import org . apache . hadoop . io . Text ;', '}', 'BooleanConfOption GIRAPH TEXT OUTPUT FORMAT REVERSE =', 'import org . apache . giraph . edge . Edge ;', 'new StrConfOption ( ""giraph . textoutputformat . separator"" , """" ,', 'private String delimiter ;', 'textOutputFormat . checkOutputSpecs ( context ) ;', 'StringBuilder msg = new StringBuilder ( ) ;', '@ SuppressWarnings ( ""rawtypes"" )', 'private RecordWriter < Text , Text > lineRecordWriter ;', 'super . initialize ( context ) ;', 'public final void writeEdge ( I sourceId , V sourceValue , Edge < I , E > edge )', 'StrConfOption EDGE OUTPUT FORMAT SUBDIR =', 'protected abstract class TextEdgeWriter', 'public void initialize ( TaskAttemptContext context ) throws IOException ,', 'reverseOutput = GIRAPH TEXT OUTPUT FORMAT REVERSE . get ( getConf ( ) ) ;', 'import org . apache . hadoop . io . WritableComparable ;', 'import org . apache . giraph . io . EdgeOutputFormat ;', 'private boolean reverseOutput ;', 'import static org . apache . giraph . conf . GiraphConstants . GIRAPH TEXT OUTPUT FORMAT REVERSE ;', 'getRecordWriter ( ) . write (', 'import org . apache . giraph . io . EdgeWriter ;', 'return new SrcIdDstIdEdgeValueEdgeWriter ( ) ;', 'import java . io . IOException ;', '""GiraphTextOuputFormat Separator"" ) ;', 'lineRecordWriter = createLineRecordWriter ( context ) ;', 'protected class SrcIdDstIdEdgeValueEdgeWriter', 'new StrConfOption ( ""giraph . edge . output . subdir"" , ""edges"" ,'}, 'removed_code': set()}"
7cc54575d867e37a43020df309a78cd65c3fbdc0,1.0,GIRAPH - 792 : Print job progress to command line ( majakabiljo ),"{'added_code': {'public void run ( ) {', 'if ( zk . exists ( workerProgressBasePath , false ) ! = null ) {', 'try {', 'WritableUtils . readFieldsFromByteArray ( zkData , workerProgress ) ;', 'submittedJob , GiraphConstants . ZOOKEEPER BASE PATH COUNTER GROUP ) ;', 'verticesToStore + = getPartitionStore ( ) . getOrCreatePartition (', 'import org . apache . giraph . conf . GiraphConfiguration ;', 'new Progressable ( ) {', 'private ZooKeeperExt zk ;', '} finally {', 'byte [ ] zkData = zk . getData ( workerProgressPath , false , null ) ;', 'private final Thread writerThread ;', 'private static final Logger LOG = Logger . getLogger ( JobProgressTracker . class ) ;', 'Thread . sleep ( ( long ) ( WRITE UPDATE PERIOD MILLISECONDS * factor ) ) ;', 'WorkerProgress . get ( ) . addVerticesStored (', 'zk = new ZooKeeperExt (', 'this ,', 'WorkerProgress . get ( ) . incrementPartitionsStored ( ) ;', 'import org . apache . log4j . Logger ;', 'private void instantiateBspService ( )', 'private static final Logger LOG =', 'zk . createExt (', 'workerProgressWriter = conf . trackJobProgressOnClient ( ) ?', 'final String basePath = CounterUtils . waitAndGetCounterNameFromGroup (', 'private static final int WRITE UPDATE PERIOD MILLISECONDS = 10 * 1000 ;', 'WorkerProgress workerProgress = new WorkerProgress ( ) ;', 'import org . apache . giraph . utils . WritableUtils ;', 'writerThread . interrupt ( ) ;', 'WorkerProgress . get ( ) . startSuperstep (', 'public void stop ( ) {', 'if ( LOG . isInfoEnabled ( ) ) {', 'break ;', 'finished = true ;', 'conf . getZookeeperOpsMaxAttempts ( ) ,', 'basePath + BspService . CLEANED UP DIR + "" / client"" ,', '@ Override', 'zkServer ,', 'super ( context , graphTaskManager ) ;', 'WorkerProgress . writeToZnode ( zk , myProgressPath ) ;', 'WorkerProgress . get ( ) . finishLoadingVertices ( ) ;', 'LOG . info ( combinedWorkerProgress . toString ( ) ) ;', 'null ,', 'ZooDefs . Ids . OPEN ACL UNSAFE ,', 'import org . apache . zookeeper . CreateMode ;', 'private static final long VERTICES TO UPDATE PROGRESS = 100000 ;', 'CombinedWorkerProgress combinedWorkerProgress =', 'VERTICES TO UPDATE PROGRESS ) ;', 'import org . apache . giraph . utils . CounterUtils ;', 'serviceWorker . getSuperstep ( ) ,', 'writerThread . start ( ) ;', 'import org . apache . giraph . worker . WorkerProgress ;', 'workerProgressBasePath , false , false , true ) ;', 'WorkerProgress . get ( ) . finishLoadingEdges ( ) ;', 'import org . apache . zookeeper . ZooDefs ;', 'verticesToCompute ,', 'if ( verticesWritten > = nextUpdateProgressVertices ) {', 'public WorkerProgressWriter ( final String myProgressPath ,', 'verticesToCompute + =', 'long verticesToStore = 0 ;', 'double factor = 1 + Math . random ( ) ;', 'private volatile boolean finished = false ;', 'for ( int partitionId : getPartitionStore ( ) . getPartitionIds ( ) ) {', 'package org . apache . giraph . job ;', 'WorkerProgress . get ( ) . startStoring (', 'verticesWritten % VERTICES TO UPDATE PROGRESS ) ;', 'import org . apache . hadoop . util . Progressable ;', 'nextUpdateProgressVertices + = VERTICES TO UPDATE PROGRESS ;', 'private final WorkerProgressWriter workerProgressWriter ;', 'partitionId ) . getVertexCount ( ) ;', 'import org . apache . giraph . bsp . BspService ;', 'Thread . sleep ( UPDATE MILLISECONDS ) ;', 'WorkerProgress . writeToZnode ( getZkExt ( ) , myProgressPath ) ;', 'final GiraphConfiguration conf ) throws IOException , InterruptedException {', 'true ) ;', 'LOG . info ( ""run : WorkerProgressWriter interrupted"" , e ) ;', 'public void process ( WatchedEvent event ) {', 'CreateMode . PERSISTENT ,', 'public class WorkerProgressWriter {', 'String workerProgressBasePath = basePath + BspService . WORKER PROGRESSES ;', 'conf . getZooKeeperSessionTimeout ( ) ,', '} catch ( InterruptedException | KeeperException e ) {', 'import org . apache . hadoop . mapreduce . Job ;', 'final ZooKeeperExt zk ) {', 'import org . apache . giraph . conf . GiraphConstants ;', 'new CombinedWorkerProgress ( workerProgresses ) ;', 'LOG . info ( ""run : Exception occurred"" , e ) ;', 'WorkerProgress . get ( ) . finishStoring ( ) ;', 'submittedJob , GiraphConstants . ZOOKEEPER SERVER PORT COUNTER GROUP ) ;', '}', '} ) ;', 'private Thread writerThread ;', 'public void progress ( ) {', 'new ArrayList < WorkerProgress > ( workerProgressPaths . size ( ) ) ;', 'long nextUpdateProgressVertices = 0 ;', 'zk . close ( ) ;', 'public JobProgressTracker ( final Job submittedJob ,', 'import org . apache . zookeeper . Watcher ;', 'package org . apache . giraph . worker ;', 'import java . util . ArrayList ;', 'for ( String workerProgressPath : workerProgressPaths ) {', 'writerThread = new Thread ( new Runnable ( ) {', 'serviceMaster = new BspServiceMaster < I , V , E > ( context , this ) ;', 'List < WorkerProgress > workerProgresses =', 'public class JobProgressTracker implements Watcher {', 'workerProgresses . add ( workerProgress ) ;', 'import org . apache . zookeeper . KeeperException ;', 'List < String > workerProgressPaths = zk . getChildrenExt (', 'serviceWorker = new BspServiceWorker < I , V , E > ( context , this ) ;', 'import java . util . List ;', 'new WorkerProgressWriter ( myProgressPath , getZkExt ( ) ) : null ;', 'while ( !finished ) {', 'serviceWorker . getPartitionStore ( ) . getOrCreatePartition (', 'serviceWorker . getPartitionStore ( ) . getNumPartitions ( ) ) ;', 'private static final int UPDATE MILLISECONDS = 5 * 1000 ;', 'import org . apache . giraph . zk . ZooKeeperExt ;', 'String zkServer = CounterUtils . waitAndGetCounterNameFromGroup (', 'import org . apache . zookeeper . WatchedEvent ;', '} catch ( InterruptedException e ) {', 'if ( combinedWorkerProgress . isDone ( conf . getMaxWorkers ( ) ) ) {', 'Logger . getLogger ( WorkerProgressWriter . class ) ;', 'if ( workerProgressWriter ! = null ) {', 'conf . getZookeeperOpsRetryWaitMsecs ( ) ,', 'instantiateBspService ( ) ;', 'workerProgressWriter . stop ( ) ;', 'long verticesToCompute = 0 ;', 'import java . io . IOException ;', 'verticesToStore , getPartitionStore ( ) . getNumPartitions ( ) ) ;'}, 'removed_code': {'sessionMsecTimeout , context , this ) ;', 'int sessionMsecTimeout = conf . getZooKeeperSessionTimeout ( ) ;', 'instantiateBspService ( sessionMsecTimeout ) ;', 'int sessionMsecTimeout ,', 'serviceWorker = new BspServiceWorker < I , V , E > (', 'super ( sessionMsecTimeout , context , graphTaskManager ) ;', 'private void instantiateBspService ( int sessionMsecTimeout )', '}', 'serviceMaster = new BspServiceMaster < I , V , E > ('}}"
b17feea4827863c85207c0aaa5c8c5b035d27df1,1.0,"SCXML - 197 : Better separation of concern between SCXMLExecutor and SCInstance and introducing a new SCXMLExecutionContext See : https : / / issues . apache . org / jira / browse / SCXML - 197 - move all persistable state to SCInstance and support detach / ( re ) attach the instance from the SCXMLExecutor , which no longer is Serializable - introduce a new SCXMLExecutionContext to encapsulate all internal API and services - switch to using the SCXMLExecutionContext as primary interface ( parameter ) for the SCXMLSemantics algorithms - switch to use a restricted ActionExecutionContext ( subset of SCXMLExecutionContext ) as interface for the Action ( SCXML Executable Content ) execution - add internal and ( synchronous ) external event queues and switch to 'single event step' processing as requirement by the SCXML specification","{'added_code': {'this . actionExecutionContext = new ActionExecutionContext ( this ) ;', 'return executor . getSCInstance ( ) ;', 'internalEventQueue . add ( event ) ;', 'setEventData ( event ) ;', 'try {', 'public SCInstance getScInstance ( ) {', 'cancelInvoker ( invoke ) ;', 'internalEventQueue . clear ( ) ;', 'if ( event ! = null ) {', 'return invokeIds ;', 'return executor . getEvaluator ( ) ;', 'public Evaluator getEvaluator ( ) {', 'public Log getAppLog ( ) {', 'invokerClasses . put ( type , invokerClass ) ;', 'SCXMLExecutionContext ( SCXMLExecutor executor ) {', '} catch ( IllegalAccessException iae ) {', 'package org . apache . commons . scxml2 ;', 'for ( EnterableState es : getCurrentStatus ( ) . getStates ( ) ) {', '@ SuppressWarnings ( ""unused"" )', 'step = new Step ( event , getCurrentStatus ( ) ) ;', 'private final SCXMLExecutor executor ;', 'import org . apache . commons . scxml2 . ActionExecutionContext ;', 'throws ModelException {', 'private final Map < Invoke , String > invokeIds = new HashMap < Invoke , String > ( ) ;', 'triggerEvents ( ) ;', 'if ( scInstance ! = null ) {', 'eventVar = new EventVariable ( evt . getName ( ) , eventType , null , null , null , null , eventData ) ;', 'throw new InvokerException ( ""No Invoker registered for type \\ """"', 'Datamodel rootdm = stateMachine . getDatamodel ( ) ;', 'String invokeId = invokeIds . get ( invoke ) ;', 'import org . apache . commons . logging . Log ;', 'import java . util . Queue ;', 'if ( evt ! = null ) {', 'for ( Invoke invoke : new ArrayList < Invoke > ( invokeIds . keySet ( ) ) ) {', 'public ErrorReporter getErrorReporter ( ) {', 'this . evaluator = evaluator ;', 'Class < ? extends Invoker > invokerClass = invokerClasses . get ( type ) ;', 'semantics . updateHistoryStates ( exctx , step ) ;', 'this . exctx = new SCXMLExecutionContext ( this ) ;', 'return notificationRegistry ;', 'public boolean hasPendingEvents ( ) {', 'semantics . enterStates ( exctx , step ) ;', 'SCXML stateMachine = getStateMachine ( ) ;', 'final int triggerEventType = evt . getType ( ) ;', 'return internalEventQueue . poll ( ) ;', 'public void attachInstance ( SCInstance instance ) {', 'throw new InvokerException ( iae . getMessage ( ) , iae . getCause ( ) ) ;', 'Invoker newInvoker ( final String type )', 'public Map < Invoke , String > getInvokeIds ( ) {', 'removeInvoker ( invoke ) ;', 'if ( triggerEventType = = TriggerEvent . ERROR EVENT | | triggerEventType = = TriggerEvent . CHANGE EVENT ) {', 'return invokerClass . newInstance ( ) ;', 'return executor . getErrorReporter ( ) ;', 'import org . apache . commons . scxml2 . model . SCXML ;', '} while ( event ! = null ) ;', 'this . notificationRegistry = new NotificationRegistry ( ) ;', 'public void triggerEvents ( final TriggerEvent [ ] evts )', 'externalEventQueue . add ( evt ) ;', 'if ( SCXMLHelper . isStringEmpty ( invokeId ) ) {', 'private Evaluator evaluator ;', 'public void triggerEvents ( ) throws ModelException {', 'semantics . filterTransitionsSet ( exctx , step ) ;', 'import java . util . LinkedList ;', 'getCurrentStatus ( ) . getStates ( ) . clear ( ) ;', 'scInstance . setExecutor ( this ) ;', 'throws InvokerException {', 'if ( getStateMachine ( ) = = null ) {', 'scInstance . setExecutor ( null ) ;', 'return scInstance . getCurrentStatus ( ) ;', '} catch ( InvokerException ie ) {', 'public class SCXMLExecutor {', 'if ( !invokeIds . isEmpty ( ) ) {', 'import org . apache . commons . scxml2 . invoke . Invoker ;', 'import java . util . UUID ;', '+ "" . invoke . cancel . failed"" , TriggerEvent . ERROR EVENT ) ;', 'externalEventQueue . clear ( ) ;', 'scInstance = instance ;', 'addInternalEvent ( te ) ;', 'SCXMLHelper . cloneDatamodel ( rootdm , rootContext , getEvaluator ( ) , log ) ;', 'return evaluator ;', 'return actionExecutionContext ;', 'handleEvent ( evt ) ;', 'public class SCXMLExecutionContext {', 'private void setEventData ( final TriggerEvent evt ) {', 'import java . util . concurrent . ConcurrentLinkedQueue ;', '} catch ( InstantiationException ie ) {', 'public ActionExecutionContext getActionExecutionContext ( ) {', 'exctx . reset ( ) ;', 'import java . util . HashMap ;', 'invokeId = UUID . randomUUID ( ) . toString ( ) ;', 'String invokeId = invoke . getId ( ) ;', 'public SCXML getStatemachine ( ) {', 'Context rootContext = scInstance . getRootContext ( ) ;', 'this . invokerClasses = new HashMap < String , Class < ? extends Invoker > > ( ) ;', 'return executor . getNotificationRegistry ( ) ;', 'private Log appLog = LogFactory . getLog ( SCXMLExecutionContext . class ) ;', 'running = true ;', 'throw new InvokerException ( ie . getMessage ( ) , ie . getCause ( ) ) ;', 'for ( TriggerEvent evt : evts ) {', 'public String setInvoker ( final Invoke invoke , final Invoker invoker ) {', 'scInstance . getRootContext ( ) . setLocal ( "" ALL STATES"" , getCurrentStatus ( ) . getAllStates ( ) ) ;', 'this . running = false ;', 'public Invoker getInvoker ( final Invoke invoke ) {', 'private final Queue < TriggerEvent > externalEventQueue = new ConcurrentLinkedQueue < TriggerEvent > ( ) ;', 'this . executor = executor ;', 'while ( ( evt = externalEventQueue . poll ( ) ) ! = null ) {', 'if ( invokeId ! = null ) {', 'import org . apache . commons . scxml2 . model . Invoke ;', 'return appLog ;', 'semantics . executeActions ( exctx , step ) ;', 'Step step = new Step ( null , getCurrentStatus ( ) ) ;', 'private NotificationRegistry notificationRegistry ;', 'semantics . enumerateReachableTransitions ( exctx , step ) ;', 'eventData = evt . getPayload ( ) ;', 'private final Map < String , Invoker > invokers = new HashMap < String , Invoker > ( ) ;', 'void setNotificationRegistry ( final NotificationRegistry notifRegistry ) {', 'rootCtx . setLocal ( EVENT DATA MAP , payloadMap ) ;', 'EventVariable eventVar = null ;', 'if ( invokerClass = = null ) {', 'private final ActionExecutionContext actionExecutionContext ;', 'notificationRegistry . removeListener ( observable , listener ) ;', 'if ( evts ! = null ) {', 'return invokeId ;', 'private SCXMLExecutionContext exctx ;', 'exctx . getEventDispatcher ( ) . cancel ( sendid ) ;', 'private final Map < String , Class < ? extends Invoker > > invokerClasses ;', 'semantics . executeGlobalScript ( exctx , step ) ;', 'Map < String , Object > payloadMap = new HashMap < String , Object > ( ) ;', 'semantics . processInvokes ( exctx , evt ) ;', 'scInstance = null ;', 'public SCInstance detachInstance ( ) {', 'this . notificationRegistry = notifRegistry ;', 'invokerClasses . remove ( type ) ;', 'return executor . getEventdispatcher ( ) ;', 'void reset ( ) {', 'TriggerEvent te = new TriggerEvent ( invokeId', 'event = exctx . nextInternalEvent ( ) ;', 'getCurrentStatus ( ) . getStates ( ) . addAll ( step . getAfterStatus ( ) . getStates ( ) ) ;', 'public Invoker newInvoker ( String type ) throws InvokerException {', 'rootCtx . setLocal ( EVENT VARIABLE , eventVar ) ;', 'import java . util . Map ;', 'String eventType = EventVariable . TYPE EXTERNAL ;', '}', 'payloadMap . put ( evt . getName ( ) , evt . getPayload ( ) ) ;', 'return executor . getStateMachine ( ) ;', 'private boolean running ;', 'Object eventData = null ;', 'this . evaluator = expEvaluator ;', 'handleEvent ( event ) ;', 'semantics . determineInitialStates ( exctx , step ) ;', '@ SuppressWarnings ( ""unused deprecation"" )', 'SCInstance instance = scInstance ;', 'SCXMLHelper . cloneDatamodel ( dm , context , getEvaluator ( ) , log ) ;', 'public void addEvent ( final TriggerEvent evt ) {', 'import java . util . ArrayList ;', 'return instance ;', 'public NotificationRegistry getNotificationRegistry ( ) {', 'return invokers . get ( invokeIds . get ( invoke ) ) ;', 'public void removeInvoker ( final Invoke invoke ) {', 'scInstance . setStateMachine ( semantics . normalizeStateMachine ( stateMachine , errorReporter ) ) ;', 'invokeIds . put ( invoke , invokeId ) ;', 'import org . apache . commons . scxml2 . invoke . InvokerException ;', 'rootCtx . setLocal ( EVENT DATA , eventData ) ;', 'public void execute ( ActionExecutionContext exctx ) throws ModelException , SCXMLExpressionException {', 'public boolean isRunning ( ) {', 'TriggerEvent nextInternalEvent ( ) {', 'semantics . initiateInvokes ( this , exctx , step ) ;', 'invokers . put ( invokeId , invoker ) ;', 'import org . apache . commons . logging . LogFactory ;', 'TriggerEvent evt ;', 'return !externalEventQueue . isEmpty ( ) ;', 'TriggerEvent event = evt ;', 'protected void handleEvent ( final TriggerEvent evt )', 'semantics . followTransitions ( exctx , step ) ;', 'eventType = EventVariable . TYPE PLATFORM ;', 'return scInstance . getStateMachine ( ) ;', 'return executor . newInvoker ( type ) ;', 'TriggerEvent event = exctx . nextInternalEvent ( ) ;', 'public EventDispatcher getEventDispatcher ( ) {', 'public void addInternalEvent ( TriggerEvent event ) {', 'private final Queue < TriggerEvent > internalEventQueue = new LinkedList < TriggerEvent > ( ) ;', 'notificationRegistry . addListener ( observable , listener ) ;', 'public void stopRunning ( ) {', 'invokers . get ( invokeId ) . cancel ( ) ;', 'invokers . remove ( invokeIds . remove ( invoke ) ) ;', 'return running ;', 'public void cancelInvoker ( Invoke invoke ) {', '+ type + "" \\ """" ) ;'}, 'removed_code': {'for ( TriggerEvent te : evts ) {', '} while ( superStep & & currentStatus . getEvents ( ) . size ( ) > 0 ) ;', 'eventVar = new EventVariable ( evts [ 0 ] . getName ( ) , eventType , null , null , null , null , eventData ) ;', 'this . stateMachine = semantics . normalizeStateMachine ( stateMachine , errorReporter ) ;', 'if ( superStep ) {', 'scInstance . getRootContext ( ) . setLocal ( EVENT VARIABLE , oldData [ 2 ] ) ;', 'List < TriggerEvent > evs = new ArrayList < TriggerEvent > ( Arrays . asList ( evts ) ) ;', 'return scInstance . getEvaluator ( ) ;', 'this . scInstance . setEvaluator ( evaluator ) ;', 'semantics . executeGlobalScript ( step , stateMachine , eventdispatcher , errorReporter , scInstance ) ;', 'semantics . processInvokes ( evts , errorReporter , scInstance ) ;', 'import java . io . Serializable ;', 'private static final long serialVersionUID = 1L ;', 'eventData = evts [ 0 ] . getPayload ( ) ;', 'Context rootCtx = scInstance . getRootContext ( ) ;', 'private void restoreEventData ( final Object [ ] oldData ) {', 'scInstance . registerInvokerClass ( type , invokerClass ) ;', 'import java . util . Collection ;', '@ SuppressWarnings ( ""deprecation"" )', 'Datamodel rootdm = stateMachine . getDatamodel ( ) ;', 'Object [ ] oldData = setEventData ( evts ) ;', 'import org . apache . commons . logging . Log ;', 'SCXMLHelper . cloneDatamodel ( rootdm , rootCtx ,', 'currentStatus = step . getAfterStatus ( ) ;', 'if ( superStep & & currentStatus . getEvents ( ) . size ( ) > 0 ) {', 'return oldData ;', 'import org . apache . commons . scxml2 . EventDispatcher ;', 'semantics . updateHistoryStates ( step , errorReporter , scInstance ) ;', 'scInstance . getRootContext ( ) . setLocal ( EVENT DATA , oldData [ 0 ] ) ;', 'currentStatus = new Status ( ) ;', 'if ( triggerEventType = = TriggerEvent . ERROR EVENT | | triggerEventType = = TriggerEvent . CHANGE EVENT ) {', 'SCXMLHelper . getAncestorClosure ( currentStatus . getStates ( ) , null ) ) ;', 'private Object [ ] setEventData ( final TriggerEvent [ ] evts ) {', 'restoreEventData ( oldData ) ;', 'listener ) ;', 'scInstance . getRootContext ( ) . setLocal ( "" ALL STATES"" ,', 'public synchronized void triggerEvents ( final TriggerEvent [ ] evts )', 'semantics . initiateInvokes ( step , errorReporter , scInstance ) ;', 'semantics . enumerateReachableTransitions ( stateMachine , step ,', 'this . scInstance . setEvaluator ( expEvaluator ) ;', '} else {', 'for ( EnterableState es : currentStatus . getStates ( ) ) {', 'if ( stateMachine = = null ) {', 'this . currentStatus = new Status ( ) ;', 'semantics . followTransitions ( step , errorReporter , scInstance ) ;', 'if ( len = = 1 ) {', 'if ( len > 0 ) {', 'semantics . executeActions ( step , stateMachine , eventdispatcher ,', 'semantics . enterStates ( step , stateMachine , eventdispatcher , errorReporter , scInstance ) ;', 'return currentStatus ;', 'this . stateMachine = null ;', 'throws ModelException , SCXMLExpressionException {', 'Step step = new Step ( null , currentStatus ) ;', 'import org . apache . commons . scxml2 . SCInstance ;', 'errorReporter , scInstance ) ;', 'return stateMachine ;', 'evs . clear ( ) ;', 'scInstance . getNotificationRegistry ( ) . addListener ( observable , listener ) ;', 'evtDispatcher . cancel ( sendid ) ;', 'Object [ ] oldData = { rootCtx . get ( EVENT DATA ) , rootCtx . get ( EVENT DATA MAP ) , rootCtx . get ( EVENT VARIABLE ) } ;', 'import org . apache . commons . scxml2 . ErrorReporter ;', 'rootCtx . setLocal ( EVENT DATA MAP , payloadMap ) ;', 'private Status currentStatus ;', 'EventVariable eventVar = null ;', 'private SCXML stateMachine ;', 'step = new Step ( evs , currentStatus ) ;', 'scInstance . unregisterInvokerClass ( type ) ;', 'scInstance . getNotificationRegistry ( ) . removeListener ( observable ,', 'Map < String , Object > payloadMap = new HashMap < String , Object > ( ) ;', 'import org . apache . commons . scxml2 . model . State ;', 'scInstance . getEvaluator ( ) , log ) ;', 'setEventData ( currentStatus . getEvents ( ) . toArray ( new TriggerEvent [ currentStatus . getEvents ( ) . size ( ) ] ) ) ;', 'final int triggerEventType = evts [ 0 ] . getType ( ) ;', 'rootCtx . setLocal ( EVENT VARIABLE , eventVar ) ;', 'payloadMap . put ( te . getName ( ) , te . getPayload ( ) ) ;', 'String eventType = EventVariable . TYPE EXTERNAL ;', 'int len = evts . length ;', '}', 'public class SCXMLExecutor implements Serializable {', 'import org . apache . commons . scxml2 . TriggerEvent ;', 'this . triggerEvents ( new TriggerEvent [ 0 ] ) ;', 'Object eventData = null ;', 'public void execute ( final EventDispatcher evtDispatcher ,', 'import java . util . ArrayList ;', 'SCXMLHelper . cloneDatamodel ( dm , context , scInstance . getEvaluator ( ) , log ) ;', 'semantics . determineInitialStates ( step , stateMachine , errorReporter , scInstance ) ;', 'semantics . filterTransitionsSet ( step , eventdispatcher ,', 'rootCtx . setLocal ( EVENT DATA , eventData ) ;', 'errorReporter ) ;', 'final ErrorReporter errRep , final SCInstance scInstance ,', 'final Log appLog , final Collection < TriggerEvent > derivedEvents )', 'import java . util . Arrays ;', 'scInstance . getRootContext ( ) . setLocal ( EVENT DATA MAP , oldData [ 1 ] ) ;', 'import java . util . List ;', 'triggerEvents ( new TriggerEvent [ ] { evt } ) ;', 'eventType = EventVariable . TYPE PLATFORM ;'}}"
e7a431fe539df61d38a602c4c44820f1ee0cc4a5,1.0,SCXML - 191 : Support foreach element,"{'added_code': {'for ( Action aa : actions ) {', 'import org . apache . commons . scxml2 . TriggerEvent ;', 'currentIndex + + ;', 'return ELEM FOREACH ;', 'else {', 'import org . apache . commons . scxml2 . SCInstance ;', 'ctx . setLocal ( item , Array . get ( arrayObject , currentIndex ) ) ;', 'try {', 'import org . apache . commons . scxml2 . Context ;', 'ArrayList < Object > arrayList = new ArrayList < Object > ( ) ;', 'public void execute ( final EventDispatcher evtDispatcher ,', 'public String getIndex ( ) {', 'for ( Object value : arrayList ) {', 'Context ctx = scInstance . getContext ( getParentTransitionTarget ( ) ) ;', 'if ( arrayObject . getClass ( ) . isArray ( ) ) {', 'import java . util . ArrayList ;', 'public final List < Action > getActions ( ) {', 'private List < Action > actions ;', 'this . array = array ;', '}', 'public void setIndex ( final String index ) {', 'Evaluator eval = scInstance . getEvaluator ( ) ;', 'import org . apache . commons . scxml2 . SCXMLExpressionException ;', 'ctx . setLocal ( item , value ) ;', 'return item ;', '@ Override', 'return index ;', 'import org . apache . commons . scxml2 . ErrorReporter ;', 'private String item ;', 'if ( action ! = null ) {', 'private static final long serialVersionUID = 1L ;', 'return actions ;', 'this . actions = new ArrayList < Action > ( ) ;', 'private String index ;', 'ctx . setLocal ( getNamespacesKey ( ) , null ) ;', 'super ( ) ;', 'final Log appLog , final Collection < TriggerEvent > derivedEvents )', 'if ( arrayObject ! = null & & arrayObject instanceof Iterable | | arrayObject . getClass ( ) . isArray ( ) ) {', 'final ErrorReporter errRep , final SCInstance scInstance ,', 'for ( int currentIndex = 0 , size = Array . getLength ( arrayObject ) ; currentIndex < size ; currentIndex + + ) {', 'import java . lang . reflect . Array ;', 'finally {', 'import java . util . Collection ;', 'aa . execute ( evtDispatcher , errRep , scInstance , appLog , derivedEvents ) ;', 'package org . apache . commons . scxml2 . model ;', 'import java . util . List ;', 'import org . apache . commons . logging . Log ;', 'this . actions . add ( action ) ;', 'public final void addAction ( final Action action ) {', 'private String array ;', 'this . item = item ;', 'import org . apache . commons . scxml2 . EventDispatcher ;', 'ctx . setLocal ( index , currentIndex ) ;', 'ctx . setLocal ( getNamespacesKey ( ) , getNamespaces ( ) ) ;', 'for ( Object value : ( Iterable ) arrayObject ) {', 'this . index = index ;', 'public String getArray ( ) {', 'return array ;', 'public final String getContainerElementName ( ) {', 'arrayList . add ( value ) ;', 'public String getItem ( ) {', 'public void setArray ( final String array ) {', 'public class Foreach extends Action implements ActionsContainer {', 'int currentIndex = 0 ;', 'import org . apache . commons . scxml2 . Evaluator ;', 'public Foreach ( ) {', 'if ( index ! = null ) {', 'Object arrayObject = eval . eval ( ctx , array ) ;', 'public void setItem ( final String item ) {', 'throws ModelException , SCXMLExpressionException {'}, 'removed_code': set()}"
8ff987bd1b9ad2b00d32f8bd6594bffc27cff335,1.0,OPENNLP - 777 - naive bayes classifier ( patch from Cohan Sujay Carlos ),"{'added_code': {'System . err . println ( outcomePatterns . size ( ) + "" outcome patterns"" ) ;', 'activeOutcomes [ pi ] = tmpOutcomes [ pi ] ;', 'return outcomePatterns ;', 'writeDouble ( sorted [ i ] . params [ j ] ) ;', 'package opennlp . tools . ml . naivebayes ;', 'numParams + + ;', 'if ( numParams ! = 0 ) {', 'public abstract class NaiveBayesModelWriter extends AbstractModelWriter {', 'for ( int pid = 0 ; pid < PARAMS . length ; pid + + ) {', 'ComparablePredicate [ ] sorted = sortValues ( ) ;', 'int numOutcomes ;', 'import opennlp . tools . ml . model . IndexHashTable ;', 'PRED LABELS = new String [ pmap . size ( ) ] ;', 'for ( int pi = 0 ; pi < predParams . length ; pi + + ) {', 'List < List < ComparablePredicate > > outcomePatterns = new ArrayList < List < ComparablePredicate > > ( ) ;', 'public void persist ( ) throws IOException {', 'tmpParams [ numParams ] = predParams [ pi ] ;', 'writeUTF ( label ) ;', 'protected String [ ] OUTCOME LABELS ;', 'IndexHashTable < String > pmap = ( IndexHashTable < String > ) data [ 1 ] ;', 'protected List < List < ComparablePredicate > > computeOutcomePatterns ( ComparablePredicate [ ] sorted ) {', 'cp = predicate ;', 'writeInt ( sorted . length ) ;', 'writeUTF ( a . size ( ) + a . get ( 0 ) . toString ( ) ) ;', 'ComparablePredicate [ ] sortPreds ;', 'writeUTF ( s . name ) ;', 'protected Context [ ] PARAMS ;', 'double [ ] tmpParams = new double [ numOutcomes ] ;', 'OUTCOME LABELS = ( String [ ] ) data [ 2 ] ;', '} else {', 'for ( int pi = 0 ; pi < numParams ; pi + + ) {', 'import opennlp . tools . ml . model . ComparablePredicate ;', 'public NaiveBayesModelWriter ( AbstractModel model ) {', 'import opennlp . tools . ml . model . Context ;', 'if ( predParams [ pi ] ! = 0d ) {', 'List < List < ComparablePredicate > > compressed = computeOutcomePatterns ( sorted ) ;', 'for ( int j = 0 ; j < sorted [ i ] . params . length ; j + + )', 'sortPreds = new ComparablePredicate [ numPreds ] ;', 'newGroup . add ( predicate ) ;', 'Object [ ] data = model . getDataStructures ( ) ;', 'for ( int i = 0 ; i < sorted . length ; i + + )', 'System . err . println ( ""Compressed "" + PARAMS . length + "" parameters to "" + numPreds ) ;', 'for ( List < ComparablePredicate > a : compressed ) {', 'tmpOutcomes [ numParams ] = outcomePattern [ pi ] ;', 'numPreds + + ;', 'close ( ) ;', 'writeInt ( OUTCOME LABELS . length ) ;', 'this . numOutcomes = model . getNumOutcomes ( ) ;', 'int [ ] activeOutcomes = new int [ numParams ] ;', 'import opennlp . tools . ml . model . AbstractModelWriter ;', 'int [ ] outcomePattern = PARAMS [ pid ] . getOutcomes ( ) ;', 'int numParams = 0 ;', 'if ( cp . compareTo ( predicate ) = = 0 ) {', 'tmpPreds [ numPreds ] = new ComparablePredicate ( PRED LABELS [ pid ] , activeOutcomes , activeParams ) ;', 'import opennlp . tools . ml . model . AbstractModel ;', 'int numPreds = 0 ;', 'ComparablePredicate [ ] tmpPreds = new ComparablePredicate [ PARAMS . length ] ;', '}', 'return sortPreds ;', 'activeParams [ pi ] = tmpParams [ pi ] ;', 'for ( ComparablePredicate predicate : sorted ) {', 'System . arraycopy ( tmpPreds , 0 , sortPreds , 0 , numPreds ) ;', 'for ( ComparablePredicate s : sorted ) {', 'outcomePatterns . add ( newGroup ) ;', 'import java . util . ArrayList ;', 'newGroup = new ArrayList < ComparablePredicate > ( ) ;', 'protected String [ ] PRED LABELS ;', 'PARAMS = ( Context [ ] ) data [ 0 ] ;', 'List < ComparablePredicate > newGroup = new ArrayList < ComparablePredicate > ( ) ;', 'protected ComparablePredicate [ ] sortValues ( ) {', 'double [ ] activeParams = new double [ numParams ] ;', 'int [ ] tmpOutcomes = new int [ numOutcomes ] ;', 'import java . util . Arrays ;', 'pmap . toArray ( PRED LABELS ) ;', 'import java . util . List ;', 'writeInt ( compressed . size ( ) ) ;', 'double [ ] predParams = PARAMS [ pid ] . getParameters ( ) ;', 'Arrays . sort ( sortPreds ) ;', 'writeUTF ( ""NaiveBayes"" ) ;', 'for ( String label : OUTCOME LABELS ) {', 'import java . io . IOException ;', 'ComparablePredicate cp = sorted [ 0 ] ;'}, 'removed_code': set()}"
56326400fcb5df7bd9336f143f7a3b7d601e5f58,1.0,"PARQUET - 99 : Add page size check properties This adds properties to set the min and max number of records that are passed between page checks , as well as a property that controls whether the next check will be based on records already seen or set to the minimum number of records between checks . * `parquet . page . size . row . check . min` - minimum number of records between page size checks * `parquet . page . size . row . check . max` - maximum number of records between page size checks * `parquet . page . size . check . estimate` - whether to estimate the number of records before the next check , or to always use the minimum number of records . This also updates the internal API to use ParquetProperties to carry encoding settings ( used in parquet - column ) to reduce the number of parameters passed through internal APIs . It also adds a builder for ParquetProperties to avoid needing to reference defaults in other modules . This closes #250 Author : Daniel Weeks < dweeks @ netflix . com > Author : Ryan Blue < blue @ apache . org > Closes #297 from rdblue / parquet - properties - update and squashes the following commits : c93b73e [ Ryan Blue ] PARQUET - 99 : Use ParquetProperties to carry encoding config . 18f8d3a [ Daniel Weeks ] Spacing 2090719 [ Daniel Weeks ] Update sizeCheck to write page properly if estimating is turned off 71336ee [ Daniel Weeks ] Fixed param name 5d99072 [ Daniel Weeks ] Update page size checking for v2 writer 3f7870c [ Daniel Weeks ] Rebase to resolve byte buffer conflicts 68794f0 [ Daniel Weeks ] Merge branch 'master' into page size check b49f03c [ Daniel Weeks ] Fixed reset of nextSizeCheck a057f46 [ Daniel Weeks ] Fixed inverted property logic e7cd54b [ Daniel Weeks ] Added property to toggle page size check estimation and initial row size checking","{'added_code': {'if ( INFO ) LOG . info ( ""Min row count for page size check is : "" + props . getMaxRowCountForPageSizeCheck ( ) ) ;', '. withDictionaryEncoding ( enableDictionary )', 'public static final String MAX ROW COUNT FOR PAGE SIZE CHECK = ""parquet . page . size . row . check . max"" ;', 'if ( INFO ) LOG . info ( ""Parquet block size to "" + blockSize ) ;', '. withDictionaryPageSize ( getDictionaryPageSize ( conf ) )', 'int maxPaddingSize = getMaxPaddingSize ( conf ) ;', 'boolean validating ,', 'memoryManager ) ;', 'return configuration . getInt ( PAGE SIZE , ParquetProperties . DEFAULT PAGE SIZE ) ;', 'return configuration . getBoolean ( ESTIMATE PAGE SIZE CHECK ,', 'encodingPropsBuilder . withDictionaryEncoding ( enableDictionary ) ;', 'if ( INFO ) LOG . info ( ""Page size checking is : "" + ( props . estimateNextSizeCheck ( ) ? ""estimated"" : ""constant"" ) ) ;', 'encodingPropsBuilder . withDictionaryPageSize ( dictionaryPageSize ) ;', 'DICTIONARY PAGE SIZE , ParquetProperties . DEFAULT DICTIONARY PAGE SIZE ) ;', 'encodingPropsBuilder . withPageSize ( pageSize ) ;', 'public static final int DEFAULT PAGE SIZE =', '. withWriterVersion ( getWriterVersion ( conf ) )', 'public static final String MIN ROW COUNT FOR PAGE SIZE CHECK = ""parquet . page . size . row . check . min"" ;', 'encodingPropsBuilder . build ( ) ) ;', 'return configuration . getInt (', 'ParquetProperties . builder ( ) ;', 'this ( w , writeSupport , schema , extraMetaData , blockSize , compressor ,', '. withMinRowCountForPageSizeCheck ( getMinRowCountForPageSizeCheck ( conf ) )', 'WRITER VERSION , ParquetProperties . DEFAULT WRITER VERSION . toString ( ) ) ;', 'if ( INFO ) LOG . info ( ""Dictionary is "" + ( props . isEnableDictionary ( ) ? ""on"" : ""off"" ) ) ;', 'if ( INFO ) LOG . info ( ""Writer version is : "" + props . getWriterVersion ( ) ) ;', 'MessageType schema ,', '. withWriterVersion ( writerVersion )', 'CodecFactory codecFactory = new CodecFactory ( conf , encodingProps . getPageSizeThreshold ( ) ) ;', 'ParquetFileWriter w ,', 'if ( INFO ) LOG . info ( ""Min row count for page size check is : "" + props . getMinRowCountForPageSizeCheck ( ) ) ;', '. build ( ) ,', 'String writerVersion = configuration . get (', 'ParquetProperties . DEFAULT ESTIMATE ROW COUNT FOR PAGE SIZE CHECK ) ;', 'Map < String , String > extraMetaData ,', 'props ,', 'return configuration . getBoolean (', 'long blockSize ,', 'public static int getMinRowCountForPageSizeCheck ( Configuration configuration ) {', 'validating , ParquetProperties . builder ( )', 'this . memoryManager = null ;', 'public static final String ESTIMATE PAGE SIZE CHECK = ""parquet . page . size . check . estimate"" ;', '. withPageSize ( getPageSize ( conf ) )', 'ParquetRecordWriter (', 'if ( INFO ) LOG . info ( ""Parquet page size to "" + props . getPageSizeThreshold ( ) ) ;', 'blockSize ,', 'encodingProps ) ;', 'extraMetaData , blockSize , compressor , validating , props ) ;', '. build ( ) ;', 'if ( INFO ) LOG . info ( ""Parquet dictionary page size to "" + props . getDictionaryPageSizeThreshold ( ) ) ;', 'WriteSupport < T > writeSupport ,', 'CodecFactory codecFactory = new CodecFactory ( conf , props . getPageSizeThreshold ( ) ) ;', 'ParquetProperties props = ParquetProperties . builder ( )', 'return configuration . getInt ( MIN ROW COUNT FOR PAGE SIZE CHECK ,', 'ENABLE DICTIONARY , ParquetProperties . DEFAULT IS DICTIONARY ENABLED ) ;', 'ParquetProperties . DEFAULT PAGE SIZE ;', '. withDictionaryEncoding ( getEnableDictionary ( conf ) )', 'ParquetProperties . DEFAULT WRITER VERSION ;', 'encodingPropsBuilder . withDictionaryEncoding ( true ) ;', 'int maxPaddingSize ,', '}', 'ParquetProperties . DEFAULT MINIMUM RECORD COUNT FOR CHECK ) ;', 'BytesCompressor compressor ,', 'this ( file , mode , writeSupport , compressionCodecName , blockSize ,', 'public static final boolean DEFAULT IS DICTIONARY ENABLED =', 'private ParquetProperties . Builder encodingPropsBuilder =', '. withPageSize ( pageSize )', 'public static int getMaxRowCountForPageSizeCheck ( Configuration configuration ) {', '. estimateRowCountForPageSizeCheck ( getEstimatePageSizeCheck ( conf ) )', 'ParquetProperties encodingProps ) throws IOException {', 'ParquetProperties props ,', 'MemoryManager memoryManager ) {', 'return configuration . getInt ( MAX ROW COUNT FOR PAGE SIZE CHECK ,', '@ Deprecated', '. withMaxRowCountForPageSizeCheck ( getMaxRowCountForPageSizeCheck ( conf ) )', 'ParquetProperties . builder ( )', '. build ( ) ) ;', '. withDictionaryPageSize ( dictionaryPageSize )', 'validating , conf , MAX PADDING SIZE DEFAULT ,', 'rowGroupSize , enableValidation , conf , maxPaddingSize ,', 'import org . apache . parquet . column . ParquetProperties ;', 'public static boolean getEstimatePageSizeCheck ( Configuration configuration ) {', 'ParquetProperties . DEFAULT IS DICTIONARY ENABLED ;', 'encodingPropsBuilder . withWriterVersion ( version ) ;'}, 'removed_code': {'private int pageSize = DEFAULT PAGE SIZE ;', 'WriterVersion . PARQUET 1 0 ;', 'if ( INFO ) LOG . info ( ""Writer version is : "" + writerVersion ) ;', 'int dictionaryPageSize ,', 'public static final int DEFAULT PAGE SIZE = 1 * 1024 * 1024 ;', 'writerVersion ,', 'if ( INFO ) LOG . info ( ""Parquet block size to "" + blockSize ) ;', 'return configuration . getInt ( PAGE SIZE , DEFAULT PAGE SIZE ) ;', 'return configuration . getInt ( DICTIONARY PAGE SIZE , DEFAULT PAGE SIZE ) ;', 'import static org . apache . parquet . hadoop . ParquetWriter . DEFAULT PAGE SIZE ;', 'private boolean enableDictionary = DEFAULT IS DICTIONARY ENABLED ;', 'if ( INFO ) LOG . info ( ""Parquet page size to "" + pageSize ) ;', 'int maxPaddingSize = getMaxPaddingSize ( conf ) ;', 'boolean enableDictionary = getEnableDictionary ( conf ) ;', 'private WriterVersion writerVersion = DEFAULT WRITER VERSION ;', 'WriterVersion writerVersion ,', 'public static final boolean DEFAULT IS DICTIONARY ENABLED = true ;', 'int pageSize = getPageSize ( conf ) ;', 'this . pageSize = pageSize ;', 'pageSize ,', 'this . writerVersion = version ;', 'private int dictionaryPageSize = DEFAULT PAGE SIZE ;', 'this . enableDictionary = true ;', 'int pageSize ,', 'this ( file , mode , writeSupport , compressionCodecName , blockSize , pageSize ,', 'MAX PADDING SIZE DEFAULT ) ;', 'WriterVersion writerVersion = getWriterVersion ( conf ) ;', 'boolean enableDictionary ,', 'validating , writerVersion , new HeapByteBufferAllocator ( ) ) ;', 'this . enableDictionary = enableDictionary ;', 'int dictionaryPageSize = getDictionaryPageSize ( conf ) ;', 'dictionaryPageSize ,', 'return configuration . getBoolean ( ENABLE DICTIONARY , true ) ;', 'enableDictionary ,', 'new HeapByteBufferAllocator ( ) ) ;', 'String writerVersion = configuration . get ( WRITER VERSION , WriterVersion . PARQUET 1 0 . toString ( ) ) ;', 'rowGroupSize , pageSize , dictionaryPageSize , enableDictionary ,', 'import org . apache . parquet . bytes . HeapByteBufferAllocator ;', 'this . dictionaryPageSize = dictionaryPageSize ;', 'dictionaryPageSize , enableDictionary , validating , writerVersion , conf ,', 'if ( INFO ) LOG . info ( ""Parquet dictionary page size to "" + dictionaryPageSize ) ;', 'CodecFactory codecFactory = new CodecFactory ( conf , pageSize ) ;', 'int maxPaddingSize ) throws IOException {', 'if ( INFO ) LOG . info ( ""Dictionary is "" + ( enableDictionary ? ""on"" : ""off"" ) ) ;', 'enableValidation , writerVersion , conf , maxPaddingSize ) ;', 'blockSize , pageSize ,', 'extraMetaData , blockSize , pageSize , compressor , dictionaryPageSize , enableDictionary ,'}}"
c6c087c9f8672bc386d93994e49e68dc97087896,1.0,Clean up code .,"{'added_code': {'SpecificDatumReader < ? > reader = readerMap . get ( schemaId ) ;', 'if ( solrJServerType . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""http"" ) ) {', '} else if ( solrJServerType . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""cloud"" ) ) {', 'sb . append ( "" \\ \\ "" ) . append ( c ) ;', '} else if ( solrJServerType . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""loadbalance"" ) ) {', 'SpecificDatumWriter writer = writerMap . get ( schemaId ) ;', '} else if ( solrJServerType . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""concurrent"" ) ) {'}, 'removed_code': {'if ( solrJServerType . toString ( ) . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""http"" ) ) {', '} else if ( solrJServerType . toString ( ) . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""loadbalance"" ) ) {', '} else if ( solrJServerType . toString ( ) . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""concurrent"" ) ) {', 'SpecificDatumReader < ? > reader = ( SpecificDatumReader < ? > ) readerMap', '. get ( schemaId ) ;', '} else if ( solrJServerType . toString ( ) . toLowerCase ( Locale . getDefault ( ) ) . equals ( ""cloud"" ) ) {', 'sb . append ( "" \\ \\ "" + c ) ;', 'SpecificDatumWriter writer = ( SpecificDatumWriter < ? > ) writerMap'}}"
5120797447ee6b029f483049db56cc4aac673e50,1.0,Fix most magic numbers,"{'added_code': {'if ( octet . length ( ) > IPV6 MAX HEX DIGITS PER GROUP ) {', 'private static final int BASE 16 = 16 ;', 'if ( octetInt < 0 | | octetInt > MAX UNSIGNED SHORT ) {', 'if ( octets . length > IPV6 MAX HEX GROUPS ) {', 'octetInt = Integer . valueOf ( octet , BASE 16 ) . intValue ( ) ;', 'private static final int IPV4 MAX OCTET VALUE = 255 ;', 'if ( iIpSegment > IPV4 MAX OCTET VALUE ) {', 'private static final int IPV6 MAX HEX DIGITS PER GROUP = 4 ;', 'private static final int IPV6 MAX HEX GROUPS = 8 ;', 'if ( validOctets < IPV6 MAX HEX GROUPS & & !containsCompressedZeroes ) {', 'private static final int MAX UNSIGNED SHORT = 0xffff ;'}, 'removed_code': {'if ( octets . length > 8 ) {', 'octetInt = Integer . valueOf ( octet , 16 ) . intValue ( ) ;', 'if ( validOctets < 8 & & !containsCompressedZeroes ) {', 'if ( octetInt < 0 | | octetInt > 0xffff ) {', 'if ( octet . length ( ) > 4 ) {', 'if ( iIpSegment > 255 ) {'}}"
c3936baa95fdf419754a544dd1810b107ea1616a,1.0,PARQUET - 352 : Add object model property to file footers . WriteSupport now has a getName getter method that is added to the footer if it returns a non - null string as writer . model . name . This is intended to help identify files written by object models incorrectly . Author : Ryan Blue < blue @ apache . org > Closes #289 from rdblue / PARQUET - 352 - add - object - model - property and squashes the following commits : 23f8f67 [ Ryan Blue ] PARQUET - 352 : Add object model property to file footers .,"{'added_code': {'if ( modelName ! = null ) {', 'String modelName = writeSupport . getName ( ) ;', '}', 'finalMetadata . put ( ParquetWriter . OBJECT MODEL NAME PROP , modelName ) ;'}, 'removed_code': set()}"
0721f49bf0d8b954c8a4b8d75e5375de43af981e,1.0,[ COLLECTIONS - 508 ] Further additions .,"{'added_code': {'public abstract class AbstractSetValuedMap < K , V > extends AbstractMultiValuedMap < K , V > implements SetValuedMap < K , V > {', 'if ( col instanceof Set ) {', 'this . iterator = values . listIterator ( ) ;', 'list = ( List < V > ) createCollection ( ) ;', 'boolean result = list . addAll ( index , c ) ;', 'public boolean hasNext ( ) {', 'public ListIterator < V > listIterator ( int index ) {', 'return list . get ( index ) ;', 'private ListIterator < V > iterator ;', 'return iterator . next ( ) ;', 'import java . io . Serializable ;', 'protected < C extends List < V > > AbstractListValuedMap ( Map < K , ? super C > map , Class < C > listClazz ) {', 'UnmodifiableMultiValuedMap . unmodifiableMultiValuedMap ( new MultiValuedHashMap ( ) ) ;', 'public ValuesListIterator ( Object key ) {', 'return new HashBag < V > ( col ) ;', 'package org . apache . commons . collections4 . multimap ;', 'public static < K , V , C extends Set < V > > SetValuedMap < K , V > createSetValuedHashMap ( final Class < C > setClass ) {', 'super ( map , listClazz ) ;', 'if ( result ) {', 'public V get ( int index ) {', 'public void remove ( ) {', 'return map = = null | | map . isEmpty ( ) ;', 'public void set ( V value ) {', 'public static < K , V > MultiValuedMap < K , V > transformedMultiValuedMap ( final MultiValuedMap < K , V > map ,', 'public V next ( ) {', 'iterator . set ( value ) ;', 'import java . util . Collection ;', 'import org . apache . commons . collections4 . multimap . UnmodifiableMultiValuedMap ;', 'super ( key ) ;', 'public ValuesListIterator ( Object key , int index ) {', 'public static boolean isEmpty ( final MultiValuedMap < ? , ? > map ) {', 'public int previousIndex ( ) {', 'public static < K , V > MultiValuedMap < K , V > emptyIfNull ( final MultiValuedMap < K , V > map ) {', 'protected < C extends Set < V > > AbstractSetValuedMap ( Map < K , ? super C > map , Class < C > setClazz ) {', 'public Set < V > get ( Object key ) {', 'int initialSetCapacity ) {', 'this . values = list ;', 'public ListIterator < V > listIterator ( ) {', 'public class MultiMapUtils {', 'public V remove ( int index ) {', 'public boolean addAll ( int index , Collection < ? extends V > c ) {', 'protected < C extends Set < V > > AbstractSetValuedMap ( Map < K , ? super C > map , Class < C > setClazz ,', 'return list . indexOf ( o ) ;', 'return null ;', 'import org . apache . commons . collections4 . multimap . MultiValuedHashMap ;', 'if ( col instanceof Bag ) {', 'return iterator . previous ( ) ;', 'protected class WrappedSet extends WrappedCollection implements Set < V > {', 'public int nextIndex ( ) {', '@ Override', 'this . values = ListUtils . emptyIfNull ( ( List < V > ) getMap ( ) . get ( key ) ) ;', 'List < V > list = ( List < V > ) createCollection ( ) ;', 'super ( map , setClazz ) ;', 'public static < K , V > List < V > getList ( MultiValuedMap < K , V > map , K key ) {', 'return map . get ( key ) ;', 'private class ValuesListIterator implements ListIterator < V > {', 'return TransformedMultiValuedMap . transformingMap ( map , keyTransformer , valueTransformer ) ;', 'public List < V > remove ( Object key ) {', 'public List < V > get ( Object key ) {', 'return iterator . hasNext ( ) ;', 'public abstract class AbstractListValuedMap < K , V > extends AbstractMultiValuedMap < K , V >', 'return map = = null ? EMPTY MULTI VALUED MAP : map ;', 'return MultiValuedHashMap . < K , V > setValuedHashMap ( ) ;', 'AbstractListValuedMap . this . remove ( key ) ;', 'import org . apache . commons . collections4 . ListUtils ;', 'return UnmodifiableMultiValuedMap . < K , V > unmodifiableMultiValuedMap ( map ) ;', 'if ( list . isEmpty ( ) ) {', 'import java . util . HashMap ;', 'return ( Set < V > ) col ;', '@ SuppressWarnings ( { ""rawtypes"" , ""unchecked"" } )', 'return new ArrayList < V > ( col ) ;', 'import org . apache . commons . collections4 . SetValuedMap ;', 'return new ValuesListIterator ( key ) ;', 'return SetUtils . emptyIfNull ( ( Set < V > ) getMap ( ) . remove ( key ) ) ;', 'return list . subList ( fromIndex , toIndex ) ;', 'public Set < V > remove ( Object key ) {', 'private static final long serialVersionUID = 6024950625989666915L ;', 'public V previous ( ) {', 'return list . addAll ( index , c ) ;', 'protected final Object key ;', 'super ( map , listClazz , initialListCapacity ) ;', 'return result ;', 'list = ( List < V > ) AbstractListValuedMap . this . createCollection ( ) ;', 'if ( getMap ( ) . get ( key ) = = null ) {', 'public List < V > subList ( int fromIndex , int toIndex ) {', 'int initialListCapacity ) {', 'public int lastIndexOf ( Object o ) {', 'public static final MultiValuedMap EMPTY MULTI VALUED MAP =', 'protected < C extends List < V > > AbstractListValuedMap ( Map < K , ? super C > map , Class < C > listClazz ,', 'return MultiValuedHashMap . < K , V > listValuedHashMap ( ) ;', 'this . key = key ;', 'getMap ( ) . remove ( key ) ;', 'return ( Bag < V > ) col ;', 'protected class WrappedCollection implements Collection < V > {', 'this . iterator . add ( value ) ;', 'return iterator . previousIndex ( ) ;', 'return MultiValuedHashMap . < K , V , C > listValuedHashMap ( listClass ) ;', 'return new WrappedList ( key ) ;', 'return new ValuesListIterator ( key , index ) ;', 'import java . util . ListIterator ;', 'public static < K , V > SetValuedMap < K , V > createSetValuedHashMap ( ) {', 'public V set ( int index , V value ) {', 'import org . apache . commons . collections4 . SetUtils ;', 'return new HashSet < V > ( col ) ;', 'final List < V > list = ListUtils . emptyIfNull ( ( List < V > ) getMapping ( ) ) ;', 'public static < K , V > MultiValuedMap < K , V > emptyMultiValuedMap ( ) {', 'return iterator . nextIndex ( ) ;', 'import org . apache . commons . collections4 . multimap . TransformedMultiValuedMap ;', 'package org . apache . commons . collections4 ;', 'this . iterator = values . listIterator ( index ) ;', 'import org . apache . commons . collections4 . ListValuedMap ;', 'public WrappedList ( Object key ) {', 'if ( map ! = null ) {', 'public WrappedSet ( Object key ) {', 'return EMPTY MULTI VALUED MAP ;', 'return value ;', 'return ( List < V > ) col ;', 'private static final long serialVersionUID = 3383617478898639862L ;', 'import java . util . Map ;', 'return list . set ( index , value ) ;', 'public static < K , V , C extends List < V > > ListValuedMap < K , V > createListValuedHashMap ( final Class < C > listClass ) {', '}', 'final Transformer < ? super V , ? extends V > valueTransformer ) {', 'getMap ( ) . put ( ( K ) key , list ) ;', 'public static < K , V > Bag < V > getBag ( MultiValuedMap < K , V > map , K key ) {', 'V value = list . remove ( index ) ;', 'import java . util . Set ;', 'Collection < V > col = map . get ( key ) ;', 'private final Object key ;', 'this . iterator = list . listIterator ( ) ;', 'private MultiMapUtils ( ) {', 'import java . util . ArrayList ;', 'return ListUtils . emptyIfNull ( ( List < V > ) getMap ( ) . remove ( key ) ) ;', 'super ( map , setClazz , initialSetCapacity ) ;', 'list . add ( index , value ) ;', 'import org . apache . commons . collections4 . bag . HashBag ;', 'if ( list = = null ) {', 'iterator . remove ( ) ;', 'public static < K , V > ListValuedMap < K , V > createListValuedHashMap ( ) {', 'public static < K , V > Set < V > getSet ( MultiValuedMap < K , V > map , K key ) {', 'return new WrappedSet ( key ) ;', 'final MultiValuedMap < ? extends K , ? extends V > map ) {', 'protected Collection < V > getMapping ( ) {', 'public static < K , V > Collection < V > getCollection ( final MultiValuedMap < K , V > map , final K key ) {', 'import java . util . List ;', 'public boolean hasPrevious ( ) {', '@ SuppressWarnings ( ""unchecked"" )', 'public static < K , V > MultiValuedMap < K , V > unmodifiableMultiValuedMap (', 'import java . util . HashSet ;', 'return MultiValuedHashMap . < K , V , C > setValuedHashMap ( setClass ) ;', 'public int indexOf ( Object o ) {', 'public void add ( int index , V value ) {', 'public void add ( V value ) {', 'final Class < C > collectionClazz , final int initialCollectionCapacity ) {', 'implements ListValuedMap < K , V > , Serializable {', 'List < V > list = ( List < V > ) getMapping ( ) ;', 'final Transformer < ? super K , ? extends K > keyTransformer ,', 'if ( values . isEmpty ( ) ) {', 'if ( col instanceof List ) {', 'return iterator . hasPrevious ( ) ;', 'private class WrappedList extends WrappedCollection implements List < V > {', 'return CollectionUtils . emptyIfNull ( getMap ( ) . remove ( key ) ) ;', 'private List < V > values ;'}, 'removed_code': {'return coll = = null ? Collections . < V > emptyList ( ) : coll ;', 'Collection < V > coll = getMap ( ) . remove ( key ) ;', 'int initialCollectionCapacity , final Class < C > collectionClazz ) {', 'private final Object key ;', 'private class WrappedCollection implements Collection < V > {', 'import java . util . Collections ;', 'private Collection < V > getMapping ( ) {'}}"
c9c4dfa594ab2901ba627d68c0fc043806ec0ab1,1.0,OPENNLP - 744 Added support for attribute annotation in the brat . ann files,"{'added_code': {'private static final int VALUE OFFSET = 3 ;', 'if ( values . length = = 3 | | values . length = = 4 ) {', 'else {', 'static class AttributeAnnotationParser extends BratAnnotationParser {', 'case ""attributes"" :', '. getCoveredText ( line ) . toString ( ) ) ;', 'break ;', 'parsers . put ( AnnotationConfiguration . ATTRIBUTE TYPE , new AttributeAnnotationParser ( ) ) ;', 'switch ( sectionType ) {', '@ Override', ""typeToClassMap . put ( line . substring ( 0 , line . indexOf ( ' ' ) ) , AnnotationConfiguration . ATTRIBUTE TYPE ) ;"", 'case ""entities"" :', 'BratAnnotation parse ( Span [ ] values , CharSequence line ) throws IOException {', 'default :', 'value = values [ VALUE OFFSET ] . getCoveredText ( line ) . toString ( ) ;', 'case ""relations"" :', '"" type class , no parser registered : "" + tokens [ BratAnnotationParser . TYPE OFFSET ]', 'if ( values . length = = 4 ) {', 'return new AttributeAnnotation ( values [ ID OFFSET ] . getCoveredText ( line ) . toString ( ) ,', 'String value = null ;', 'throw new InvalidFormatException ( ""Line must have 3 or 4 fields"" ) ;', 'values [ ATTACHED TO OFFSET ] . getCoveredText ( line ) . toString ( ) , value ) ;', 'values [ TYPE OFFSET ] . getCoveredText ( line ) . toString ( ) ,', 'private static final int ATTACHED TO OFFSET = 2 ;', '}', 'public static final String ATTRIBUTE TYPE = ""Attribute"" ;'}, 'removed_code': {'else if ( ""relations"" . equals ( sectionType ) ) {', '}', 'if ( ""entities"" . equals ( sectionType ) ) {', '"" type class , no parser registered : "" + tokens [ BratAnnotationParser . TYPE OFFSET ] ) ;'}}"
14313cffebe7d676ee4716a017df7e3febae6f6f,1.0,use static import rather than import of nested class,"{'added_code': {'import static org . apache . ivy . plugins . namespace . NameSpaceHelper . toSystem ;', 'dd = toSystem ( dd , ivySettings . getContextNamespace ( ) ) ;', 'import static org . apache . ivy . core . module . descriptor . Configuration . Visibility . PUBLIC ;', 'if ( PUBLIC . equals ( m2Conf . getVisibility ( ) ) ) {', 'ResolveData data = getContext ( ) . getResolveData ( ) ;', 'ResolveEngine engine = getContext ( ) . getIvy ( ) . getResolveEngine ( ) ;', 'import static org . apache . ivy . core . IvyContext . getContext ;'}, 'removed_code': {'ResolveData data = IvyContext . getContext ( ) . getResolveData ( ) ;', 'if ( Visibility . PUBLIC . equals ( m2Conf . getVisibility ( ) ) ) {', 'import org . apache . ivy . core . module . descriptor . Configuration . Visibility ;', 'import org . apache . ivy . plugins . namespace . NameSpaceHelper ;', 'ResolveEngine engine = IvyContext . getContext ( ) . getIvy ( ) . getResolveEngine ( ) ;', 'dd = NameSpaceHelper . toSystem ( dd , ivySettings . getContextNamespace ( ) ) ;', 'import org . apache . ivy . core . IvyContext ;'}}"
0079828734d62dbc2b44ccf4f21e3dc1daa7b90b,1.0,"Use Real { Vector , Matrix } in LeastSquares interfaces Covered all of the interfaces in the leastsquares package to use RealVector and RealMatrix instead of double [ ] and double [ ] [ ] . This reduced some duplicated code . For example Evaluation . computeResiduals ( ) was a complete duplication of RealVector . subtract ( ) . It also presents a consistent interface and allows data encapsulation . Lastly , this change enables [ math ] to ""eat our own dog food . "" It enables the linear package to be used in the implementation of the optimization algorithms .","{'added_code': {'final double residual = currentResiduals . getEntry ( i ) ;', 'double [ ] currentResiduals = current . computeResiduals ( ) . toArray ( ) ;', 'final RealVector dX = solver . solve ( new ArrayRealVector ( b , false ) ) ;', 'current = problem . evaluate ( new ArrayRealVector ( currentPoint , false ) ) ;', 'import org . apache . commons . math3 . linear . ArrayRealVector ;', 'Evaluation current = problem . evaluate ( new ArrayRealVector ( currentPoint , false ) ) ;', 'final RealVector currentPoint = lsp . getStart ( ) ;', 'currentResiduals = current . computeResiduals ( ) . toArray ( ) ;', 'currentPoint . setEntry ( i , currentPoint . getEntry ( i ) + dX . getEntry ( i ) ) ;', 'final RealVector currentResiduals = current . computeResiduals ( ) ;', 'import org . apache . commons . math3 . linear . RealVector ;', 'final double [ ] currentPoint = problem . getStart ( ) . toArray ( ) ;'}, 'removed_code': {'Evaluation current = problem . evaluate ( currentPoint ) ;', 'current = problem . evaluate ( currentPoint ) ;', 'final double [ ] currentResiduals = current . computeResiduals ( ) ;', 'double [ ] currentResiduals = current . computeResiduals ( ) ;', 'final double [ ] currentPoint = lsp . getStart ( ) ;', 'currentPoint [ i ] + = dX [ i ] ;', 'final double [ ] currentPoint = problem . getStart ( ) ;', 'final double [ ] dX = solver . solve ( new ArrayRealVector ( b , false ) ) . toArray ( ) ;', 'final double residual = currentResiduals [ i ] ;', 'currentResiduals = current . computeResiduals ( ) ;'}}"
b82d96218bfd37f6df95a2e8d7675d091ab61970,1.0,PARQUET - 1217 : Incorrect handling of missing values in Statistics In parquet - format every value in Statistics is optional while parquet - mr does not properly handle these scenarios : - null count is set but min / max or min value / max value are not : filtering may fail with NPE or incorrect filtering occurs fix : check if min / max is set before comparing to the related values - null count is not set : filtering handles null count as if it would be 0 - > incorrect filtering may occur fix : introduce new method in Statistics object to check if num nulls is set ; check if num nulls is set by the new method before using its value for filtering Author : Gabor Szadovszky < gabor . szadovszky @ cloudera . com > Closes #458 from gszadovszky / PARQUET - 1217 and squashes the following commits : 9d14090 [ Gabor Szadovszky ] Updates according to rdblue's comments 116d1d3 [ Gabor Szadovszky ] PARQUET - 1217 : Updates according to zi's comments c264b50 [ Gabor Szadovszky ] PARQUET - 1217 : fix handling of unset nullCount 2ec2fb1 [ Gabor Szadovszky ] PARQUET - 1217 : Incorrect handling of missing values in Statistics,"{'added_code': {'statsBuilder . withMin ( formatStats . min . array ( ) ) ;', 'if ( formatStats . isSetNull count ( ) ) {', 'statsBuilder . withMax ( formatStats . max . array ( ) ) ;', 'org . apache . parquet . column . statistics . Statistics . Builder statsBuilder =', 'return statsBuilder . build ( ) ;', 'statsBuilder . withMin ( min ) ;', 'org . apache . parquet . column . statistics . Statistics . getBuilder ( type ) ;', 'statsBuilder . withMax ( max ) ;', '}', 'statsBuilder . withNumNulls ( formatStats . null count ) ;'}, 'removed_code': {'stats . setMinMaxFromBytes ( min , max ) ;', 'org . apache . parquet . column . statistics . Statistics stats = org . apache . parquet . column . statistics . Statistics . createStats ( type ) ;', 'stats . setNumNulls ( formatStats . null count ) ;', 'stats . setMinMaxFromBytes ( formatStats . min . array ( ) , formatStats . max . array ( ) ) ;', 'return stats ;'}}"
48055baa938695fa302fc8aa51a5a2df24c73fe7,1.0,fix style,"{'added_code': {'parser . parseDescriptor (', 'Map parentPomProps = PomModuleDescriptorBuilder . extractPomProperties (', 'getSettings ( ) , temp . toURI ( ) . toURL ( ) , res , false ) ;', 'parentDescr . getExtraInfo ( ) ) ;'}, 'removed_code': {'parser . parseDescriptor ( getSettings ( ) , temp . toURI ( ) . toURL ( ) , res , false ) ;', 'Map parentPomProps = PomModuleDescriptorBuilder . extractPomProperties ( parentDescr . getExtraInfo ( ) ) ;'}}"
1a5e5c6802a920cd8e379de0552dd289f680fa56,1.0,"PARQUET - 99 : Add page size check properties This adds properties to set the min and max number of records that are passed between page checks , as well as a property that controls whether the next check will be based on records already seen or set to the minimum number of records between checks . * `parquet . page . size . row . check . min` - minimum number of records between page size checks * `parquet . page . size . row . check . max` - maximum number of records between page size checks * `parquet . page . size . check . estimate` - whether to estimate the number of records before the next check , or to always use the minimum number of records . This also updates the internal API to use ParquetProperties to carry encoding settings ( used in parquet - column ) to reduce the number of parameters passed through internal APIs . It also adds a builder for ParquetProperties to avoid needing to reference defaults in other modules . This closes #250 Author : Daniel Weeks < dweeks @ netflix . com > Author : Ryan Blue < blue @ apache . org > Closes #297 from rdblue / parquet - properties - update and squashes the following commits : c93b73e [ Ryan Blue ] PARQUET - 99 : Use ParquetProperties to carry encoding config . 18f8d3a [ Daniel Weeks ] Spacing 2090719 [ Daniel Weeks ] Update sizeCheck to write page properly if estimating is turned off 71336ee [ Daniel Weeks ] Fixed param name 5d99072 [ Daniel Weeks ] Update page size checking for v2 writer 3f7870c [ Daniel Weeks ] Rebase to resolve byte buffer conflicts 68794f0 [ Daniel Weeks ] Merge branch 'master' into page size check b49f03c [ Daniel Weeks ] Fixed reset of nextSizeCheck a057f46 [ Daniel Weeks ] Fixed inverted property logic e7cd54b [ Daniel Weeks ] Added property to toggle page size check estimation and initial row size checking Conflicts : parquet - column / src / main / java / org / apache / parquet / column / ParquetProperties . java parquet - column / src / main / java / org / apache / parquet / column / impl / ColumnWriteStoreV1 . java parquet - column / src / main / java / org / apache / parquet / column / impl / ColumnWriteStoreV2 . java parquet - column / src / main / java / org / apache / parquet / column / impl / ColumnWriterV1 . java parquet - column / src / main / java / org / apache / parquet / column / impl / ColumnWriterV2 . java parquet - column / src / test / java / org / apache / parquet / column / impl / TestCorruptDeltaByteArrays . java parquet - column / src / test / java / org / apache / parquet / column / mem / TestMemColumn . java parquet - column / src / test / java / org / apache / parquet / io / PerfTest . java parquet - column / src / test / java / org / apache / parquet / io / TestColumnIO . java parquet - column / src / test / java / org / apache / parquet / io / TestFiltered . java parquet - hadoop / src / main / java / org / apache / parquet / hadoop / InternalParquetRecordWriter . java parquet - hadoop / src / main / java / org / apache / parquet / hadoop / ParquetOutputFormat . java parquet - hadoop / src / main / java / org / apache / parquet / hadoop / ParquetRecordWriter . java parquet - hadoop / src / main / java / org / apache / parquet / hadoop / ParquetWriter . java parquet - pig / src / test / java / org / apache / parquet / pig / TupleConsumerPerfTest . java parquet - thrift / src / test / java / org / apache / parquet / thrift / TestParquetReadProtocol . java Resolution : Fixed changes that depended on the addition of an allocator argument Ignored adjacent changes that were flagged Passed page size at compressor instantiation instead of to the factory","{'added_code': {'if ( INFO ) LOG . info ( ""Min row count for page size check is : "" + props . getMaxRowCountForPageSizeCheck ( ) ) ;', '. withDictionaryEncoding ( enableDictionary )', 'BytesCompressor compressor ,', 'return configuration . getInt (', 'this . memoryManager = null ;', 'validating , ParquetProperties . builder ( )', 'codecFactory . getCompressor ( codec , props . getPageSizeThreshold ( ) ) ,', 'public static final String MAX ROW COUNT FOR PAGE SIZE CHECK = ""parquet . page . size . row . check . max"" ;', 'if ( INFO ) LOG . info ( ""Parquet block size to "" + blockSize ) ;', 'public static final String ESTIMATE PAGE SIZE CHECK = ""parquet . page . size . check . estimate"" ;', 'this ( w , writeSupport , schema , extraMetaData , blockSize , compressor ,', '. withDictionaryPageSize ( getDictionaryPageSize ( conf ) )', '. withMinRowCountForPageSizeCheck ( getMinRowCountForPageSizeCheck ( conf ) )', '. withPageSize ( getPageSize ( conf ) )', '. withPageSize ( pageSize )', 'ParquetRecordWriter (', 'int maxPaddingSize = getMaxPaddingSize ( conf ) ;', 'WRITER VERSION , ParquetProperties . DEFAULT WRITER VERSION . toString ( ) ) ;', 'if ( INFO ) LOG . info ( ""Parquet page size to "" + props . getPageSizeThreshold ( ) ) ;', 'public static int getMaxRowCountForPageSizeCheck ( Configuration configuration ) {', 'import org . apache . commons . math3 . analysis . function . Add ;', 'if ( INFO ) LOG . info ( ""Dictionary is "" + ( props . isEnableDictionary ( ) ? ""on"" : ""off"" ) ) ;', 'blockSize ,', 'CodecFactory codecFactory = new CodecFactory ( conf ) ;', 'if ( INFO ) LOG . info ( ""Writer version is : "" + props . getWriterVersion ( ) ) ;', 'boolean validating ,', 'MessageType schema ,', '. estimateRowCountForPageSizeCheck ( getEstimatePageSizeCheck ( conf ) )', 'memoryManager ) ;', 'return configuration . getInt ( PAGE SIZE , ParquetProperties . DEFAULT PAGE SIZE ) ;', 'extraMetaData , blockSize , compressor , validating , props ) ;', 'return configuration . getBoolean ( ESTIMATE PAGE SIZE CHECK ,', '. build ( ) ;', 'ParquetProperties props ,', 'if ( INFO ) LOG . info ( ""Parquet dictionary page size to "" + props . getDictionaryPageSizeThreshold ( ) ) ;', 'long blockSize ,', 'return configuration . getInt ( MAX ROW COUNT FOR PAGE SIZE CHECK ,', 'MemoryManager memoryManager ) {', '@ Deprecated', '. withWriterVersion ( writerVersion )', 'if ( INFO ) LOG . info ( ""Page size checking is : "" + ( props . estimateNextSizeCheck ( ) ? ""estimated"" : ""constant"" ) ) ;', 'WriteSupport < T > writeSupport ,', 'ParquetProperties props = ParquetProperties . builder ( )', 'return configuration . getInt ( MIN ROW COUNT FOR PAGE SIZE CHECK ,', '. withMaxRowCountForPageSizeCheck ( getMaxRowCountForPageSizeCheck ( conf ) )', 'ParquetFileWriter w ,', 'DICTIONARY PAGE SIZE , ParquetProperties . DEFAULT DICTIONARY PAGE SIZE ) ;', 'if ( INFO ) LOG . info ( ""Min row count for page size check is : "" + props . getMinRowCountForPageSizeCheck ( ) ) ;', 'ENABLE DICTIONARY , ParquetProperties . DEFAULT IS DICTIONARY ENABLED ) ;', '. withWriterVersion ( getWriterVersion ( conf ) )', '. build ( ) ,', '. withDictionaryPageSize ( dictionaryPageSize )', '. withDictionaryEncoding ( getEnableDictionary ( conf ) )', 'ParquetProperties . DEFAULT ESTIMATE ROW COUNT FOR PAGE SIZE CHECK ) ;', 'String writerVersion = configuration . get (', 'import org . apache . parquet . column . ParquetProperties ;', 'public static boolean getEstimatePageSizeCheck ( Configuration configuration ) {', 'Map < String , String > extraMetaData ,', 'props ,', 'return configuration . getBoolean (', '}', 'public static final String MIN ROW COUNT FOR PAGE SIZE CHECK = ""parquet . page . size . row . check . min"" ;', 'ParquetProperties . DEFAULT MINIMUM RECORD COUNT FOR CHECK ) ;', 'public static int getMinRowCountForPageSizeCheck ( Configuration configuration ) {'}, 'removed_code': {'if ( INFO ) LOG . info ( ""Writer version is : "" + writerVersion ) ;', 'writerVersion ,', 'if ( INFO ) LOG . info ( ""Parquet block size to "" + blockSize ) ;', 'return configuration . getInt ( PAGE SIZE , DEFAULT PAGE SIZE ) ;', 'return configuration . getInt ( DICTIONARY PAGE SIZE , DEFAULT PAGE SIZE ) ;', 'import static org . apache . parquet . hadoop . ParquetWriter . DEFAULT PAGE SIZE ;', 'if ( INFO ) LOG . info ( ""Parquet page size to "" + pageSize ) ;', 'int maxPaddingSize = getMaxPaddingSize ( conf ) ;', 'boolean enableDictionary = getEnableDictionary ( conf ) ;', 'int pageSize = getPageSize ( conf ) ;', 'CodecFactory codecFactory = new CodecFactory ( conf ) ;', 'WriterVersion writerVersion = getWriterVersion ( conf ) ;', 'validating , writerVersion ) ;', 'codecFactory . getCompressor ( codec , pageSize ) ,', 'int dictionaryPageSize = getDictionaryPageSize ( conf ) ;', 'enableDictionary ,', 'return configuration . getBoolean ( ENABLE DICTIONARY , true ) ;', 'dictionaryPageSize ,', 'String writerVersion = configuration . get ( WRITER VERSION , WriterVersion . PARQUET 1 0 . toString ( ) ) ;', 'if ( INFO ) LOG . info ( ""Parquet dictionary page size to "" + dictionaryPageSize ) ;', 'if ( INFO ) LOG . info ( ""Dictionary is "" + ( enableDictionary ? ""on"" : ""off"" ) ) ;', 'blockSize , pageSize ,', 'extraMetaData , blockSize , pageSize , compressor , dictionaryPageSize , enableDictionary ,'}}"
54a1a8dedbd4af64ca8079da69878f89a69d9e5b,1.0,"Auto - restart from checkpoint doesn't pick up latest checkpoint Summary : While running different jobs with checkpoints enabled I noticed some issues : 1 ) The way we pick up latest checkpoint is not correct . Current implementation just picks whatever is returned last from FileSystem . list ( ) , which is not necessarily the last checkpoint 2 ) If job restarts from checkpoint it immediately creates another checkpoint . 3 ) We need more flexibility in GiraphJobRetryChecker to allow restarts after multiple failures . Test Plan : Run our production jobs with checkpointing Reviewers : majakabiljo , pavanka , pavanka . 26 , maja . kabiljo Reviewed By : maja . kabiljo Differential Revision : https : / / reviews . facebook . net / D23913","{'added_code': {'"" . "" + mrTaskId + CheckpointingUtils . CHECKPOINT METADATA POSTFIX ) ) ;', 'CheckpointingUtils . CHECKPOINT FINALIZED POSTFIX ) ;', 'long firstCheckpoint = INPUT SUPERSTEP + 1 + checkpointFrequency ;', 'CheckpointingUtils . CHECKPOINT FINALIZED POSTFIX ;', 'String finalizedCheckpointPath = getSavedCheckpointBasePath ( superstep ) +'}, 'removed_code': {'"" . "" + mrTaskId + CHECKPOINT METADATA POSTFIX ) ) ;', 'getSavedCheckpointBasePath ( superstep ) + CHECKPOINT FINALIZED POSTFIX ;', 'long firstCheckpoint = INPUT SUPERSTEP + 1 ;', 'String finalizedCheckpointPath =', 'CHECKPOINT FINALIZED POSTFIX ) ;'}}"
7d0e006992574973bbd732373af32462393f00b5,1.0,GIRAPH - 736 : Bring back FindBugs ( nitay ),"{'added_code': {'LOG . error ( ""deletePartitionFiles : Failed to delete file "" + file ) ;', 'LOG . error ( ""offloadPartition : Failed to create file "" + file ) ;', 'if ( !file . createNewFile ( ) ) {', 'if ( !file . getParentFile ( ) . mkdirs ( ) ) {', 'LOG . error ( ""offloadPartition : Failed to create directory "" + file ) ;', 'inactive . isEmpty ( ) ) {', 'if ( !file . delete ( ) ) {', 'import com . google . common . collect . Lists ;', 'LOG . error ( ""loadPartition : Failed to delete file "" + file ) ;', 'import org . apache . log4j . Logger ;', 'import static org . apache . giraph . conf . GiraphConstants . COMPUTATION CLASS ;', '}'}, 'removed_code': {'import org . apache . log4j . Logger ;', 'inactive . size ( ) = = 0 ) {', 'import com . google . common . collect . Lists ;', 'file . getParentFile ( ) . mkdirs ( ) ;', 'file . delete ( ) ;', 'import static org . apache . giraph . conf . GiraphConstants . COMPUTATION CLASS ;', 'file . createNewFile ( ) ;'}}"
8705e97fbd1aa9de951456f05dff9ec56c4344b2,1.0,"trivial fixes of ""bugs"" reported by Sonar","{'added_code': {'ji = new JarInputStream ( streamBridge . getInput ( ) ) ;', 'p . pack ( ji , originalOutput ) ;'}, 'removed_code': {'originalOutput ) ;', 'p . pack ( ji = new JarInputStream ( streamBridge . getInput ( ) ) ,'}}"
eb2b89efbe15ab0b70fd94f0ecd0aa03866fb4d2,1.0,Add final modifier to local variables .,"{'added_code': {'final Map < String , Integer > values = new HashMap < > ( ) ;', 'final char c = pattern . charAt ( currentIdx ) ;', 'final int value = Integer . parseInt ( source . substring ( pos . getIndex ( ) , idx ) ) ;', 'final TimeZone tz = TimeZone . getTimeZone ( value . toUpperCase ( ) ) ;', 'final String formatField = sb . toString ( ) ;', 'final String key = zoneNames [ i ] . toLowerCase ( locale ) ;', 'final Matcher matcher = pattern . matcher ( source . substring ( pos . getIndex ( ) ) ) ;', 'final Strategy nextStrategy = lt . next ( ) . strategy ;', 'final StrategyAndWidth pattern = lt . next ( ) ;', 'final ParsePosition pp = new ParsePosition ( 0 ) ;', 'for ( final Map . Entry < String , Integer > displayName : displayNames . entrySet ( ) ) {', 'final TzInfo tzInfo = tzNames . get ( value . toLowerCase ( locale ) ) ;', 'final char c = source . charAt ( idx ) ;', 'for ( final String zoneName : sorted ) {', 'final StrategyParser fm = new StrategyParser ( pattern , definingCalendar ) ;', 'final int end = idx + maxWidth ;', 'final StringBuilder sb = new StringBuilder ( ) ;', 'final StringBuilder regex = new StringBuilder ( ) ;', 'final StrategyAndWidth field = fm . getNextStrategy ( ) ;', 'final char c = value . charAt ( i ) ;', 'final int width = currentIdx - begin ;', 'final int sIdx = idx + pos . getIndex ( ) ;', 'final ListIterator < StrategyAndWidth > lt = patterns . listIterator ( ) ;', 'final String key = displayName . getKey ( ) . toLowerCase ( locale ) ;', 'final TreeSet < String > sorted = new TreeSet < > ( LONGER FIRST LOWERCASE ) ;', 'final int maxWidth = pattern . getMaxWidth ( lt ) ;', 'final Map < String , Integer > displayNames = cal . getDisplayNames ( field , Calendar . ALL STYLES , locale ) ;', 'final int begin = currentIdx ;', 'final TzInfo standard = new TzInfo ( tz , false ) ;', 'final TimeZone tz = TimeZone . getTimeZone ( ""GMT"" + value ) ;', 'for ( final String symbol : sorted ) {'}, 'removed_code': {'StringBuilder regex = new StringBuilder ( ) ;', 'Map < String , Integer > displayNames = cal . getDisplayNames ( field , Calendar . ALL STYLES , locale ) ;', 'int value = Integer . parseInt ( source . substring ( pos . getIndex ( ) , idx ) ) ;', 'Matcher matcher = pattern . matcher ( source . substring ( pos . getIndex ( ) ) ) ;', 'char c = source . charAt ( idx ) ;', 'ParsePosition pp = new ParsePosition ( 0 ) ;', 'int begin = currentIdx ;', 'char c = pattern . charAt ( currentIdx ) ;', 'int sIdx = idx + pos . getIndex ( ) ;', 'int maxWidth = pattern . getMaxWidth ( lt ) ;', 'StrategyAndWidth pattern = lt . next ( ) ;', 'TzInfo tzInfo = tzNames . get ( value . toLowerCase ( locale ) ) ;', 'TreeSet < String > sorted = new TreeSet < > ( LONGER FIRST LOWERCASE ) ;', 'String formatField = sb . toString ( ) ;', 'TzInfo standard = new TzInfo ( tz , false ) ;', 'ListIterator < StrategyAndWidth > lt = patterns . listIterator ( ) ;', 'TimeZone tz = TimeZone . getTimeZone ( ""GMT"" + value ) ;', 'StrategyAndWidth field = fm . getNextStrategy ( ) ;', 'int end = idx + maxWidth ;', 'TimeZone tz = TimeZone . getTimeZone ( value . toUpperCase ( ) ) ;', 'for ( String zoneName : sorted ) {', 'char c = value . charAt ( i ) ;', 'Strategy nextStrategy = lt . next ( ) . strategy ;', 'StrategyParser fm = new StrategyParser ( pattern , definingCalendar ) ;', 'StringBuilder sb = new StringBuilder ( ) ;', 'for ( Map . Entry < String , Integer > displayName : displayNames . entrySet ( ) ) {', 'String key = zoneNames [ i ] . toLowerCase ( locale ) ;', 'for ( String symbol : sorted ) {', 'String key = displayName . getKey ( ) . toLowerCase ( locale ) ;', 'int width = currentIdx - begin ;', 'Map < String , Integer > values = new HashMap < > ( ) ;'}}"
0e8ff9c44058afbca9c9126a8feebe41cd682626,1.0,"COMPRESS - 382 and COMPRESS - 386 - - take 3 , create static MemoryLimit and remove new ctors .","{'added_code': {'import org . apache . commons . compress . MemoryLimit ;', 'public ZCompressorInputStream ( final InputStream inputStream ) throws IOException {', 'initializeTables ( maxCodeSize , MemoryLimit . getMemoryLimitInKb ( ) ) ;'}, 'removed_code': {'public ZCompressorInputStream ( final InputStream inputStream , int memoryLimitInKb )', 'public ZCompressorInputStream ( final InputStream inputStream ) throws IOException {', 'initializeTables ( maxCodeSize , memoryLimitInKb ) ;', 'throws IOException {', '}', 'this ( inputStream , - 1 ) ;'}}"
10ec5a35b13963b953d3c6a9d8321dcecf11fb3f,1.0,OPENNLP - 927 : Removed PluggableParameter Fixes OPENNLP - 927 Closes apache / opennlp#55,"{'added_code': {'trainingParameters . put ( AbstractDataIndexer . SORT PARAM , Boolean . toString ( isSortAndMerge ( ) ) ) ;', 'import opennlp . tools . ml . model . DataIndexerFactory ;', 'addToReport ( AbstractTrainer . TRAINER TYPE PARAM , EventTrainer . EVENT VALUE ) ;', 'DataIndexer indexer = DataIndexerFactory . getDataIndexer ( trainingParameters , reportMap ) ;', 'public static final String DATA INDEXER ONE PASS REAL VALUE = ""OnePassRealValue"" ;', 'if ( trainingParameters . getIntParameter ( CUTOFF PARAM , - 1 ) = = - 1 ) {', 'protected Map < String , String > reportMap = new HashMap < > ( ) ;', 'trainingParameters . put ( CUTOFF PARAM , ""5"" ) ;'}, 'removed_code': {'if ( dataIndexer ! = null ) {', 'DataIndexer indexer ;', 'if ( ! ( DATA INDEXER ONE PASS VALUE . equals ( dataIndexer ) | | DATA INDEXER TWO PASS VALUE', 'indexer . init ( indexParams , parameters . getReportMap ( ) ) ;', 'String dataIndexerName = parameters . getStringParam ( DATA INDEXER PARAM ,', 'parameters . addToReport ( AbstractTrainer . TRAINER TYPE PARAM , EventTrainer . EVENT VALUE ) ;', 'indexer = new TwoPassDataIndexer ( ) ;', 'String dataIndexer = parameters . getStringParam ( DATA INDEXER PARAM ,', 'indexer = new OnePassDataIndexer ( ) ;', 'indexParams . put ( AbstractDataIndexer . SORT PARAM , Boolean . toString ( isSortAndMerge ( ) ) ) ;', '+ dataIndexerName ) ;', '} else if ( DATA INDEXER TWO PASS VALUE . equals ( dataIndexerName ) ) {', '} else {', 'Map < String , String > indexParams = new HashMap < String , String > ( ) ;', 'throw new IllegalStateException ( ""Unexpected data indexer name : ""', 'indexParams . put ( AbstractDataIndexer . CUTOFF PARAM , Integer . toString ( getCutoff ( ) ) ) ;', 'DATA INDEXER TWO PASS VALUE ) ;', 'if ( DATA INDEXER ONE PASS VALUE . equals ( dataIndexerName ) ) {', 'return false ;', '}', '. equals ( dataIndexer ) ) ) {'}}"
37ba197e62d6b60037d18afc33801e6221f1b8c6,1.0,"< action dev = ""ggregory"" type = ""add"" issue = ""CODEC - 184"" due - to = ""Cyrille Artho"" > NullPointerException in DoubleMetaPhone . isDoubleMetaphoneEqual when using empty strings < / action >","{'added_code': {'if ( cs1 = = cs2 ) {', 'public static boolean equals ( final CharSequence cs1 , final CharSequence cs2 ) {', 'return false ;', 'return true ;', 'return CharSequenceUtils . regionMatches ( cs1 , false , 0 , cs2 , 0 , Math . max ( cs1 . length ( ) , cs2 . length ( ) ) ) ;', 'if ( cs1 instanceof String & & cs2 instanceof String ) {', '}', 'return cs1 . equals ( cs2 ) ;', 'if ( cs1 = = null | | cs2 = = null ) {'}, 'removed_code': set()}"
1954a51bb5aa0ab3cf762c07b961ea8fd873f17a,1.0,Continue review of multimap package .,"{'added_code': {'public boolean contains ( Object obj ) {', 'return asMap ( ) . equals ( ( ( SetValuedMap < ? , ? > ) obj ) . asMap ( ) ) ;', 'for ( final Collection < V > col : getMap ( ) . values ( ) ) {', 'if ( coll . isEmpty ( ) ) {', 'boolean changed = false ;', 'for ( Map . Entry < ? extends K , ? extends V > entry : map . entrySet ( ) ) {', 'public WrappedCollection ( final K key ) {', 'List < V > list = createCollection ( ) ;', 'return changed ;', 'coll = createCollection ( ) ;', 'final Collection < V > coll = getMapping ( ) ;', 'for ( Map . Entry < ? extends K , ? extends V > entry : map . entries ( ) ) {', 'return coll = = null ? false : coll . contains ( obj ) ;', 'private final K key ;', 'final List < V > list = ListUtils . emptyIfNull ( getMapping ( ) ) ;', 'final Iterator < ? extends V > it = transformedValues . iterator ( ) ;', 'if ( changed ) {', 'return !valueCollection . isEmpty ( ) & & get ( key ) . addAll ( valueCollection ) ;', 'public ValuesListIterator ( final K key , int index ) {', 'return SetUtils . isEqualSet ( set , otherSet ) ;', 'if ( obj instanceof ListValuedMap ) {', 'Collection < V > coll = getMapping ( ) ;', 'Collection < ? extends V > valueCollection = ( Collection < ? extends V > ) values ;', 'return ListUtils . isEqualList ( list , otherList ) ;', 'final Iterable < V > transformedValues = FluentIterable . of ( values ) . transform ( valueTransformer ) ;', 'final List < V > list = getMapping ( ) ;', 'new Class [ ] { Integer . TYPE } ,', 'import org . apache . commons . collections4 . FluentIterable ;', 'boolean result = coll . remove ( item ) ;', 'protected List < V > createCollection ( ) {', 'return coll ! = null & & coll . contains ( value ) ;', '@ Override', 'if ( obj instanceof MultiValuedMap ) {', 'protected final K key ;', 'private class ValuesListIterator implements ListIterator < V > {', 'coll . clear ( ) ;', 'if ( coll = = null ) {', 'public Collection < V > get ( final K key ) {', 'boolean changed = coll . remove ( value ) ;', '} else {', 'public boolean put ( final K key , final V value ) {', 'if ( !map . isEmpty ( ) ) {', 'public boolean putAll ( final MultiValuedMap < ? extends K , ? extends V > map ) {', 'if ( obj instanceof SetValuedMap ) {', 'return asMap ( ) . hashCode ( ) ;', 'return list . lastIndexOf ( o ) ;', 'boolean result = coll . retainAll ( c ) ;', 'throw new NullPointerException ( ""Map must not be null . "" ) ;', 'return coll . add ( value ) ;', 'if ( coll ! = null ) {', 'implements SetValuedMap < K , V > {', 'protected TransformedMultiValuedMap ( final MultiValuedMap < K , V > map ,', 'return it . hasNext ( ) & & CollectionUtils . addAll ( get ( key ) , it ) ;', 'return values ( ) . contains ( value ) ;', 'changed | = put ( entry . getKey ( ) , entry . getValue ( ) ) ;', 'Collection < V > coll = getMap ( ) . get ( key ) ;', 'public boolean containsAll ( Collection < ? > other ) {', 'Iterator < ? extends V > it = values . iterator ( ) ;', 'return decorated ( ) . put ( transformKey ( key ) , transformValue ( value ) ) ;', 'return coll = = null ? 0 : coll . size ( ) ;', 'public boolean removeMapping ( final Object key , final Object value ) {', 'public ValuesListIterator ( final K key ) {', 'getMap ( ) . remove ( key ) ;', 'public List < V > get ( final K key ) {', 'boolean changed = list . addAll ( index , c ) ;', 'public abstract class AbstractMultiValuedMap < K , V > implements MultiValuedMap < K , V > , Serializable {', 'this . iterator . add ( value ) ;', 'throw new IllegalArgumentException ( ""InitialCapacity must not be negative . "" ) ;', 'return ( List < V > ) super . createCollection ( ) ;', 'return EmptyMapIterator . emptyMapIterator ( ) ;', 'return asMap ( ) . equals ( ( ( MultiValuedMap < ? , ? > ) obj ) . asMap ( ) ) ;', 'return coll . toArray ( ) ;', 'list = createCollection ( ) ;', 'AbstractMultiValuedMap . this . map . put ( key , coll ) ;', 'return it . hasNext ( ) & & CollectionUtils . addAll ( decorated ( ) . get ( transformKey ( key ) ) , it ) ;', 'decorated . putAll ( mapCopy ) ;', 'if ( map = = null ) {', 'public Set < V > get ( final K key ) {', 'final Collection < V > coll = getMap ( ) . get ( key ) ;', 'boolean result = coll . removeAll ( c ) ;', 'return coll = = null ? false : coll . containsAll ( other ) ;', '}', 'final Transformer < ? super V , ? extends V > valueTransformer ) {', 'public boolean addAll ( Collection < ? extends V > other ) {', 'protected List < V > getMapping ( ) {', 'return getMap ( ) . hashCode ( ) ;', 'if ( values instanceof Collection < ? > ) {', 'public abstract class AbstractSetValuedMap < K , V > extends AbstractMultiValuedMap < K , V >', 'public WrappedSet ( final K key ) {', 'return coll . addAll ( other ) ;', 'final MultiValuedMap < K , V > mapCopy = new MultiValuedHashMap < K , V > ( map ) ;', 'return coll . toString ( ) ;', 'public WrappedList ( final K key ) {', 'if ( coll . add ( value ) ) {', 'return UnmodifiableSet . unmodifiableSet ( keySet ( ) ) ;', 'private static final long serialVersionUID = 20150612L ;', 'List < V > list = getMapping ( ) ;', 'import org . apache . commons . collections4 . CollectionUtils ;', 'getMap ( ) . put ( key , list ) ;', 'return true ;', 'return coll = = null ? true : coll . isEmpty ( ) ;', 'public boolean putAll ( final K key , final Iterable < ? extends V > values ) {', 'final Transformer < ? super K , ? extends K > keyTransformer ,', 'return asMap ( ) . equals ( ( ( ListValuedMap < ? , ? > ) obj ) . asMap ( ) ) ;', 'this . collectionFactory = new InstantiateFactory < C > ( collectionClazz ,', 'return false ;', 'public boolean putAll ( final Map < ? extends K , ? extends V > map ) {', 'return coll . toArray ( a ) ;', 'return ( List < V > ) getMap ( ) . get ( key ) ;'}, 'removed_code': {'if ( SetUtils . isEqualSet ( set , otherSet ) = = false ) {', 'public abstract class AbstractSetValuedMap < K , V > extends AbstractMultiValuedMap < K , V > implements SetValuedMap < K , V > {', 'boolean tmpResult = coll . add ( it . next ( ) ) ;', 'return col . toArray ( ) ;', 'V transformedValue = transformValue ( value ) ;', 'import java . util . Map . Entry ;', 'list = ( List < V > ) createCollection ( ) ;', 'getMap ( ) . put ( key , coll ) ;', 'if ( ListUtils . isEqualList ( list , otherList ) = = false ) {', 'if ( val ! = null ) {', 'boolean result = list . addAll ( index , c ) ;', 'result . put ( transformKey ( entry . getKey ( ) ) , transformValue ( entry . getValue ( ) ) ) ;', 'vh + = val . hashCode ( ) ;', 'public ValuesListIterator ( Object key ) {', 'coll = createCollection ( ) ;', 'return Collections . emptyList ( ) . hashCode ( ) ;', 'remove ( key ) ;', 'if ( result ) {', 'return col . size ( ) ;', 'if ( map . size ( ) > 0 ) {', 'put ( entry . getKey ( ) , entry . getValue ( ) ) ;', 'h + = ( key = = null ? 0 : key . hashCode ( ) ) ^ vh ;', 'Iterator < Entry < K , Collection < V > > > it = getMap ( ) . entrySet ( ) . iterator ( ) ;', 'putAll ( key , map . get ( key ) ) ;', 'Collection < ? > col = get ( key ) ;', 'import java . util . Collection ;', 'coll . add ( it . next ( ) ) ;', 'throw new IllegalArgumentException ( ""Illegal Capacity : "" + initialCollectionCapacity ) ;', 'public ValuesListIterator ( Object key , int index ) {', 'return EmptyMapIterator . < K , V > emptyMapIterator ( ) ;', 'return AbstractMultiValuedMap . this . put ( ( K ) key , value ) ;', 'if ( !result ) {', 'return AbstractMultiValuedMap . this . putAll ( ( K ) key , c ) ;', 'if ( other = = null ) {', 'return ( Map < K , V > ) map ;', 'if ( set = = null ) {', 'protected MultiValuedMap < K , V > transformMultiValuedMap (', 'if ( col . isEmpty ( ) ) {', 'public Set < V > get ( Object key ) {', 'import java . util . Iterator ;', 'final List < V > list = ( List < V > ) getMapping ( ) ;', 'final Map < K , V > result = new LinkedMap < K , V > ( map . size ( ) ) ;', 'if ( obj instanceof SetValuedMap = = false ) {', 'return decorated ( ) . putAll ( transformedKey , transformedValues ) ;', 'result = true ;', 'for ( final Map . Entry < ? extends K , ? extends V > entry : map . entries ( ) ) {', 'List < ? > list = get ( key ) ;', 'return list . indexOf ( o ) ;', 'import java . util . LinkedList ;', 'private static final long serialVersionUID = - 1254147899086470720L ;', 'if ( col ! = null ) {', 'return col . addAll ( c ) ;', 'public WrappedCollection ( Object key ) {', 'public void putAll ( MultiValuedMap < ? extends K , ? extends V > m ) {', 'List < V > list = ( List < V > ) createCollection ( ) ;', 'private class ValuesListIterator implements ListIterator < V > {', 'return col . toArray ( a ) ;', 'if ( coll = = null ) {', 'result = coll . add ( value ) ;', 'public List < V > get ( Object key ) {', 'int h = 0 ;', 'return col . containsAll ( o ) ;', 'if ( valueCol ! = null ) {', 'if ( obj instanceof ListValuedMap = = false ) {', 'public boolean put ( K key , V value ) {', 'public void putAll ( MultiValuedMap < ? extends K , ? extends V > map ) {', 'if ( otherCol = = null ) {', 'if ( otherSet = = null ) {', 'V val = colIt . next ( ) ;', 'private static final long serialVersionUID = 7994988366330224277L ;', 'SetValuedMap < ? , ? > other = ( SetValuedMap < ? , ? > ) obj ;', 'h + = ( key = = null ? 0 : key . hashCode ( ) ) ^ SetUtils . hashCodeForSet ( valueSet ) ;', 'K transformedKey = transformKey ( key ) ;', 'Object key = it . next ( ) ;', 'if ( map . isEmpty ( ) ) {', 'for ( final K key : map . keySet ( ) ) {', 'while ( colIt . hasNext ( ) ) {', 'int vh = 0 ;', 'ListValuedMap < ? , ? > other = ( ListValuedMap < ? , ? > ) obj ;', 'if ( col = = null ) {', 'private static final long serialVersionUID = 6024950625989666915L ;', 'return decorated ( ) . put ( transformedKey , transformedValue ) ;', 'Collection < V > coll = getMap ( ) . get ( key ) ;', 'protected final Object key ;', 'final Collection < V > col = getMap ( ) . get ( key ) ;', 'return result ;', 'list = ( List < V > ) AbstractListValuedMap . this . createCollection ( ) ;', 'boolean result = col . remove ( item ) ;', 'Iterator < ? extends V > it = values . iterator ( ) ;', 'public boolean removeMapping ( K key , V item ) {', 'MultiValuedMap < K , V > transformed = decorated . transformMultiValuedMap ( map ) ;', 'this . iterator . add ( value ) ;', 'protected TransformedMultiValuedMap ( MultiValuedMap < K , V > map ,', 'K key = entry . getKey ( ) ;', 'public boolean addAll ( Collection < ? extends V > c ) {', 'return Collections . emptySet ( ) . hashCode ( ) ;', 'if ( CollectionUtils . isEqualCollection ( col , otherCol ) = = false ) {', 'Iterator < V > it = ( Iterator < V > ) values . iterator ( ) ;', 'final List < V > list = ListUtils . emptyIfNull ( ( List < V > ) getMapping ( ) ) ;', 'List < ? > otherList = other . get ( key ) ;', 'boolean result = col . retainAll ( c ) ;', 'public void putAll ( final Map < ? extends K , ? extends V > map ) {', 'for ( Collection < V > col : getMap ( ) . values ( ) ) {', 'return col . toString ( ) ;', 'public void putAll ( Map < ? extends K , ? extends V > m ) {', 'decorated ( ) . putAll ( transformMap ( m ) ) ;', 'Collection < V > valueCol = entry . getValue ( ) ;', 'public WrappedList ( Object key ) {', 'if ( !it . hasNext ( ) ) {', 'if ( map ! = null ) {', 'public WrappedSet ( Object key ) {', 'h + = ( key = = null ? 0 : key . hashCode ( ) ) ^ ListUtils . hashCodeForList ( valueList ) ;', 'Set < ? > set = get ( key ) ;', 'if ( other . size ( ) ! = size ( ) ) {', 'return col . add ( value ) ;', 'transformedValues . add ( transformValue ( it . next ( ) ) ) ;', 'Transformer < ? super K , ? extends K > keyTransformer , Transformer < ? super V , ? extends V > valueTransformer ) {', 'private static final long serialVersionUID = 3383617478898639862L ;', 'if ( pairs ! = null ) {', 'List < V > transformedValues = new LinkedList < V > ( ) ;', 'return UnmodifiableSet . < K > unmodifiableSet ( keySet ( ) ) ;', 'if ( obj instanceof MultiValuedMap = = false ) {', 'List < V > valueList = ( List < V > ) entry . getValue ( ) ;', 'Set < ? > otherSet = other . get ( key ) ;', 'final Set < Map . Entry < K , Collection < V > > > pairs = getMap ( ) . entrySet ( ) ;', 'public class AbstractMultiValuedMap < K , V > implements MultiValuedMap < K , V > , Serializable {', '}', 'getMap ( ) . put ( ( K ) key , list ) ;', 'boolean result = false ;', 'private final Object key ;', 'if ( !result & & tmpResult ) {', 'if ( otherList = = null ) {', 'return col . contains ( o ) ;', 'public boolean putAll ( K key , Iterable < ? extends V > values ) {', 'while ( it . hasNext ( ) ) {', 'MultiValuedMap < ? , ? > other = ( MultiValuedMap < ? , ? > ) obj ;', 'Set < V > valueSet = ( Set < V > ) entry . getValue ( ) ;', 'list . add ( index , value ) ;', 'if ( obj = = null ) {', 'decorated . decorated ( ) . putAll ( transformed ) ;', 'final Collection < V > col = getMapping ( ) ;', 'this . collectionFactory = new InstantiateFactory < C > ( collectionClazz , new Class [ ] { Integer . TYPE } ,', 'if ( list = = null ) {', 'Entry < K , Collection < V > > entry = it . next ( ) ;', 'return ( MultiValuedMap < K , V > ) map ;', 'for ( final Map . Entry < ? extends K , ? extends V > entry : map . entrySet ( ) ) {', 'result = col . remove ( item ) ;', 'final MultiValuedMap < ? extends K , ? extends V > map ) {', 'for ( final Map . Entry < K , Collection < V > > entry : pairs ) {', 'final MultiValuedMap < K , V > result = new MultiValuedHashMap < K , V > ( ) ;', 'return 0 ;', 'return col . isEmpty ( ) ;', 'col . clear ( ) ;', 'public boolean contains ( Object o ) {', 'Iterator < V > colIt = valueCol . iterator ( ) ;', 'Iterator < ? > it = keySet ( ) . iterator ( ) ;', 'return col . contains ( value ) ;', '@ SuppressWarnings ( ""unchecked"" )', 'return h ;', 'Collection < ? > otherCol = other . get ( key ) ;', 'return true ;', 'protected Map < K , V > transformMap ( final Map < ? extends K , ? extends V > map ) {', 'import java . util . List ;', 'if ( entry . getValue ( ) . contains ( value ) ) {', 'boolean result = col . removeAll ( c ) ;', 'public boolean containsAll ( Collection < ? > o ) {', 'if ( coll . size ( ) > 0 ) {', 'List < V > list = ( List < V > ) getMapping ( ) ;', 'import org . apache . commons . collections4 . map . LinkedMap ;', 'return false ;', 'decorated ( ) . putAll ( transformMultiValuedMap ( m ) ) ;', 'coll . add ( value ) ;', 'public Collection < V > get ( Object key ) {'}}"
